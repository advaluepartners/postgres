The below represents the folders and files from the root paths:
- /Users/barneycook/Desktop/code/ProjectRef/postgres/amazon-arm64-nix.pkr.hcl
- /Users/barneycook/Desktop/code/ProjectRef/postgres/ansible/playbook.yml
- /Users/barneycook/Desktop/code/ProjectRef/postgres/ansible/tasks/stage2-setup-postgres.yml
- /Users/barneycook/Desktop/code/ProjectRef/postgres/scripts/nix-provision.sh
- /Users/barneycook/Desktop/code/ProjectRef/postgres/stage2-nix-psql.pkr.hcl
- /Users/barneycook/Desktop/code/ProjectRef/postgres/flake.nix

Each file is separated by '''--- followed by the file path and ending with ---.
File content begins immediately after its path and extends until the next '''---

'''--- /Users/barneycook/Desktop/code/ProjectRef/postgres/amazon-arm64-nix.pkr.hcl ---
variable "ami" {
  type    = string
  default = "ubuntu/images/hvm-ssd/ubuntu-focal-20.04-arm64-server-*"
}

variable "profile" {
  type    = string
  default = "${env("AWS_PROFILE")}"
}

variable "ami_name" {
  type    = string
  default = "capitala-project-ami"
}

variable "ami_regions" {
  type    = list(string)
  default = ["ap-southeast-2"]
}

variable "ansible_arguments" {
  type    = string
  default = "--skip-tags install-postgrest,install-pgbouncer,install-supabase-internal"
}

variable "aws_access_key" {
  type    = string
  default = ""
}

variable "aws_secret_key" {
  type    = string
  default = ""
}

variable "environment" {
  type    = string
  default = "prod"
}

variable "region" {
  type    = string
}

variable "build-vol" {
  type    = string
  default = "xvdc"
}

# ccache docker image details
variable "docker_user" {
  type    = string
  default = ""
}

variable "docker_passwd" {
  type    = string
  default = ""
}

variable "docker_image" {
  type    = string
  default = ""
}

variable "docker_image_tag" {
  type    = string
  default = "latest"
}

locals {
  creator = "packer"
}

variable "postgres-version" {
  type = string
  default = ""
}

variable "git-head-version" {
  type = string
  default = "unknown"
}

variable "packer-execution-id" {
  type = string
  default = "unknown"
}

variable "force-deregister" {
  type    = bool
  default = false
}

packer {
  required_plugins {
    amazon = {
      source  = "github.com/hashicorp/amazon"
      version = "~> 1"
    }
  }
}

# source block
source "amazon-ebssurrogate" "source" {
  profile = "${var.profile}"
  #access_key    = "${var.aws_access_key}"
  #ami_name = "${var.ami_name}-arm64-${formatdate("YYYY-MM-DD-hhmm", timestamp())}"
  ami_name = "${var.ami_name}-${var.postgres-version}-stage-1"
  ami_virtualization_type = "hvm"
  ami_architecture = "arm64"
  ami_regions   = "${var.ami_regions}"
  instance_type = "c6g.xlarge"
  region       = "${var.region}"
  #secret_key   = "${var.aws_secret_key}"
  force_deregister = var.force-deregister

  # Use latest official ubuntu focal ami owned by Canonical.
  source_ami_filter {
    filters = {
      virtualization-type = "hvm"
      name = "${var.ami}"
      root-device-type = "ebs"
    }
    owners = [ "099720109477" ]
    most_recent = true
   }
  ena_support = true
  launch_block_device_mappings {
    device_name = "/dev/xvdf"
    delete_on_termination = true
    volume_size = 10
    volume_type = "gp3"
   }

  launch_block_device_mappings {
    device_name = "/dev/xvdh"
    delete_on_termination = true
    volume_size = 8
    volume_type = "gp3"
   }

  launch_block_device_mappings {
    device_name           = "/dev/${var.build-vol}"
    delete_on_termination = true
    volume_size           = 16
    volume_type           = "gp2"
    omit_from_artifact    = true
  }

  run_tags = {
    creator           = "packer"
    appType           = "postgres"
    packerExecutionId = "${var.packer-execution-id}"
  }
  run_volume_tags = {
    creator = "packer"
    appType = "postgres"
  }
  snapshot_tags = {
    creator = "packer"
    appType = "postgres"
  }
  tags = {
    creator = "packer"
    appType = "postgres"
    postgresVersion = "${var.postgres-version}-stage1"
    sourceSha = "${var.git-head-version}"
  }

  communicator = "ssh"
  ssh_pty = true
  ssh_username = "ubuntu"
  ssh_timeout = "5m"

  ami_root_device {
    source_device_name = "/dev/xvdf"
    device_name = "/dev/xvda"
    delete_on_termination = true
    volume_size = 10
    volume_type = "gp2"
  }

  associate_public_ip_address = true
}

# a build block invokes sources and runs provisioning steps on them.
build {
  sources = ["source.amazon-ebssurrogate.source"]

  provisioner "file" {
    source = "ebssurrogate/files/sources-arm64.cfg"
    destination = "/tmp/sources.list"
  }

  provisioner "file" {
    source = "ebssurrogate/files/ebsnvme-id"
    destination = "/tmp/ebsnvme-id"
  }

  provisioner "file" {
    source = "ebssurrogate/files/70-ec2-nvme-devices.rules"
    destination = "/tmp/70-ec2-nvme-devices.rules"
  }

  provisioner "file" {
    source = "ebssurrogate/scripts/chroot-bootstrap-nix.sh"
    destination = "/tmp/chroot-bootstrap-nix.sh"
  }

  provisioner "file" {
    source = "ebssurrogate/files/cloud.cfg"
    destination = "/tmp/cloud.cfg"
  }

  provisioner "file" {
    source = "ebssurrogate/files/vector.timer"
    destination = "/tmp/vector.timer"
  }

  provisioner "file" {
    source = "ebssurrogate/files/apparmor_profiles"
    destination = "/tmp"
  }

  provisioner "file" {
    source = "migrations"
    destination = "/tmp"
  }

  provisioner "file" {
    source = "ebssurrogate/files/unit-tests"
    destination = "/tmp"
  }

  # Copy ansible playbook
  provisioner "shell" {
    inline = ["mkdir /tmp/ansible-playbook"]
  }

  provisioner "file" {
    source = "ansible"
    destination = "/tmp/ansible-playbook"
  }

  provisioner "file" {
    source = "scripts"
    destination = "/tmp/ansible-playbook"
  }

  provisioner "file" {
    source = "ansible/vars.yml"
    destination = "/tmp/ansible-playbook/vars.yml"
  }

  provisioner "shell" {
    environment_vars = [
      "ARGS=${var.ansible_arguments}",
      "DOCKER_USER=${var.docker_user}",
      "DOCKER_PASSWD=${var.docker_passwd}",
      "DOCKER_IMAGE=${var.docker_image}",
      "DOCKER_IMAGE_TAG=${var.docker_image_tag}",
      "POSTGRES_SUPABASE_VERSION=${var.postgres-version}"
    ]
    use_env_var_file = true
    script = "ebssurrogate/scripts/surrogate-bootstrap-nix.sh"
    execute_command = "sudo -S sh -c '. {{.EnvVarFile}} && {{.Path}}'"
    start_retry_timeout = "5m"
    skip_clean = true
  }

  provisioner "file" {
    source = "/tmp/ansible.log"
    destination = "/tmp/ansible.log"
    direction = "download"
  }
}

'''

'''--- /Users/barneycook/Desktop/code/ProjectRef/postgres/stage2-nix-psql.pkr.hcl ---
variable "profile" {
  type    = string
  default = "${env("AWS_PROFILE")}"
}

variable "ami_regions" {
  type    = list(string)
  default = ["ap-southeast-2"]
}

variable "environment" {
  type    = string
  default = "prod"
}

variable "region" {
  type    = string
}

variable "ami_name" {
  type    = string
  default = "capitala-postgres"
}

variable "postgres-version" {
  type    = string
  default = ""
}

variable "git-head-version" {
  type    = string
  default = "unknown"
}

variable "postgres_major_version" {
  type    = string
  default = "15"
}

variable "git_commit_sha" {
  type    = string
  default = "local"
}

variable "packer-execution-id" {
  type    = string
  default = "unknown"
}

variable "force-deregister" {
  type    = bool
  default = false
}

variable "git_sha" {
  type    = string
  default = env("GIT_SHA")
}

packer {
  required_plugins {
    amazon = {
      version = ">= 0.0.2"
      source  = "github.com/hashicorp/amazon"
    }
  }
}

source "amazon-ebs" "ubuntu" {
  ami_name      = "${var.ami_name}-${var.postgres-version}"
  instance_type = "c6g.xlarge"
  region        = "${var.region}"
  source_ami_filter {
    filters = {
      name                = "${var.ami_name}-${var.postgres-version}-stage-1"
      root-device-type    = "ebs"
      virtualization-type = "hvm"
    }
    most_recent = true
    owners      = ["amazon", "self"]
  }
  
  communicator = "ssh"
  ssh_pty = true
  ssh_username = "ubuntu"
  ssh_timeout = "15m"
  
  associate_public_ip_address = true
  ena_support = true

  # Root volume - keep existing size
  launch_block_device_mappings {
    device_name           = "/dev/sda1"
    volume_type           = "gp3"
    volume_size           = 20
    delete_on_termination = true
  }
  
  # CRITICAL: 60GB volume for Nix store
  launch_block_device_mappings {
    device_name           = "/dev/sdf"
    volume_type           = "gp3"
    volume_size           = 60
    delete_on_termination = true
  }
  
  run_tags = {
    creator           = "packer"
    appType           = "postgres"
    packerExecutionId = "${var.packer-execution-id}"
  }
  run_volume_tags = {
    creator = "packer"
    appType = "postgres"
  }
  snapshot_tags = {
    creator = "packer"
    appType = "postgres"
  }
  tags = {
    creator = "packer"
    appType = "postgres"
    postgresVersion = "${var.postgres-version}"
    sourceSha = "${var.git-head-version}"
  }
}

build {
  name = "nix-packer-ubuntu"
  sources = [
    "source.amazon-ebs.ubuntu"
  ]

  provisioner "shell" {
    inline = [
      "echo '=== DEFINITIVE FIX: Mount 60GB volume at /nix instead of /nix/store ==='",
      "sudo mkdir -p /nix",
      "sudo mkfs.ext4 -F /dev/nvme2n1",
      "sudo mount /dev/nvme2n1 /nix", 
      "sudo chmod 1775 /nix",
      "sudo mkdir -p /nix/store",
      "sudo chmod 1775 /nix/store",
      "echo '60GB volume mounted at /nix (includes store)'",
      "df -h | grep nvme",
      # Test filesystem operations
      "echo 'test' | sudo tee /tmp/test-file",
      "sudo mkdir -p /nix/test-temp-dir",
      "sudo mv /tmp/test-file /nix/test-temp-dir/",
      "sudo mkdir -p /nix/store/test-final",
      "sudo mv /nix/test-temp-dir/test-file /nix/store/test-final/",
      "sudo rm -rf /nix/test-temp-dir /nix/store/test-final",
      "echo 'Filesystem move test passed'",
      # Prepare directories
      "mkdir -p /tmp/ansible-playbook",
      "rm -rf /tmp/ansible-playbook/nix",
      "mkdir -p /tmp/nix-build"
    ]
  }

  provisioner "file" {
    source = "ansible"
    destination = "/tmp/ansible-playbook"
  }

  provisioner "file" {
    source = "migrations"
    destination = "/tmp"
  }

  provisioner "file" {
    source = "ebssurrogate/files/unit-tests"
    destination = "/tmp/unit-tests"
  }

  provisioner "file" {
    source = "scripts"
    destination = "/tmp/ansible-playbook"
  }

  provisioner "file" {
    source = "flake.nix"
    destination = "/tmp/ansible-playbook/flake.nix"
  }

  provisioner "file" {
    source = "flake.lock"
    destination = "/tmp/ansible-playbook/flake.lock"
  }

  provisioner "shell" {
  inline = [
    "mkdir -p /tmp/ansible-playbook/nix"
  ]
  }

  provisioner "file" {
    source = "nix/"
    destination = "/tmp/ansible-playbook/nix/"
  }
  
  # FIXED: Enhanced script provisioner with proper exit code handling
  provisioner "shell" {
    environment_vars = [
      "GIT_SHA=${var.git_commit_sha}",
      "POSTGRES_MAJOR_VERSION=${var.postgres_major_version}",
      "NIX_BUILD_CORES=2",
      "_NIX_FORCE_HTTP_BINARY_CACHE_UPDATE=1" 
    ]
    script           = "scripts/nix-provision.sh"
    expect_disconnect = true
    # CRITICAL FIX: Added exit code 141 (SIGPIPE) to valid exit codes
    valid_exit_codes  = [0, 2, 141, 2300218]
    # Additional safeguards
    pause_before      = "5s"
    timeout          = "20m"
  }
}
  

'''

'''--- /Users/barneycook/Desktop/code/ProjectRef/postgres/ansible/tasks/stage2-setup-postgres.yml ---
# - name: Install openjdk11 for pljava from nix binary cache
#   become: yes
#   shell: |
#     sudo -u postgres bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix profile install nixpkgs#openjdk11"
# It was decided to leave pljava disabled at https://github.com/supabase/postgres/pull/690 therefore removing this task

- name: Check psql_version and modify supautils.conf and postgresql.conf if necessary
  block:
    - name: Check if psql_version is psql_orioledb-16
      set_fact:
        is_psql_oriole: "{{ psql_version in ['psql_orioledb-16', 'psql_orioledb-17'] }}"

    - name: Remove specified extensions from postgresql.conf if oriole-16 build
      ansible.builtin.command:
        cmd: >
          sed -i 's/ timescaledb,//g' 
          /etc/postgresql/postgresql.conf
      when: is_psql_oriole and stage2_nix
      become: yes

    - name: Remove specified extensions from supautils.conf if oriole-16 build
      ansible.builtin.command:
        cmd: >
          sed -i 's/ timescaledb,//g; s/ vector,//g; s/ plv8,//g; s/ postgis,//g; s/ pgrouting,//g' 
          /etc/postgresql-custom/supautils.conf
      when: is_psql_oriole and stage2_nix
      become: yes

    - name: Remove db_user_namespace from postgresql.conf if oriole-xx build
      ansible.builtin.command:
        cmd: >
          sed -i 's/db_user_namespace = off/#db_user_namespace = off/g;' 
          /etc/postgresql/postgresql.conf
      when: is_psql_oriole and stage2_nix
      become: yes

    - name: Append orioledb to shared_preload_libraries append within closing quote
      ansible.builtin.command:
        cmd: >
          sed -i 's/\(shared_preload_libraries.*\)'\''\(.*\)$/\1, orioledb'\''\2/'
          /etc/postgresql/postgresql.conf
      when: is_psql_oriole and stage2_nix
      become: yes

    - name: Add default_table_access_method setting
      ansible.builtin.lineinfile:
        path: /etc/postgresql/postgresql.conf
        line: "default_table_access_method = 'orioledb'"
        state: present
      when: is_psql_oriole and stage2_nix
      become: yes
    
    - name: Add ORIOLEDB_ENABLED environment variable
      ansible.builtin.lineinfile:
        path: /etc/environment
        line: 'ORIOLEDB_ENABLED=true'
      when: is_psql_oriole and stage2_nix
      become: yes

- name: Ensure /tmp/ansible-playbook is writable by postgres
  become: yes
  file:
    path: /tmp/ansible-playbook
    owner: postgres
    group: postgres
    mode: '0755'
    recurse: yes
  when: stage2_nix

- name: Debug supabase-groonga.nix contents
  become: yes
  shell: |
    cat /tmp/ansible-playbook/nix/supabase-groonga.nix || echo "File not found"
    ls -l /tmp/ansible-playbook/nix/
    sha256sum /tmp/ansible-playbook/nix/supabase-groonga.nix || echo "Checksum failed"
  when: stage2_nix
  register: groonga_debug
- debug:
    var: groonga_debug.stdout_lines
  when: stage2_nix

# - name: Install Postgres from local flake
#   become: yes
#   shell: |
#     sudo -u postgres bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix profile install /tmp/ansible-playbook#postgresql_15"
#   when: stage2_nix
#   register: install_postgres
#   retries: 3
#   delay: 5
#   until: install_postgres.rc == 0

############################################### Testing from Sonnet 

- name: Debug Nix environment before install
  shell: |
    echo "=== Environment Variables ==="
    env | grep -E "(TMPDIR|NIX_|BUILD)"
    echo "=== Nix Config ==="
    sudo -u postgres bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix show-config | head -20"
    echo "=== Available Space ==="
    df -h
    echo "=== Nix Store Location ==="
    sudo -u postgres bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix-store --version && nix eval --expr 'builtins.storeDir'"
  register: debug_nix_env

- name: Show debug output
  debug:
    var: debug_nix_env.stdout_lines

- name: Verify nix directory structure
  shell: |
    echo "=== Checking /tmp/ansible-playbook structure ==="
    ls -la /tmp/ansible-playbook/
    echo "=== Checking for nix directory ==="
    ls -la /tmp/ansible-playbook/nix/ || echo "nix directory missing"
    echo "=== Checking for cargo-pgrx ==="
    ls -la /tmp/ansible-playbook/nix/cargo-pgrx/ || echo "cargo-pgrx directory missing"
    echo "=== Checking for default.nix ==="
    ls -la /tmp/ansible-playbook/nix/cargo-pgrx/default.nix || echo "default.nix missing"
  when: stage2_nix
  register: nix_structure_check

- name: Show nix structure check results
  debug:
    var: nix_structure_check.stdout_lines
  when: stage2_nix

- name: Install Postgres from local flake
  become: yes
  shell: |
    chown -R postgres:postgres /var/lib/postgresql
    sudo -u postgres bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix --extra-experimental-features 'nix-command flakes' profile install --accept-flake-config /tmp/ansible-playbook#{{ psql_version }}/bin"
  when: stage2_nix
  register: install_postgres
  retries: 3
  delay: 5
  until: install_postgres.rc == 0

- name: Debug Nix profile contents
  become: yes
  shell: |
    sudo -u postgres bash -c "ls -l /var/lib/postgresql/.nix-profile"
    sudo -u postgres bash -c "ls -l /var/lib/postgresql/.nix-profile/lib || true"
    sudo -u postgres bash -c "ls -l /var/lib/postgresql/.nix-profile/include || true"
  when: stage2_nix
  register: nix_profile_debug
- debug:
    var: nix_profile_debug.stdout_lines
  when: stage2_nix

- name: Ensure PostgreSQL include subdirectories exist
  file:
    path: /usr/lib/postgresql/include/server
    state: directory
    owner: postgres
    group: postgres
    mode: '0755'
  when: stage2_nix

- name: Remove existing PostgreSQL include directory (ARM64 fix)
  file:
    path: /usr/lib/postgresql/include
    state: absent
  when: ansible_architecture == 'aarch64' and stage2_nix
  become: yes

- name: Debug contents of /var/lib/postgresql/.nix-profile/lib
  shell: ls -l /var/lib/postgresql/.nix-profile/lib
  register: lib_contents
  become: yes
  when: stage2_nix

- name: Show lib contents
  debug:
    var: lib_contents.stdout_lines
  when: stage2_nix

- name: Create ARM64 specific symlinks
  file:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
    state: link
  with_items:
    - { src: "/var/lib/postgresql/.nix-profile/lib", dest: "/usr/lib/postgresql/lib" }
    - { src: "/var/lib/postgresql/.nix-profile/include", dest: "/usr/lib/postgresql/include" }
  become: yes
  when: stage2_nix

- name: Create symlinks for PostgreSQL headers
  file:
    src: "{{ item }}"
    dest: "/usr/lib/postgresql/include/server/{{ item | basename }}"
    state: link
  with_fileglob:
    - "/var/lib/postgresql/.nix-profile/include/*.h"
  become: yes
  when:
    - stage2_nix
    - ansible_architecture != 'aarch64'

- name: Install pg_prove from nix binary cache
  become: yes
  shell: |
    sudo -u postgres bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix profile install github:supabase/postgres/{{ git_commit_sha }}#pg_prove"
  when: stage2_nix

- name: Install supabase-groonga from nix binary cache
  become: yes
  shell: |
    sudo -u postgres bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix profile install github:supabase/postgres/{{ git_commit_sha }}#supabase_groonga"
  when: stage2_nix and ansible_architecture != 'aarch64'

- name: Skip supabase-groonga on ARM
  debug:
    msg: "Skipping supabase-groonga installation on ARM architecture"
  when: stage2_nix and ansible_architecture == 'aarch64'

- name: Configure ARM-specific settings
  set_fact:
    platform_specific_paths:
      lib_dir: "/lib/aarch64-linux-gnu"
      include_dir: "/usr/include/aarch64-linux-gnu"
  when: ansible_architecture == 'arm64'

- name: Install debug symbols for postgres version
  become: yes
  shell: |
    sudo -u postgres bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix profile install github:supabase/postgres/{{ git_commit_sha }}#{{ postgresql_version }}_debug"
  when:
    - stage2_nix
    - ansible_architecture != 'aarch64'

  
- name: Set ownership and permissions for /etc/ssl/private
  become: yes
  file:
    path: /etc/ssl/private
    owner: root
    group: postgres
    mode: '0750'
  when: stage2_nix

- name: Set permissions for postgresql.env
  become: yes
  file:
    path: /etc/environment.d/postgresql.env
    owner: postgres
    group: postgres
    mode: '0644'
  when: stage2_nix

- name: Ensure /usr/lib/postgresql/bin directory exists
  file:
    path: /usr/lib/postgresql/bin
    state: directory
    owner: postgres
    group: postgres
  when: stage2_nix

- name: Ensure /usr/lib/postgresql/share directory exists
  file:
    path: /usr/lib/postgresql/share/postgresql
    state: directory
    owner: postgres
    group: postgres
  when: stage2_nix

- name: Ensure /usr/lib/postgresql/share/contrib directory exists
  file:
    path: /usr/lib/postgresql/share/postgresql/contrib
    state: directory
    owner: postgres
    group: postgres
  when: stage2_nix

- name: Ensure /usr/lib/postgresql/share/timezonesets directory exists
  file:
    path: /usr/lib/postgresql/share/postgresql/timezonesets
    state: directory
    owner: postgres
    group: postgres
  when: stage2_nix

- name: Ensure /usr/lib/postgresql/share/tsearch_data directory exists
  file:
    path: /usr/lib/postgresql/share/postgresql/tsearch_data
    state: directory
    owner: postgres
    group: postgres
  when: stage2_nix

- name: Ensure /usr/lib/postgresql/share/extension directory exists
  file:
    path: /usr/lib/postgresql/share/postgresql/extension
    state: directory
    owner: postgres
    group: postgres
  when: stage2_nix

# - name: Ensure /usr/lib/postgresql/share/postgresql/pljava directory exists
#   file:
#     path: /usr/lib/postgresql/share/postgresql/pljava
#     state: directory
#     owner: postgres
#     group: postgres
#   when: stage2_nix
# It was decided to leave pljava disabled at https://github.com/supabase/postgres/pull/690 therefore removing this task

- name: import pgsodium_getkey script
  template:
    src: /tmp/ansible-playbook/ansible/files/pgsodium_getkey_readonly.sh.j2
    dest: "/usr/lib/postgresql/bin/pgsodium_getkey.sh"
    owner: postgres
    group: postgres
    mode: 0700
  when: stage2_nix

- name: Create symbolic links from /var/lib/postgresql/.nix-profile/bin to /usr/lib/postgresql/bin
  file:
    src: "{{ item }}"
    dest: "/usr/lib/postgresql/bin/{{ item | basename }}"
    state: link
  with_fileglob:
    - "/var/lib/postgresql/.nix-profile/bin/*"
  become: yes
  when: stage2_nix

- name: Check if /usr/bin/pg_config exists
  stat:
    path: /usr/bin/pg_config
  register: pg_config_stat
  when: stage2_nix

- name: Remove existing /usr/bin/pg_config if it is not a symlink
  file:
    path: /usr/bin/pg_config
    state: absent
  when: pg_config_stat.stat.exists and not pg_config_stat.stat.islnk and stage2_nix
  become: yes

- name: Create symbolic links from /var/lib/postgresql/.nix-profile/bin to /usr/bin
  file:
    src: "{{ item }}"
    dest: "/usr/bin/{{ item | basename }}"
    state: link
  with_fileglob:
    - "/var/lib/postgresql/.nix-profile/bin/*"
  become: yes
  when: stage2_nix

- name: Ensure postgres user has ownership of symlink
  file:
    path: "/usr/bin/{{ item | basename }}"
    owner: postgres
    group: postgres
  with_fileglob:
    - "/var/lib/postgresql/.nix-profile/bin/*"
  become: yes
  when: stage2_nix

# - name: Create symbolic links from /var/lib/postgresql/.nix-profile/share/pljava to /usr/lib/postgresql/share/postgresql/pljava
#   file:
#     src: "{{ item }}"
#     dest: "/usr/lib/postgresql/share/postgresql/pljava/{{ item | basename }}"
#     state: link
#   with_fileglob:
#     - "/var/lib/postgresql/.nix-profile/share/pljava/*"
#   become: yes
# It was decided to leave pljava disabled at https://github.com/supabase/postgres/pull/690 therefore removing this task

- name: Create symbolic links from /var/lib/postgresql/.nix-profile/share/postgresql to /usr/lib/postgresql/share/postgresql
  file:
    src: "{{ item }}"
    dest: "/usr/lib/postgresql/share/postgresql/{{ item | basename }}"
    state: link
  with_fileglob:
    - "/var/lib/postgresql/.nix-profile/share/postgresql/*"
  become: yes
  when: stage2_nix

### Test2 Anthropic Block Tuesday 25 --  // out this one block 

# - name: Create symbolic links from /var/lib/postgresql/.nix-profile/share/postgresql/extension to /usr/lib/postgresql/share/postgresql/extension
#   file:
#     src: "{{ item }}"
#     dest: "/usr/lib/postgresql/share/postgresql/extension/{{ item | basename }}"
#     state: link
#   with_fileglob:
#     - "/var/lib/postgresql/.nix-profile/share/postgresql/extension/*"
#   become: yes
#   when: stage2_nix

- name: Ensure all PostgreSQL extensions are properly linked from Nix
  block:
    - name: Create required PostgreSQL library directories
      file:
        path: "{{ item }}"
        state: directory
        owner: postgres
        group: postgres
        mode: '0755'
      loop:
        - "/usr/lib/postgresql/lib"
        - "/usr/lib/postgresql/share/postgresql/extension"

    # First find all extension libraries (.so files)
    - name: Find all extension shared libraries in Nix profile
      shell: |
        find /var/lib/postgresql/.nix-profile -name "*.so" | grep -v "lib/lib"
      register: extension_libs_search
      changed_when: false
      failed_when: false

    - name: Show found extension libraries
      debug:
        var: extension_libs_search.stdout_lines

    # Copy all extension libraries to PostgreSQL lib directory
    - name: Link all extension shared libraries to PostgreSQL lib directory
      shell: |
        if [ -n "{{ extension_libs_search.stdout }}" ]; then
          for lib in {{ extension_libs_search.stdout_lines | join(' ') }}; do
            # Get the basename of the library
            lib_name=$(basename "$lib")
            # Copy the library to PostgreSQL lib directory
            cp -f "$lib" /usr/lib/postgresql/lib/
            chmod 755 /usr/lib/postgresql/lib/"$lib_name"
            chown postgres:postgres /usr/lib/postgresql/lib/"$lib_name"
            echo "Copied $lib_name"
          done
        else
          echo "No extension libraries found"
        fi
      register: extension_libs_copy
      when: extension_libs_search.stdout != ""

    # Find all extension files (.control, .sql)
    - name: Find all extension control files in Nix profile
      shell: |
        find /var/lib/postgresql/.nix-profile -path "*/extension/*" | grep -E '\.control$|\.sql$'
      register: extension_files_search
      changed_when: false
      failed_when: false

    - name: Show found extension files
      debug:
        var: extension_files_search.stdout_lines

    # Copy all extension files to PostgreSQL extension directory
    - name: Link all extension files to PostgreSQL extension directory
      shell: |
        if [ -n "{{ extension_files_search.stdout }}" ]; then
          for ext_file in {{ extension_files_search.stdout_lines | join(' ') }}; do
            # Get the basename of the extension file
            ext_name=$(basename "$ext_file")
            # Copy the extension file to PostgreSQL extension directory
            cp -f "$ext_file" /usr/lib/postgresql/share/postgresql/extension/
            chmod 644 /usr/lib/postgresql/share/postgresql/extension/"$ext_name"
            chown postgres:postgres /usr/lib/postgresql/share/postgresql/extension/"$ext_name"
            echo "Copied $ext_name"
          done
        else
          echo "No extension files found"
        fi
      register: extension_files_copy
      when: extension_files_search.stdout != ""

    # Special handling for extension-specific directories (like postgis)
    - name: Find extension directories in Nix profile
      shell: |
        find /var/lib/postgresql/.nix-profile -path "*/postgresql/contrib/*" -type d
      register: extension_dirs_search
      changed_when: false
      failed_when: false

    - name: Show found extension directories
      debug:
        var: extension_dirs_search.stdout_lines

    - name: Create extension directories in PostgreSQL
      file:
        path: "/usr/lib/postgresql/share/postgresql/contrib"
        state: directory
        owner: postgres
        group: postgres
        mode: '0755'
      when: extension_dirs_search.stdout != ""

    - name: Copy extension directories to PostgreSQL
      shell: |
        if [ -n "{{ extension_dirs_search.stdout }}" ]; then
          for dir in {{ extension_dirs_search.stdout_lines | join(' ') }}; do
            # Get the basename of the directory
            dir_name=$(basename "$dir")
            # Create the directory in PostgreSQL contrib directory
            mkdir -p /usr/lib/postgresql/share/postgresql/contrib/"$dir_name"
            # Copy all files from the directory
            cp -rf "$dir"/* /usr/lib/postgresql/share/postgresql/contrib/"$dir_name"/
            chmod -R 755 /usr/lib/postgresql/share/postgresql/contrib/"$dir_name"
            chown -R postgres:postgres /usr/lib/postgresql/share/postgresql/contrib/"$dir_name"
            echo "Copied directory $dir_name"
          done
        else
          echo "No extension directories found"
        fi
      register: extension_dirs_copy
      when: extension_dirs_search.stdout != ""

    # Verify key extensions
    - name: Verify key extension files
      shell: |
        echo "=== Checking Extension Files ==="
        echo "PgAudit:"
        ls -la /usr/lib/postgresql/lib/pgaudit* 2>/dev/null || echo "PgAudit lib not found"
        ls -la /usr/lib/postgresql/share/postgresql/extension/pgaudit* 2>/dev/null || echo "PgAudit extension not found"
        
        echo "PostGIS:"
        ls -la /usr/lib/postgresql/lib/postgis* 2>/dev/null || echo "PostGIS lib not found"
        ls -la /usr/lib/postgresql/share/postgresql/extension/postgis* 2>/dev/null || echo "PostGIS extension not found"
        
        echo "plpgsql:"
        ls -la /usr/lib/postgresql/share/postgresql/extension/plpgsql* 2>/dev/null || echo "plpgsql extension not found"
      register: extension_check
      changed_when: false
      ignore_errors: yes

    - name: Show extension check results
      debug:
        var: extension_check.stdout_lines

    # As a fallback, try a more direct approach for copying all extension files
    - name: Direct copy of extension files from Nix profile (fallback)
      shell: |
        cp -rf /var/lib/postgresql/.nix-profile/share/postgresql/extension/* /usr/lib/postgresql/share/postgresql/extension/ || echo "No extension files to copy"
        if [ -d "/var/lib/postgresql/.nix-profile/lib/postgresql" ]; then
          cp -rf /var/lib/postgresql/.nix-profile/lib/postgresql/* /usr/lib/postgresql/lib/ || echo "No library files to copy"
        fi
        find /var/lib/postgresql/.nix-profile -name "*.so" -exec cp -f {} /usr/lib/postgresql/lib/ \; || echo "No .so files found"
        chown -R postgres:postgres /usr/lib/postgresql/lib/
        chown -R postgres:postgres /usr/lib/postgresql/share/
        chmod -R 755 /usr/lib/postgresql/lib/
        chmod -R 755 /usr/lib/postgresql/share/
      ignore_errors: yes
  when: stage2_nix

- name: Direct install of pgaudit as fallback
  block:
    - name: Temporarily remove pgaudit from shared_preload_libraries
      become: yes
      become_user: postgres
      replace:
        path: /etc/postgresql/postgresql.conf
        regexp: '(shared_preload_libraries\s*=\s*[''"].*),?\s*pgaudit(.*[''"])'
        replace: '\1\2'
      
    - name: Create pgaudit directory
      file:
        path: "/usr/lib/postgresql/lib"
        state: directory
        owner: postgres
        group: postgres
        mode: '0755'

    - name: Find all extensions inside Nix store
      shell: |
        find /nix/store -name "pgaudit.so" -o -name "pgaudit*control" 2>/dev/null || echo "Not found"
      register: nix_store_search
      changed_when: false

    - name: Show Nix store search results
      debug:
        var: nix_store_search.stdout_lines
  
    - name: Use an alternative approach to copy extensions from Nix
      shell: |
        echo "=== Finding Nix packages ==="
        cp -v /var/lib/postgresql/.nix-profile/lib/*.so* /usr/lib/postgresql/lib/ 2>/dev/null || echo "No .so files found"
        mkdir -p /usr/lib/postgresql/share/postgresql/extension
        cp -v /var/lib/postgresql/.nix-profile/share/postgresql/extension/* /usr/lib/postgresql/share/postgresql/extension/ 2>/dev/null || echo "No extension files found"
        find /nix/store -path "*/postgresql/extension/pgaudit*.control" -exec cp -v {} /usr/lib/postgresql/share/postgresql/extension/ \; 2>/dev/null || echo "No control files found"
        find /nix/store -path "*/lib/pgaudit.so" -exec cp -v {} /usr/lib/postgresql/lib/ \; 2>/dev/null || echo "No lib files found"
        chmod 755 /usr/lib/postgresql/lib/*.so* 2>/dev/null || true
        chmod 644 /usr/lib/postgresql/share/postgresql/extension/* 2>/dev/null || true
        chown -R postgres:postgres /usr/lib/postgresql/lib/
        chown -R postgres:postgres /usr/lib/postgresql/share/
      ignore_errors: yes

    - name: Verify installation after direct copy
      shell: |
        echo "=== Library files ==="
        ls -la /usr/lib/postgresql/lib/ || echo "No directory"
        echo "=== Extension files ==="
        ls -la /usr/lib/postgresql/share/postgresql/extension/ || echo "No directory"
      register: direct_copy_check
      changed_when: false

    - name: Show direct copy results
      debug:
        var: direct_copy_check.stdout_lines
  when: stage2_nix

- name: Fix permissions for all PostgreSQL extension files
  block:
    - name: Ensure correct permissions for extension directory
      file:
        path: "/usr/lib/postgresql/share/postgresql/extension"
        state: directory
        owner: postgres
        group: postgres
        mode: '0755'
        recurse: no

    - name: Fix permissions for extension files
      shell: |
        find /usr/lib/postgresql/share/postgresql/extension -type f -exec chmod 644 {} \;
        find /usr/lib/postgresql/share/postgresql/extension -type f -exec chown postgres:postgres {} \;
        find /usr/lib/postgresql/lib -name "*.so*" -exec chmod 755 {} \; 2>/dev/null || true
        find /usr/lib/postgresql/lib -name "*.so*" -exec chown postgres:postgres {} \; 2>/dev/null || true
      become: yes

    - name: Verify fixed permissions
      shell: |
        echo "=== Extension directory permissions ==="
        ls -la /usr/lib/postgresql/share/postgresql/extension/
        echo "=== pgtap.control permissions ==="
        ls -la /usr/lib/postgresql/share/postgresql/extension/pgtap.control 2>/dev/null || echo "File not found"
      register: perm_check
      changed_when: false

    - name: Show permissions check results
      debug:
        var: perm_check.stdout_lines
  when: stage2_nix



### Test2 Anthropic Block Tuesday 25 --  // out this one block 


- name: create destination directory
  file:
    path: /usr/lib/postgresql/share/postgresql/contrib/
    state: directory
    recurse: yes
  when: stage2_nix

- name: Check psql_version and run postgis linking if not oriole-xx
  block:
    - name: Check if psql_version is psql_orioledb-17
      set_fact:
        is_psql_oriole: "{{ psql_version == 'psql_orioledb-17' }}"

    - name: Install PostGIS from nixpkgs
      become: yes
      shell: |
        sudo -u postgres bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix profile install nixpkgs#postgresql15Packages.postgis"
      when: stage2_nix and not is_psql_oriole and ansible_architecture != 'aarch64'
      register: install_postgis
      retries: 3
      delay: 5
      until: install_postgis.rc == 0

    - name: Skip PostGIS on ARM64
      debug:
        msg: "Skipping PostGIS installation on ARM64 as it’s not available in nixpkgs"
      when: stage2_nix and not is_psql_oriole and ansible_architecture == 'aarch64'

    - name: Debug contrib directory contents
      shell: "ls -l /var/lib/postgresql/.nix-profile/share/postgresql/contrib/ || echo 'Contrib directory not found'"
      register: contrib_debug
      become: yes
      when: stage2_nix and not is_psql_oriole and ansible_architecture != 'aarch64'

    - name: Show contrib directory contents
      debug:
        var: contrib_debug.stdout_lines
      when: stage2_nix and not is_psql_oriole and ansible_architecture != 'aarch64'

    - name: Recursively create symbolic links and set permissions for the contrib/postgis-* dir
      shell: >
        sudo mkdir -p /usr/lib/postgresql/share/postgresql/contrib && \
        sudo find /var/lib/postgresql/.nix-profile/share/postgresql/contrib/ -mindepth 1 -type d -exec sh -c 'for dir do sudo ln -s "$dir" "/usr/lib/postgresql/share/postgresql/contrib/$(basename "$dir")"; done' sh {} + \
        && chown -R postgres:postgres "/usr/lib/postgresql/share/postgresql/contrib/"
      become: yes
      when: stage2_nix and not is_psql_oriole and ansible_architecture != 'aarch64'

- name: Create symbolic links from /var/lib/postgresql/.nix-profile/share/postgresql/timezonesets to /usr/lib/postgresql/share/postgresql/timeszonesets
  file:
    src: "{{ item }}"
    dest: "/usr/lib/postgresql/share/postgresql/timezonesets/{{ item | basename }}"
    state: link
  with_fileglob:
    - "/var/lib/postgresql/.nix-profile/share/postgresql/timezonesets/*"
  become: yes
  when: stage2_nix

- name: Create symbolic links from /var/lib/postgresql/.nix-profile/share/postgresql/tsearch_data to /usr/lib/postgresql/share/postgresql/tsearch_data
  file:
    src: "{{ item }}"
    dest: "/usr/lib/postgresql/share/postgresql/tsearch_data/{{ item | basename }}"
    state: link
  with_fileglob:
    - "/var/lib/postgresql/.nix-profile/share/postgresql/tsearch_data/*"
  become: yes
  when: stage2_nix

- set_fact:
    pg_bindir: "/usr/lib/postgresql/bin"
  when: stage2_nix

- name: pgsodium - set pgsodium.getkey_script
  become: yes
  lineinfile:
    path: /etc/postgresql/postgresql.conf
    state: present
    # script is expected to be placed by finalization tasks for different target platforms
    line: pgsodium.getkey_script= '{{ pg_bindir }}/pgsodium_getkey.sh'
  when: stage2_nix

- name: Create symbolic link for pgsodium_getkey script
  file:
    src: "/usr/lib/postgresql/bin/pgsodium_getkey.sh"
    dest: "/usr/lib/postgresql/share/postgresql/extension/pgsodium_getkey"
    state: link
  become: yes
  when: stage2_nix

- name: Append GRN_PLUGINS_DIR to /etc/environment.d/postgresql.env
  ansible.builtin.lineinfile:
    path: /etc/environment.d/postgresql.env
    line: 'GRN_PLUGINS_DIR=/var/lib/postgresql/.nix-profile/lib/groonga/plugins'
  become: yes

'''

'''--- /Users/barneycook/Desktop/code/ProjectRef/postgres/ansible/playbook.yml ---
- hosts: all
  become: yes
  gather_facts: yes  # Add this line

  pre_tasks:
    - import_tasks: tasks/setup-system.yml
  vars_files:
    - ./vars.yml

  vars:
    sql_files:
      - {
          source: "pgbouncer_config/pgbouncer_auth_schema.sql",
          dest: "00-schema.sql",
        }
      - { source: "stat_extension.sql", dest: "01-extension.sql" }
    
  environment:
    PATH: /usr/lib/postgresql/bin:{{ ansible_env.PATH }}

  tasks:
    # New tasks to ensure git is installed and clone the repository
    - name: Ensure git is installed
      apt:
        name: git
        state: present

    # - name: Clone advaluepartners/postgres repo
    #   git:
    #     repo: 'https://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@github.com/advaluepartners/postgres.git'
    #     dest: /usr/local/src/advaluepartners-postgres
    #     version: main
  
    - set_fact:
        supabase_internal: true
      tags:
        - install-supabase-internal

    - set_fact:
        parallel_jobs: 16
    - name: Set system state for user management
      block:
        - name: Ensure nscd is installed (if using glibc)
          apt:
            name: nscd
            state: present
          when: ansible_os_family == "Debian"
          ignore_errors: yes

        - name: Clear system user/group cache
          shell: |
            if command -v nscd >/dev/null 2>&1; then
              nscd -i group
              nscd -i passwd
            fi
            systemctl daemon-reload
          ignore_errors: yes

    - name: Install Postgres from source
      import_tasks: tasks/setup-postgres.yml


    - name: Install PgBouncer
      import_tasks: tasks/setup-pgbouncer.yml
      tags:
        - install-pgbouncer
        - install-supabase-internal
      when:  debpkg_mode or nixpkg_mode or stage2_nix

    - name: Install WAL-G
      import_tasks: tasks/setup-wal-g.yml
      when: debpkg_mode or nixpkg_mode or stage2_nix

    - name: Install Gotrue
      import_tasks: tasks/setup-gotrue.yml
      tags:
        - install-gotrue
        - install-supabase-internal
      when: debpkg_mode or nixpkg_mode or stage2_nix  # Add stage2_nix
      
    - name: Install PostgREST
      import_tasks: tasks/setup-postgrest.yml
      vars:
        postgresql_major: "{{ postgresql_major_version }}"
      tags:
        - install-postgrest
        - install-supabase-internal
      when: debpkg_mode or nixpkg_mode or stage2_nix

    - name: Install Envoy
      import_tasks: tasks/setup-envoy.yml
      tags:
        - install-supabase-internal
      when: debpkg_mode or nixpkg_mode or stage2_nix  # Add stage2_nix

    - name: Install Kong
      import_tasks: tasks/setup-kong.yml
      tags:
        - install-supabase-internal
      when: debpkg_mode or nixpkg_mode or stage2_nix

    - name: Install nginx
      import_tasks: tasks/setup-nginx.yml
      tags:
        - install-supabase-internal
      when: debpkg_mode or nixpkg_mode or stage2_nix

    - name: Install Vector
      import_tasks: tasks/setup-vector.yml
      tags:
        - install-supabase-internal
      when: debpkg_mode or nixpkg_mode or stage2_nix

    - name: Install Supabase specific content
      import_tasks: tasks/setup-supabase-internal.yml
      tags:
        - install-supabase-internal
      when: debpkg_mode or nixpkg_mode  or stage2_nix


    - name: Fix IPv6 NDisc issues
      import_tasks: tasks/fix_ipv6_ndisc.yml
      tags:
        - install-supabase-internal
      when: debpkg_mode or nixpkg_mode

    - name: Start Postgres Database without Systemd
      become: yes
      become_user: postgres
      shell:
        cmd: /usr/lib/postgresql/bin/pg_ctl -D /var/lib/postgresql/data start
      when: debpkg_mode

    - name: Adjust APT update intervals
      copy:
        src: files/apt_periodic
        dest: /etc/apt/apt.conf.d/10periodic
      when: debpkg_mode or nixpkg_mode
      
    - name: Transfer init SQL files
      copy:
        src: files/{{ item.source }}
        dest: /tmp/{{ item.dest }}
      loop: "{{ sql_files }}"
      when: debpkg_mode or stage2_nix

    - name: Create postgres role
      become: yes
      become_user: postgres
      shell:
        cmd: /usr/lib/postgresql/bin/psql --username=capitala_admin -d postgres -c "create role postgres superuser login; alter database postgres owner to postgres;"
      when: debpkg_mode or stage2_nix

    - name: Execute init SQL files
      become: yes
      become_user: postgres
      shell:
        cmd: /usr/lib/postgresql/bin/psql -f /tmp/{{ item.dest }}
      loop: "{{ sql_files }}"
      when: debpkg_mode or stage2_nix

    - name: Delete SQL scripts
      file:
        path: /tmp/{{ item.dest }}
        state: absent
      loop: "{{ sql_files }}"
      when: debpkg_mode or stage2_nix

    - name: First boot optimizations
      import_tasks: tasks/internal/optimizations.yml
      tags:
        - install-supabase-internal
      when: debpkg_mode or stage2_nix
      
    - name: Finalize AMI
      import_tasks: tasks/finalize-ami.yml
      tags:
        - install-supabase-internal
      when: debpkg_mode or nixpkg_mode
      
    - name: Enhance fail2ban
      import_tasks: tasks/setup-fail2ban.yml
      when: debpkg_mode or nixpkg_mode

    - name: Install Admin API
      import_tasks: tasks/internal/admin-api.yml
      tags:
        - install-supabase-internal
      when: debpkg_mode or nixpkg_mode or stage2_nix

    - name: Internal tasks setup
      block:
        - name: Install supautils
          import_tasks: tasks/internal/supautils.yml
        - name: Setup postgresql-prestart
          import_tasks: tasks/internal/postgresql-prestart.yml
        # - name: Setup optimizations
        #   import_tasks: tasks/internal/optimizations.yml
        - name: Setup admin-api
          import_tasks: tasks/internal/admin-api.yml
        - name: Install salt
          import_tasks: tasks/internal/install-salt.yml
        - name: Setup pg_egress_collect
          import_tasks: tasks/internal/pg_egress_collect.yml
        - name: Setup admin-mgr
          import_tasks: tasks/internal/admin-mgr.yml
        - name: Setup postgres-exporter
          import_tasks: tasks/internal/postgres-exporter.yml
        - name: Setup nftables
          import_tasks: tasks/internal/setup-nftables.yml
      when: debpkg_mode or nixpkg_mode or stage2_nix
      tags:
        - install-supabase-internal

    # Install EC2 instance connect
    # Only for AWS images
    - name: install EC2 instance connect
      become: yes
      apt:
        pkg:
          - ec2-instance-connect
      tags:
        - aws-only

    # Install this at the end to prevent it from kicking in during the apt process, causing conflicts
    - name: Install security tools
      become: yes
      apt:
        pkg:
          - unattended-upgrades
        update_cache: yes
        cache_valid_time: 3600

    - name: Clean out build dependencies
      import_tasks: tasks/clean-build-dependencies.yml

    - name: Ensure /run/postgresql exists for lock file creation
      become: yes
      file:
        path: /run/postgresql
        state: directory
        owner: postgres
        group: postgres
        mode: '2775'

      when: stage2_nix

    - name: Check if PostgreSQL is running
      become: yes
      become_user: postgres
      shell: /usr/lib/postgresql/bin/pg_ctl -D /var/lib/postgresql/data status
      args:
        executable: /bin/bash
      register: pg_status
      ignore_errors: yes
      when: stage2_nix

    - name: Force kill PostgreSQL process if running and remove stale PID file
      become: yes
      become_user: postgres
      shell: |
        if [ -f /var/lib/postgresql/data/postmaster.pid ]; then
          PID=$(head -n 1 /var/lib/postgresql/data/postmaster.pid)
          if ps -p $PID > /dev/null 2>&1; then
            echo "PostgreSQL process $PID is still running. Force killing..."
            kill -9 $PID
            # Give the OS a moment to reap the process
            sleep 2
          fi
          echo "Removing stale PID file"
          rm -f /var/lib/postgresql/data/postmaster.pid
        fi
      args:
        executable: /bin/bash
      when: stage2_nix

    - name: Ensure PostgreSQL is not running (double-check)
      become: yes
      become_user: postgres
      shell: /usr/lib/postgresql/bin/pg_ctl -D /var/lib/postgresql/data status
      args:
        executable: /bin/bash
      register: pg_status_after
      ignore_errors: yes
      when: stage2_nix

    - name: Fail if PostgreSQL is still running
      fail:
        msg: "PostgreSQL is still running after force kill; cannot start a new instance."
      when: stage2_nix and (pg_status_after.rc == 0)

    - name: Restart PostgreSQL without Systemd
      become: yes
      become_user: postgres
      ansible.builtin.shell: |
        # Export environment variables inline
        # export LANG=en_US.UTF-8
        # export LANGUAGE=en_US:en
        # export LC_ALL=en_US.UTF-8
        # export LC_CTYPE=en_US.UTF-8
        export LANG=C
        export LANGUAGE=C
        export LC_ALL=C
        export LC_CTYPE=C
        export LOCALE_ARCHIVE=/usr/lib/locale/locale-archive
        # Use the POSIX "." operator instead of "source"
        . /var/lib/postgresql/.bashrc
        /usr/lib/postgresql/bin/pg_ctl -D /var/lib/postgresql/data start
      args:
        executable: /bin/bash
      when: stage2_nix

    - name: Setup Apache AGE extension
      become: yes
      become_user: postgres
      shell: |
        # Wait for PostgreSQL to be fully ready
        for i in {1..30}; do
          if psql -d postgres -c "SELECT 1;" > /dev/null 2>&1; then
            break
          fi
          sleep 1
        done
        
        # Create AGE extension with error handling
        psql -d postgres -c "CREATE EXTENSION IF NOT EXISTS age CASCADE;" || {
          echo "Failed to create AGE extension, checking dependencies..."
          psql -d postgres -c "\dx"
          exit 1
        }
        
        # Load AGE
        psql -d postgres -c "LOAD 'age';" || {
          echo "Failed to load AGE extension"
          exit 1
        }
        
        # Set search path only if ag_catalog exists
        psql -d postgres -c "DO \$\$ 
        BEGIN 
          IF EXISTS (SELECT 1 FROM pg_namespace WHERE nspname = 'ag_catalog') THEN 
            EXECUTE 'SET search_path = ag_catalog, \"\$user\", public'; 
            RAISE NOTICE 'AGE extension successfully configured';
          ELSE
            RAISE WARNING 'ag_catalog schema not found - AGE may not be properly installed';
          END IF; 
        END \$\$;"
        
        # Verify AGE installation
        psql -d postgres -c "SELECT extname, extversion FROM pg_extension WHERE extname = 'age';"
      when: stage2_nix and postgresql_major_version == "15"
      register: age_setup
      changed_when: "'CREATE EXTENSION' in age_setup.stdout"
      failed_when: age_setup.rc != 0
    
    # Be careful, if already created, this won't show.
    # Maybe check for 'LOAD' or 'SET' in stdout too, or ignore changed_when for this.

    - name: Setup and add extensions
      import_tasks: tasks/setup-extensions.yml
      when: stage2_nix

    - name: Check if PostgreSQL PID file exists
      stat:
        path: /var/lib/postgresql/data/postmaster.pid
      register: pg_pid_file
      when: stage2_nix

    - name: Stop Postgres Database without Systemd (force shutdown)
      become: yes
      become_user: postgres
      shell: /usr/lib/postgresql/bin/pg_ctl -D /var/lib/postgresql/data stop -m immediate
      args:
        executable: /bin/bash
      when: stage2_nix and pg_pid_file.stat.exists

    - name: Run unit tests
      import_tasks: tasks/test-image.yml
      tags:
        - unit-tests
      when: debpkg_mode or stage2_nix

    - name: Collect Postgres binaries
      import_tasks: tasks/internal/collect-pg-binaries.yml
      tags:
        - collect-binaries
      when: debpkg_mode

    - name: Install osquery from nixpkgs binary cache
      become: yes
      shell: |
        sudo -u ubuntu bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix profile install github:nixos/nixpkgs/f98ec4f73c762223d62bee706726138cb6ea27cc#osquery"
      when: stage2_nix

    - name: Pre-check before osquery - Verify system state  
      shell: |
        echo "=== Final System State Check ==="
        echo "User details:"
        id pgbouncer
        echo "\nGroup memberships:"
        for group in postgres ssl-cert pgbouncer; do
          echo "$group:" $(getent group $group)
        done
      register: final_system_check

    - name: Display final system state
      debug:
        var: final_system_check.stdout_lines

    - name: Ensure pgbouncer has correct group memberships
      fail:
        msg: "pgbouncer user is missing required group memberships"
      when: >
        final_system_check.stdout is not search('postgres') or
        final_system_check.stdout is not search('ssl-cert') or
        final_system_check.stdout is not search('pgbouncer')

    - name: Display final system state
      debug:
        var: final_system_check.stdout_lines

    - name: Ensure pgbouncer has correct group memberships
      fail:
        msg: "pgbouncer user is missing required group memberships"
      when: >
        final_system_check.stdout is not search('postgres') or
        final_system_check.stdout is not search('ssl-cert') or
        final_system_check.stdout is not search('pgbouncer')

    - name: Run osquery permission checks
      become: yes
      shell: |
        sudo -u ubuntu bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && /usr/bin/python3 /tmp/ansible-playbook/ansible/files/permission_check.py"
      when: stage2_nix

    - name: Remove osquery
      become: yes
      shell: |
        sudo -u ubuntu bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix profile remove osquery"
      when: stage2_nix

    - name: nix collect garbage
      become: yes
      shell: |
        sudo -u ubuntu bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix-collect-garbage -d"
      when: stage2_nix

'''

'''--- /Users/barneycook/Desktop/code/ProjectRef/postgres/scripts/nix-provision.sh ---
#!/usr/bin/env bash
# shellcheck shell=bash

# Enhanced error handling and logging
set -o errexit
set -o pipefail
set -o xtrace

# Set up logging to capture all output
exec 1> >(tee -a /tmp/nix-provision.log)
exec 2>&1

# Trap handler for cleanup and proper exit
cleanup() {
    local exit_code=$?
    echo "=== Script cleanup, exit code: $exit_code ==="
    
    # Ensure proper permissions
    if [ -d "/nix" ]; then
        sudo chown -R ubuntu:ubuntu /nix 2>/dev/null || true
    fi
    
    # Log final state
    echo "=== Final disk usage ==="
    df -h 2>/dev/null || true
    
    exit $exit_code
}
trap cleanup EXIT INT TERM

function install_packages {
    echo "=== Installing required packages ==="
    # Setup Ansible on host VM with better error handling
    sudo apt-get update && sudo apt-get install -y software-properties-common

    # Manually add GPG key with explicit keyserver and retry logic
    for i in {1..3}; do
        if sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 93C4A3FD7BB9C367; then
            break
        fi
        echo "GPG key retrieval attempt $i failed, retrying..."
        sleep 5
    done

    # Add repository and install with verification
    sudo add-apt-repository --yes ppa:ansible/ansible
    sudo apt-get update
    sudo apt-get install -y ansible

    # Verify ansible installation
    ansible --version || {
        echo "ERROR: Ansible installation failed"
        exit 1
    }

    ansible-galaxy collection install community.general
    echo "=== Package installation completed ==="
}

function install_nix() {
    echo "=== Installing Nix with enhanced error handling ==="
    
    # DEFINITIVE FIX: Verify 60GB volume is mounted at /nix (not /nix/store)
    if ! mountpoint -q /nix; then
        echo "ERROR: /nix not mounted properly"
        exit 1
    fi
    
    echo "Installing Nix with 60GB volume mounted at /nix"
    df -h /nix
    
    # Verify /nix/store exists on the mounted filesystem
    if [ ! -d "/nix/store" ]; then
        echo "WARNING: /nix/store directory not found, creating it"
        sudo mkdir -p /nix/store
        sudo chmod 1775 /nix/store
    fi
    
    # Install Nix with enhanced configuration and error handling
    echo "=== Starting Nix installation ==="
    if ! sudo su -c "curl --proto '=https' --tlsv1.2 -sSf -L https://install.determinate.systems/nix | sh -s -- install --no-confirm \
    --extra-conf \"substituters = https://cache.nixos.org https://nix-postgres-artifacts.s3.amazonaws.com\" \
    --extra-conf \"trusted-public-keys = nix-postgres-artifacts:dGZlQOvKcNEjvT7QEAJbcV6b6uk7VF/hWMjhYleiaLI=% cache.nixos.org-1:6NCHdD59X431o0gWypbMrAURkbJ16ZPMQFGspcDShjY=\" \
    --extra-conf \"max-jobs = 2\" \
    --extra-conf \"cores = 2\" \
    --extra-conf \"keep-outputs = false\" \
    --extra-conf \"keep-derivations = false\" \
    --extra-conf \"auto-optimise-store = true\"" -s /bin/bash root; then
        echo "ERROR: Nix installation failed"
        exit 1
    fi
    
    # ENHANCED: Source Nix environment with proper error handling and SIGPIPE prevention
    echo "=== Sourcing Nix environment ==="
    if [ -f "/nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh" ]; then
        # Use a more robust method to source the environment
        set +o pipefail  # Temporarily disable pipefail to prevent SIGPIPE issues
        source /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh 2>/dev/null || {
            echo "WARNING: Nix environment sourcing had minor issues, but continuing..."
            # Try alternative sourcing method
            . /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh || true
        }
        set -o pipefail  # Re-enable pipefail
    else
        echo "ERROR: Nix environment script not found"
        exit 1
    fi
    
    # Verify Nix installation with timeout
    echo "=== Nix Installation Verification ==="
    timeout 30 nix-store --version || {
        echo "ERROR: Nix verification failed"
        exit 1
    }
    
    # Check store accessibility (avoid SIGPIPE from head command)
    if ! ls -la /nix/store >/dev/null 2>&1; then
        echo "ERROR: Nix store not accessible"
        exit 1
    fi

    # Show store contents for verification (separate command to avoid pipeline issues)
    echo "=== Nix store contents (first 5 entries) ==="
    ls -la /nix/store 2>/dev/null | head -5 || echo "Could not list store contents"
        
        echo "=== Nix installation verification completed ==="
    }

function execute_stage2_playbook {
    echo "=== Executing Stage 2 Ansible Playbook ==="
    echo "POSTGRES_MAJOR_VERSION: ${POSTGRES_MAJOR_VERSION}"
    echo "GIT_SHA: ${GIT_SHA}"
    
    # Configure Ansible with better settings
    sudo tee /etc/ansible/ansible.cfg <<EOF
[defaults]
callbacks_enabled = timer, profile_tasks, profile_roles
timeout = 30
retry_files_enabled = False
host_key_checking = False
EOF

    # Modify playbook for localhost execution
    sed -i 's/- hosts: all/- hosts: localhost/' /tmp/ansible-playbook/ansible/playbook.yml

    # Set up environment for Ansible execution
    export ANSIBLE_LOG_PATH=/tmp/ansible.log
    export ANSIBLE_REMOTE_TEMP=/tmp
    export ANSIBLE_LOCAL_TEMP=/tmp
    
    # Execute playbook with enhanced error handling
    echo "=== Running Ansible playbook ==="
    if ! ansible-playbook /tmp/ansible-playbook/ansible/playbook.yml \
        --extra-vars '{"nixpkg_mode": false, "stage2_nix": true, "debpkg_mode": false}' \
        --extra-vars "git_commit_sha=${GIT_SHA}" \
        --extra-vars "psql_version=psql_${POSTGRES_MAJOR_VERSION}" \
        --extra-vars "postgresql_version=postgresql_${POSTGRES_MAJOR_VERSION}" \
        --extra-vars "nix_secret_key=${NIX_SECRET_KEY:-}" \
        --extra-vars "postgresql_major_version=${POSTGRES_MAJOR_VERSION}" \
        $ARGS; then
        echo "ERROR: Ansible playbook execution failed"
        echo "=== Ansible log tail ==="
        tail -50 /tmp/ansible.log 2>/dev/null || echo "No ansible log available"
        exit 1
    fi
    
    echo "=== Ansible playbook execution completed ==="
}

function cleanup_packages {
    echo "=== Cleaning up packages and artifacts ==="
    
    # Clean up Nix build artifacts with error handling
    echo "=== Cleaning up Nix build artifacts ==="
    set +o errexit  # Allow nix commands to fail gracefully
    
    if command -v nix-collect-garbage >/dev/null 2>&1; then
        nix-collect-garbage -d || {
            echo "WARNING: Nix garbage collection failed, continuing..."
        }
    fi
    
    set -o errexit  # Re-enable errexit
    
    # Show final disk usage
    echo "=== Final disk usage ==="
    df -h 2>/dev/null || true
    
    # Clean up Ansible
    sudo apt-get -y remove --purge ansible || {
        echo "WARNING: Ansible removal failed, continuing..."
    }
    sudo add-apt-repository --yes --remove ppa:ansible/ansible || {
        echo "WARNING: PPA removal failed, continuing..."
    }
    
    echo "=== Package cleanup completed ==="
}

function monitor_disk_usage {
    echo "=== Disk usage monitoring ==="
    df -h /nix 2>/dev/null || echo "Nix mount not accessible"
    df -h / 2>/dev/null || echo "Root filesystem not accessible"
    echo "=== Nix total size ==="
    du -sh /nix 2>/dev/null || echo "Nix mount not accessible"
}

# Main execution flow with comprehensive error handling
main() {
    echo "=== Starting Nix provisioning script ==="
    echo "=== Environment Variables ==="
    env | grep -E "(POSTGRES|GIT|NIX)" || echo "No relevant environment variables found"
    
    install_packages
    install_nix
    monitor_disk_usage
    execute_stage2_playbook
    monitor_disk_usage
    cleanup_packages
    
    echo "=== Nix provisioning script completed successfully ==="
}

# Execute main function
main "$@"


'''

{
  description = "Prototype tooling for deploying PostgreSQL";

  inputs = {
    nixpkgs.url = "github:nixos/nixpkgs/nixpkgs-unstable";
    flake-utils.url = "github:numtide/flake-utils";
    nix2container.url = "github:nlewo/nix2container";
    nix-editor.url = "github:snowfallorg/nix-editor";
    rust-overlay.url = "github:oxalica/rust-overlay";
  };

  outputs = { self, nixpkgs, flake-utils, nix-editor, rust-overlay, nix2container, ... }:
    let
      gitRev = "vcs=${self.shortRev or "dirty"}+${builtins.substring 0 8 (self.lastModifiedDate or self.lastModified or "19700101")}";

      ourSystems = with flake-utils.lib; [
        system.x86_64-linux
        system.aarch64-linux
        system.aarch64-darwin
      ];
    in
    flake-utils.lib.eachSystem ourSystems (system:
      let
        pgsqlDefaultPort = "5435";
        pgsqlDefaultHost = "localhost";
        pgsqlSuperuser = "capitala_admin";
  pkgs = import nixpkgs {
          config = {
            allowUnfree = true;
            permittedInsecurePackages = [
              "v8-9.7.106.18"
            ];
            # MINIMAL: Only disable docs globally, no complex overrides
            doCheck = false;
          };
          inherit system;
          overlays = [
            # Keep all existing overlays unchanged - don't modify anything here
            (final: prev: {
              xmrig = throw "The xmrig package has been explicitly disabled in this flake.";
            })
            (import rust-overlay)
            (final: prev: {
              cargo-pgrx = final.callPackage ./nix/cargo-pgrx/default.nix {
                inherit (final) lib;
                inherit (final) darwin;
                inherit (final) fetchCrate;
                inherit (final) openssl;
                inherit (final) pkg-config;
                inherit (final) makeRustPlatform;
                inherit (final) stdenv;
                inherit (final) rust-bin;
              };

              buildPgrxExtension = final.callPackage ./nix/cargo-pgrx/buildPgrxExtension.nix {
                inherit (final) cargo-pgrx;
                inherit (final) lib;
                inherit (final) Security;
                inherit (final) pkg-config;
                inherit (final) makeRustPlatform;
                inherit (final) stdenv;
                inherit (final) writeShellScriptBin;
              };

              buildPgrxExtension_0_11_3 = prev.buildPgrxExtension.override {
                cargo-pgrx = final.cargo-pgrx.cargo-pgrx_0_11_3;
              };

              buildPgrxExtension_0_12_6 = prev.buildPgrxExtension.override {
                cargo-pgrx = final.cargo-pgrx.cargo-pgrx_0_12_6;
              };

              buildPgrxExtension_0_12_9 = prev.buildPgrxExtension.override {
                cargo-pgrx = final.cargo-pgrx.cargo-pgrx_0_12_9;
              };

              buildPgrxExtension_0_14_3 = prev.buildPgrxExtension.override {
                cargo-pgrx = final.cargo-pgrx.cargo-pgrx_0_14_3;
              };

            })
            (final: prev: {
              postgresql = final.callPackage ./nix/postgresql/default.nix {
                inherit (final) lib stdenv fetchurl makeWrapper callPackage buildEnv newScope;
              };
            })
          ];
        };
        # Define pythonEnv here
        pythonEnv = pkgs.python3.withPackages (ps: with ps; [
          boto3
          docker
          pytest
          pytest-testinfra
          requests
          ec2instanceconnectcli
          paramiko
        ]);

        # Add this new definition
        nixFastBuild = pkgs.nix-fast-build or null;

        sfcgal = pkgs.callPackage ./nix/ext/sfcgal/sfcgal.nix { };
        supabase-groonga = pkgs.callPackage ./nix/supabase-groonga.nix { };
        mecab-naist-jdic = pkgs.callPackage ./nix/ext/mecab-naist-jdic/default.nix { };
        inherit (pkgs.callPackage ./nix/wal-g.nix { }) wal-g-2 wal-g-3;
        # Our list of PostgreSQL extensions which come from upstream Nixpkgs.
        # These are maintained upstream and can easily be used here just by
        # listing their name. Anytime the version of nixpkgs is upgraded, these
        # may also bring in new versions of the extensions.
        psqlExtensions = [
          /* pljava */
          /*"postgis"*/
        ];

        #FIXME for now, timescaledb is not included in the orioledb version of supabase extensions, as there is an issue
        # with building timescaledb with the orioledb patched version of postgresql
        orioledbPsqlExtensions = [
          /* pljava */
          /*"timescaledb"*/
        ];

        # Custom extensions that exist in our repository. These aren't upstream
        # either because nobody has done the work, maintaining them here is
        # easier and more expedient, or because they may not be suitable, or are
        # too niche/one-off.
        #
        # Ideally, most of these should have copies upstream for third party
        # use, but even if they did, keeping our own copies means that we can
        # rollout new versions of these critical things easier without having to
        # go through the upstream release engineering process.
 ourExtensions = [
          ./nix/ext/rum.nix
          ./nix/ext/timescaledb.nix
          ./nix/ext/timescaledb-2.9.1.nix
          ./nix/ext/pgroonga.nix
          ./nix/ext/index_advisor.nix
          ./nix/ext/wal2json.nix
          ./nix/ext/pgmq.nix
          ./nix/ext/pg_repack.nix
          ./nix/ext/pg-safeupdate.nix
          ./nix/ext/plpgsql-check.nix
          ./nix/ext/pgjwt.nix
          ./nix/ext/pgaudit.nix
          ./nix/ext/postgis.nix
          ./nix/ext/pgrouting.nix
          ./nix/ext/pgtap.nix
          ./nix/ext/pg_cron.nix
          ./nix/ext/pgsql-http.nix
          ./nix/ext/pg_plan_filter.nix
          ./nix/ext/pg_net.nix
          ./nix/ext/pg_hashids.nix
          ./nix/ext/pgsodium.nix
          ./nix/ext/pg_stat_monitor.nix
          ./nix/ext/pg_jsonschema.nix
          ./nix/ext/pgvector.nix
          ./nix/ext/vault.nix
          ./nix/ext/hypopg.nix
          ./nix/ext/pg_tle.nix
          ./nix/ext/supautils.nix
          ./nix/ext/plv8.nix
          ./nix/ext/age.nix   
          ./nix/ext/pg_backtrace.nix 
        ];

        # Extensions that cannot be cross-compiled (problematic for ARM64 builds)
        crossCompileBlacklist = [
          ./nix/ext/timescaledb.nix
          ./nix/ext/timescaledb-2.9.1.nix
          ./nix/ext/plv8.nix
          ./nix/ext/pgroonga.nix
        ];

        # Helper to check if we're cross-compiling
          isCrossCompiling = pkgs: pkgs.stdenv.buildPlatform != pkgs.stdenv.hostPlatform;

        # Add a helper to check build environment
        checkBuildEnvironment = pkgs.writeScriptBin "check-build-env" ''
          #!${pkgs.stdenv.shell}
          echo "Build Platform: ${pkgs.stdenv.buildPlatform.system}"
          echo "Host Platform: ${pkgs.stdenv.hostPlatform.system}"
          echo "Is Cross Compiling: ${if isCrossCompiling pkgs then "yes" else "no"}"
          echo "Has Remote Builders: $(if [ -f /etc/nix/builders ]; then echo yes; else echo no; fi)"
        '';

        #Where we import and build the orioledb extension, we add on our custom extensions
        # plus the orioledb option
        #we're not using timescaledb or plv8 in the orioledb-17 version or pg 17 of supabase extensions
        orioleFilteredExtensions = builtins.filter
          (
            x:
            x != ./nix/ext/timescaledb.nix &&
            x != ./nix/ext/timescaledb-2.9.1.nix &&
            x != ./nix/ext/plv8.nix &&
            x != ./nix/ext/age.nix &&
            x != ./nix/ext/pgroonga.nix
        ) ourExtensions;

        orioledbExtensions = orioleFilteredExtensions ++ [ ./nix/ext/orioledb.nix ];
        dbExtensions17 = builtins.filter
        (x:
          x != ./nix/ext/timescaledb.nix &&
          x != ./nix/ext/timescaledb-2.9.1.nix &&
          x != ./nix/ext/plv8.nix &&
          x != ./nix/ext/age.nix &&      
          x != ./nix/ext/pgroonga.nix
        ) ourExtensions;

        getPostgresqlPackage = version:
          pkgs.postgresql."postgresql_${version}";
        # Create a 'receipt' file for a given postgresql package. This is a way
        # of adding a bit of metadata to the package, which can be used by other
        # tools to inspect what the contents of the install are: the PSQL
        # version, the installed extensions, et cetera.
        #
        # This takes two arguments:
        #  - pgbin: the postgresql package we are building on top of
        #    not a list of packages, but an attrset containing extension names
        #    mapped to versions.
        #  - ourExts: the list of extensions from upstream nixpkgs. This is not
        #    a list of packages, but an attrset containing extension names
        #    mapped to versions.
        #
        # The output is a package containing the receipt.json file, which can be
        # merged with the PostgreSQL installation using 'symlinkJoin'.
        makeReceipt = pgbin: ourExts: pkgs.writeTextFile {
          name = "receipt";
          destination = "/receipt.json";
          text = builtins.toJSON {
            revision = gitRev;
            psql-version = pgbin.version;
            nixpkgs = {
              revision = nixpkgs.rev;
            };
            extensions = ourExts;

            # NOTE this field can be used to do cache busting (e.g.
            # force a rebuild of the psql packages) but also to helpfully inform
            # tools what version of the schema is being used, for forwards and
            # backwards compatibility
            receipt-version = "1";
          };
        };

        # Add this function to properly handle cross-compilation
        makeCrossAwarePostgresPkgs = version:
          let
            postgresql = getPostgresqlPackage version;
            
            # When cross-compiling, use the correct nixpkgs
            targetPkgs = if (pkgs.stdenv.buildPlatform != pkgs.stdenv.hostPlatform)
              then import nixpkgs {
                system = pkgs.stdenv.hostPlatform.system;
                crossSystem = pkgs.stdenv.hostPlatform;
              }
              else pkgs;
            
            extensionsToUse =
              if version == "15" then ourExtensions
              else if (builtins.elem version [ "orioledb-17" ]) then orioledbExtensions
              else if (builtins.elem version [ "17" ]) then dbExtensions17
              else ourExtensions;
            
            # Build with target packages
            buildExtension = path: targetPkgs.callPackage path { 
              inherit postgresql;
              stdenv = targetPkgs.stdenv;
            };
          in
          map buildExtension extensionsToUse;

# Fixed version of makeOurPostgresPkgs function (around line 190-220)
      makeOurPostgresPkgs = version:
        let
          postgresql = getPostgresqlPackage version;
          extensionsToUse =
            if version == "15" then ourExtensions  # AGE will be included for PG15
            else if (builtins.elem version [ "orioledb-17" ]) then orioledbExtensions
            else if (builtins.elem version [ "17" ]) then dbExtensions17
            else ourExtensions;
          
          # For ARM64 builds (both native and cross-compilation), filter more carefully
          safeExtensions = 
            if pkgs.stdenv.isAarch64 || isCrossCompiling pkgs
            then 
              if version == "15"
              then builtins.filter (ext: 
                # Keep AGE for PostgreSQL 15 even on ARM64
                ext == ./nix/ext/age.nix || 
                !(builtins.elem ext crossCompileBlacklist)
              ) extensionsToUse
              else builtins.filter (ext: !(builtins.elem ext crossCompileBlacklist)) extensionsToUse
            else extensionsToUse;
          
          # Build extensions with error handling
          buildExtension = path:
            let
              name = baseNameOf (toString path);
            in
            builtins.tryEval (pkgs.callPackage path { inherit postgresql; });
          
          # Build all extensions, filtering out failures
          builtExtensions = map buildExtension safeExtensions;
          successfulExtensions = builtins.filter (e: e.success) builtExtensions;
        in
        map (e: e.value) successfulExtensions;

        # Alternative implementation using Nix's tryEval (around line 230-270)
        makeOurPostgresPkgsRobust = version:
          let
            postgresql = getPostgresqlPackage version;
            extensionsToUse =
              if version == "15" then ourExtensions
              else if (builtins.elem version [ "orioledb-17" ]) then orioledbExtensions  
              else if (builtins.elem version [ "17" ]) then dbExtensions17
              else ourExtensions;
            
            # Filter based on system - now includes native ARM64 builds
            systemFilteredExtensions =
              if pkgs.stdenv.isAarch64 || isCrossCompiling pkgs
              then builtins.filter (ext: !(builtins.elem ext crossCompileBlacklist)) extensionsToUse
              else extensionsToUse;
            
            # Try to build each extension
            tryBuildExtension = path:
              let
                result = builtins.tryEval (pkgs.callPackage path { inherit postgresql; });
              in
              if result.success then result.value else null;
            
            # Build and filter
            builtExtensions = map tryBuildExtension systemFilteredExtensions;
            validExtensions = builtins.filter (ext: ext != null) builtExtensions;
          in
          validExtensions;

        # Update makePostgresBin to use the robust version
        makePostgresBin = version:
          let
            postgresql = getPostgresqlPackage version;
            
            # Use the robust version that handles failures
            ourExtsList = makeOurPostgresPkgsRobust version;
            ourExts = map (ext: { name = ext.pname or "unknown"; version = ext.version or "unknown"; }) ourExtsList;

            pgbin = postgresql.withPackages (ps: ourExtsList);
          in
          pkgs.symlinkJoin {
            inherit (pgbin) name version;
            paths = [ pgbin (makeReceipt pgbin ourExts) ];
            passthru = {
              inherit ourExtsList;
              exts = makeOurPostgresPkgsSet version;
            };
          };

        # Update the set builder for consistency
        makeOurPostgresPkgsSet = version:
          let
            extsList = makeOurPostgresPkgsRobust version;
            validExts = builtins.filter (drv: drv != null) extsList;
          in
          (builtins.listToAttrs (map
            (drv: { name = drv.pname; value = drv; })
            validExts))
          // { recurseForDerivations = true; };
        # Create an attribute set, containing all the relevant packages for a
        # PostgreSQL install, wrapped up with a bow on top. There are three
        # packages:
        #
        #  - bin: the postgresql package itself, with all the extensions
        #    installed, and a receipt.json file containing metadata about the
        #    install.
        #  - exts: an attrset containing all the extensions, mapped to their
        #    package names.
        makePostgres = version: rec {
          bin = makePostgresBin version;
          exts = makeOurPostgresPkgsSet version;
          recurseForDerivations = true;
        };

        makePostgresDevSetup = { pkgs, name, extraSubstitutions ? { } }:
          let
            paths = {
              migrationsDir = builtins.path {
                name = "migrations";
                path = ./migrations/db;
              };
              postgresqlSchemaSql = builtins.path {
                name = "postgresql-schema";
                path = ./nix/tools/postgresql_schema.sql;
              };
              pgbouncerAuthSchemaSql = builtins.path {
                name = "pgbouncer-auth-schema";
                path = ./ansible/files/pgbouncer_config/pgbouncer_auth_schema.sql;
              };
              statExtensionSql = builtins.path {
                name = "stat-extension";
                path = ./ansible/files/stat_extension.sql;
              };
              pgconfigFile = builtins.path {
                name = "postgresql.conf";
                path = ./ansible/files/postgresql_config/postgresql.conf.j2;
              };
              supautilsConfigFile = builtins.path {
                name = "supautils.conf";
                path = ./ansible/files/postgresql_config/supautils.conf.j2;
              };
              loggingConfigFile = builtins.path {
                name = "logging.conf";
                path = ./ansible/files/postgresql_config/postgresql-csvlog.conf;
              };
              readReplicaConfigFile = builtins.path {
                name = "readreplica.conf";
                path = ./ansible/files/postgresql_config/custom_read_replica.conf.j2;
              };
              pgHbaConfigFile = builtins.path {
                name = "pg_hba.conf";
                path = ./ansible/files/postgresql_config/pg_hba.conf.j2;
              };
              pgIdentConfigFile = builtins.path {
                name = "pg_ident.conf";
                path = ./ansible/files/postgresql_config/pg_ident.conf.j2;
              };
              postgresqlExtensionCustomScriptsPath = builtins.path {
                name = "extension-custom-scripts";
                path = ./ansible/files/postgresql_extension_custom_scripts;
              };
              getkeyScript = builtins.path {
                name = "pgsodium_getkey.sh";
                path = ./nix/tests/util/pgsodium_getkey.sh;
              };
            };

            localeArchive =
              if pkgs.stdenv.isDarwin
              then "${pkgs.darwin.locale}/share/locale"
              else "${pkgs.glibcLocales}/lib/locale/locale-archive";

            substitutions = {
              SHELL_PATH = "${pkgs.bash}/bin/bash";
              PGSQL_DEFAULT_PORT = "${pgsqlDefaultPort}";
              PGSQL_SUPERUSER = "${pgsqlSuperuser}";
              PSQL15_BINDIR = "${basePackages.psql_15.bin}";
              PSQL17_BINDIR = "${basePackages.psql_17.bin}";
              PSQL_CONF_FILE = "${paths.pgconfigFile}";
              PSQLORIOLEDB17_BINDIR = "${basePackages.psql_orioledb-17.bin}";
              PGSODIUM_GETKEY = "${paths.getkeyScript}";
              READREPL_CONF_FILE = "${paths.readReplicaConfigFile}";
              LOGGING_CONF_FILE = "${paths.loggingConfigFile}";
              SUPAUTILS_CONF_FILE = "${paths.supautilsConfigFile}";
              PG_HBA = "${paths.pgHbaConfigFile}";
              PG_IDENT = "${paths.pgIdentConfigFile}";
              LOCALES = "${localeArchive}";
              EXTENSION_CUSTOM_SCRIPTS_DIR = "${paths.postgresqlExtensionCustomScriptsPath}";
              MECAB_LIB = "${supabase-groonga}/lib/groonga/plugins/tokenizers/tokenizer_mecab.so";
              GROONGA_DIR = "${supabase-groonga}";
              MIGRATIONS_DIR = "${paths.migrationsDir}";
              POSTGRESQL_SCHEMA_SQL = "${paths.postgresqlSchemaSql}";
              PGBOUNCER_AUTH_SCHEMA_SQL = "${paths.pgbouncerAuthSchemaSql}";
              STAT_EXTENSION_SQL = "${paths.statExtensionSql}";
              CURRENT_SYSTEM = "${system}";
            } // extraSubstitutions; # Merge in any extra substitutions
          in
          pkgs.runCommand name
            {
              inherit (paths) migrationsDir postgresqlSchemaSql pgbouncerAuthSchemaSql statExtensionSql;
            } ''
            mkdir -p $out/bin $out/etc/postgresql-custom $out/etc/postgresql $out/extension-custom-scripts

            # Copy config files with error handling
            cp ${paths.supautilsConfigFile} $out/etc/postgresql-custom/supautils.conf || { echo "Failed to copy supautils.conf"; exit 1; }
            cp ${paths.pgconfigFile} $out/etc/postgresql/postgresql.conf || { echo "Failed to copy postgresql.conf"; exit 1; }
            cp ${paths.loggingConfigFile} $out/etc/postgresql-custom/logging.conf || { echo "Failed to copy logging.conf"; exit 1; }
            cp ${paths.readReplicaConfigFile} $out/etc/postgresql-custom/read-replica.conf || { echo "Failed to copy read-replica.conf"; exit 1; }
            cp ${paths.pgHbaConfigFile} $out/etc/postgresql/pg_hba.conf || { echo "Failed to copy pg_hba.conf"; exit 1; }
            cp ${paths.pgIdentConfigFile} $out/etc/postgresql/pg_ident.conf || { echo "Failed to copy pg_ident.conf"; exit 1; }
            cp -r ${paths.postgresqlExtensionCustomScriptsPath}/* $out/extension-custom-scripts/ || { echo "Failed to copy custom scripts"; exit 1; }

            echo "Copy operation completed"
            chmod 644 $out/etc/postgresql-custom/supautils.conf
            chmod 644 $out/etc/postgresql/postgresql.conf
            chmod 644 $out/etc/postgresql-custom/logging.conf
            chmod 644 $out/etc/postgresql/pg_hba.conf

            substitute ${./nix/tools/run-server.sh.in} $out/bin/start-postgres-server \
              ${builtins.concatStringsSep " " (builtins.attrValues (builtins.mapAttrs
                (name: value: "--subst-var-by '${name}' '${value}'")
                substitutions
              ))}
            chmod +x $out/bin/start-postgres-server
          '';

        # The base set of packages that we export from this Nix Flake, that can
        # be used with 'nix build'. Don't use the names listed below; check the
        # name in 'nix flake show' in order to make sure exactly what name you
        # want.
        basePackages =
          let
            # Function to get the PostgreSQL version from the attribute name
            getVersion = name:
              let
                match = builtins.match "psql_([0-9]+)" name;
              in
              if match == null then null else builtins.head match;

            # Define the available PostgreSQL versions
            postgresVersions = {
              psql_15 = makePostgres "15";
              psql_17 = makePostgres "17";
              psql_orioledb-17 = makePostgres "orioledb-17";
            };

            # Find the active PostgreSQL version
            activeVersion = getVersion (builtins.head (builtins.attrNames postgresVersions));

            # Function to create the pg_regress package
            makePgRegress = version:
              let
                postgresqlPackage = pkgs."postgresql_${version}";
              in
              pkgs.callPackage ./nix/ext/pg_regress.nix {
                postgresql = postgresqlPackage;
              };
            postgresql_15 = getPostgresqlPackage "15";
            postgresql_17 = getPostgresqlPackage "17";
            postgresql_orioledb-17 = getPostgresqlPackage "orioledb-17";
          in
          postgresVersions // {
            supabase-groonga = supabase-groonga;
            cargo-pgrx_0_11_3 = pkgs.cargo-pgrx.cargo-pgrx_0_11_3;
            cargo-pgrx_0_12_6 = pkgs.cargo-pgrx.cargo-pgrx_0_12_6;
            cargo-pgrx_0_12_9 = pkgs.cargo-pgrx.cargo-pgrx_0_12_9;
            cargo-pgrx_0_14_3 = pkgs.cargo-pgrx.cargo-pgrx_0_14_3;
            # PostgreSQL versions.
            psql_15 = postgresVersions.psql_15;
            psql_17 = postgresVersions.psql_17;
            psql_orioledb-17 = postgresVersions.psql_orioledb-17;
            wal-g-2 = wal-g-2;
            wal-g-3 = wal-g-3;
            sfcgal = sfcgal;
            pg_prove = pkgs.perlPackages.TAPParserSourceHandlerpgTAP;
            inherit postgresql_15 postgresql_17 postgresql_orioledb-17;
            postgresql_15_debug = if pkgs.stdenv.isLinux then postgresql_15.debug else null;
            postgresql_17_debug = if pkgs.stdenv.isLinux then postgresql_17.debug else null;
            postgresql_orioledb-17_debug = if pkgs.stdenv.isLinux then postgresql_orioledb-17.debug else null;
            postgresql_15_src = pkgs.stdenv.mkDerivation {
              pname = "postgresql-15-src";
              version = postgresql_15.version;

              src = postgresql_15.src;

              nativeBuildInputs = [ pkgs.bzip2 ];

              phases = [ "unpackPhase" "installPhase" ];

              installPhase = ''
                mkdir -p $out
                cp -r . $out
              '';

              meta = with pkgs.lib; {
                description = "PostgreSQL 15 source files";
                homepage = "https://www.postgresql.org/";
                license = licenses.postgresql;
                platforms = platforms.all;
              };
            };
            postgresql_17_src = pkgs.stdenv.mkDerivation {
              pname = "postgresql-17-src";
              version = postgresql_17.version;
              src = postgresql_17.src;

              nativeBuildInputs = [ pkgs.bzip2 ];

              phases = [ "unpackPhase" "installPhase" ];

              installPhase = ''
                mkdir -p $out
                cp -r . $out
              '';
              meta = with pkgs.lib; {
                description = "PostgreSQL 17 source files";
                homepage = "https://www.postgresql.org/";
                license = licenses.postgresql;
                platforms = platforms.all;
              };
            };
            postgresql_orioledb-17_src = pkgs.stdenv.mkDerivation {
              pname = "postgresql-17-src";
              version = postgresql_orioledb-17.version;

              src = postgresql_orioledb-17.src;

              nativeBuildInputs = [ pkgs.bzip2 ];

              phases = [ "unpackPhase" "installPhase" ];

              installPhase = ''
                mkdir -p $out
                cp -r . $out
              '';

              meta = with pkgs.lib; {
                description = "PostgreSQL 15 source files";
                homepage = "https://www.postgresql.org/";
                license = licenses.postgresql;
                platforms = platforms.all;
              };
            };
            mecab_naist_jdic = mecab-naist-jdic;
            supabase_groonga = supabase-groonga;
            pg_regress = makePgRegress activeVersion;
            # Start a version of the server.
            start-server = makePostgresDevSetup {
              inherit pkgs;
              name = "start-postgres-server";
            };

            # Start a version of the client and runs migrations script on server.
            start-client =
              let
                migrationsDir = ./migrations/db;
                postgresqlSchemaSql = ./nix/tools/postgresql_schema.sql;
                pgbouncerAuthSchemaSql = ./ansible/files/pgbouncer_config/pgbouncer_auth_schema.sql;
                statExtensionSql = ./ansible/files/stat_extension.sql;
              in
              pkgs.runCommand "start-postgres-client" { } ''
                mkdir -p $out/bin
                substitute ${./nix/tools/run-client.sh.in} $out/bin/start-postgres-client \
                  --subst-var-by 'PGSQL_DEFAULT_PORT' '${pgsqlDefaultPort}' \
                  --subst-var-by 'PGSQL_SUPERUSER' '${pgsqlSuperuser}' \
                  --subst-var-by 'PSQL15_BINDIR' '${basePackages.psql_15.bin}' \
                  --subst-var-by 'PSQL17_BINDIR' '${basePackages.psql_17.bin}' \
                  --subst-var-by 'PSQLORIOLEDB17_BINDIR' '${basePackages.psql_orioledb-17.bin}' \
                  --subst-var-by 'MIGRATIONS_DIR' '${migrationsDir}' \
                  --subst-var-by 'POSTGRESQL_SCHEMA_SQL' '${postgresqlSchemaSql}' \
                  --subst-var-by 'PGBOUNCER_AUTH_SCHEMA_SQL' '${pgbouncerAuthSchemaSql}' \
                  --subst-var-by 'STAT_EXTENSION_SQL' '${statExtensionSql}'
                chmod +x $out/bin/start-postgres-client
              '';

            # Migrate between two data directories.
            migrate-tool =
              let
                configFile = ./nix/tests/postgresql.conf.in;
                getkeyScript = ./nix/tests/util/pgsodium_getkey.sh;
                primingScript = ./nix/tests/prime.sql;
                migrationData = ./nix/tests/migrations/data.sql;
              in
              pkgs.runCommand "migrate-postgres" { } ''
                mkdir -p $out/bin
                substitute ${./nix/tools/migrate-tool.sh.in} $out/bin/migrate-postgres \
                  --subst-var-by 'PSQL15_BINDIR' '${basePackages.psql_15.bin}' \
                  --subst-var-by 'PSQL_CONF_FILE' '${configFile}' \
                  --subst-var-by 'PGSODIUM_GETKEY' '${getkeyScript}' \
                  --subst-var-by 'PRIMING_SCRIPT' '${primingScript}' \
                  --subst-var-by 'MIGRATION_DATA' '${migrationData}'

                chmod +x $out/bin/migrate-postgres
              '';

            start-replica = pkgs.runCommand "start-postgres-replica" { } ''
              mkdir -p $out/bin
              substitute ${./nix/tools/run-replica.sh.in} $out/bin/start-postgres-replica \
                --subst-var-by 'PGSQL_SUPERUSER' '${pgsqlSuperuser}' \
                --subst-var-by 'PSQL15_BINDIR' '${basePackages.psql_15.bin}'
              chmod +x $out/bin/start-postgres-replica
            '';
            pg-restore =
              pkgs.runCommand "run-pg-restore" { } ''
                mkdir -p $out/bin
                substitute ${./nix/tools/run-restore.sh.in} $out/bin/pg-restore \
                  --subst-var-by PSQL15_BINDIR '${basePackages.psql_15.bin}'
                chmod +x $out/bin/pg-restore
              '';
            sync-exts-versions = pkgs.runCommand "sync-exts-versions" { } ''
              mkdir -p $out/bin
              substitute ${./nix/tools/sync-exts-versions.sh.in} $out/bin/sync-exts-versions \
                --subst-var-by 'YQ' '${pkgs.yq}/bin/yq' \
                --subst-var-by 'JQ' '${pkgs.jq}/bin/jq' \
                --subst-var-by 'NIX_EDITOR' '${nix-editor.packages.${system}.nix-editor}/bin/nix-editor' \
                --subst-var-by 'NIXPREFETCHURL' '${pkgs.nixVersions.nix_2_20}/bin/nix-prefetch-url' \
                --subst-var-by 'NIX' '${pkgs.nixVersions.nix_2_20}/bin/nix'
              chmod +x $out/bin/sync-exts-versions
            '';

            local-infra-bootstrap = pkgs.runCommand "local-infra-bootstrap" { } ''
              mkdir -p $out/bin
              substitute ${./nix/tools/local-infra-bootstrap.sh.in} $out/bin/local-infra-bootstrap
              chmod +x $out/bin/local-infra-bootstrap
            '';
            dbmate-tool =
              let
                migrationsDir = ./migrations/db;
                ansibleVars = ./ansible/vars.yml;
                pgbouncerAuthSchemaSql = ./ansible/files/pgbouncer_config/pgbouncer_auth_schema.sql;
                statExtensionSql = ./ansible/files/stat_extension.sql;
              in
              pkgs.runCommand "dbmate-tool"
                {
                  buildInputs = with pkgs; [
                    overmind
                    dbmate
                    nix
                    jq
                    yq
                  ];
                  nativeBuildInputs = with pkgs; [
                    makeWrapper
                  ];
                } ''
                mkdir -p $out/bin $out/migrations
                cp -r ${migrationsDir}/* $out
                substitute ${./nix/tools/dbmate-tool.sh.in} $out/bin/dbmate-tool \
                  --subst-var-by 'PGSQL_DEFAULT_PORT' '${pgsqlDefaultPort}' \
                  --subst-var-by 'MIGRATIONS_DIR' $out \
                  --subst-var-by 'PGSQL_SUPERUSER' '${pgsqlSuperuser}' \
                  --subst-var-by 'ANSIBLE_VARS' ${ansibleVars} \
                  --subst-var-by 'CURRENT_SYSTEM' '${system}' \
                  --subst-var-by 'PGBOUNCER_AUTH_SCHEMA_SQL' '${pgbouncerAuthSchemaSql}' \
                  --subst-var-by 'STAT_EXTENSION_SQL' '${statExtensionSql}'
                chmod +x $out/bin/dbmate-tool
                wrapProgram $out/bin/dbmate-tool \
                  --prefix PATH : ${pkgs.lib.makeBinPath [ pkgs.overmind pkgs.dbmate pkgs.nix pkgs.jq pkgs.yq ]}
              '';
            show-commands = pkgs.runCommand "show-commands"
              {
                nativeBuildInputs = [ pkgs.makeWrapper ];
                buildInputs = [ pkgs.nushell ];
              } ''
              mkdir -p $out/bin
              cat > $out/bin/show-commands << 'EOF'
              #!${pkgs.nushell}/bin/nu
              let json_output = (nix flake show --json --quiet --all-systems | from json)
              let apps = ($json_output | get apps.${system})
              $apps | transpose name info | select name | each { |it| echo $"Run this app with: nix run .#($it.name)" }
              EOF
              chmod +x $out/bin/show-commands
              wrapProgram $out/bin/show-commands \
                --prefix PATH : ${pkgs.nushell}/bin
            '';
            update-readme = pkgs.runCommand "update-readme"
              {
                nativeBuildInputs = [ pkgs.makeWrapper ];
                buildInputs = [ pkgs.nushell ];
              } ''
              mkdir -p $out/bin
              cp ${./nix/tools/update_readme.nu} $out/bin/update-readme
              chmod +x $out/bin/update-readme
              wrapProgram $out/bin/update-readme \
                --prefix PATH : ${pkgs.nushell}/bin
            '';
            # Script to run the AMI build and tests locally
            build-test-ami = pkgs.runCommand "build-test-ami"
              {
                buildInputs = with pkgs; [
                  packer
                  awscli2
                  yq
                  jq
                  openssl
                  git
                  coreutils
                  aws-vault
                ];
              } ''
                mkdir -p $out/bin
                cat > $out/bin/build-test-ami << 'EOL'
                #!/usr/bin/env bash
                set -euo pipefail

                show_help() {
                  cat << EOF
                Usage: build-test-ami [--help] <postgres-version>

                Build AMI images for PostgreSQL testing.

                This script will:
                1. Check for required tools and AWS authentication
                2. Build two AMI stages using Packer
                3. Clean up any temporary instances
                4. Output the final AMI name for use with run-testinfra

                Arguments:
                  postgres-version    PostgreSQL major version to build (required)

                Options:
                  --help    Show this help message and exit

                Requirements:
                  - AWS Vault profile must be set in AWS_VAULT environment variable
                  - Packer, AWS CLI, yq, jq, and OpenSSL must be installed
                  - Must be run from a git repository

                Example:
                  aws-vault exec <profile-name> -- nix run .#build-test-ami 15
                EOF
                }

                # Handle help flag
                if [[ "$#" -gt 0 && "$1" == "--help" ]]; then
                  show_help
                  exit 0
                fi

                export PATH="${pkgs.lib.makeBinPath (with pkgs; [
                  packer
                  awscli2
                  yq
                  jq
                  openssl
                  git
                  coreutils
                  aws-vault
                ])}:$PATH"

                # Check for required tools
                for cmd in packer aws-vault yq jq openssl; do
                  if ! command -v $cmd &> /dev/null; then
                    echo "Error: $cmd is required but not found"
                    exit 1
                  fi
                done

                # Check AWS Vault profile
                if [ -z "''${AWS_VAULT:-}" ]; then
                  echo "Error: AWS_VAULT environment variable must be set with the profile name"
                  echo "Usage: aws-vault exec <profile-name> -- nix run .#build-test-ami <postgres-version>"
                  exit 1
                fi

                # Set values
                REGION="ap-southeast-1"
                POSTGRES_VERSION="$1"
                RANDOM_STRING=$(openssl rand -hex 8)
                GIT_SHA=$(git rev-parse HEAD)
                RUN_ID=$(date +%s)

                # Generate common-nix.vars.pkr.hcl
                PG_VERSION=$(yq -r ".postgres_release[\"postgres$POSTGRES_VERSION\"]" ansible/vars.yml)
                echo "postgres-version = \"$PG_VERSION\"" > common-nix.vars.pkr.hcl

                # Build AMI Stage 1
                packer init amazon-arm64-nix.pkr.hcl
                packer build \
                  -var "git-head-version=$GIT_SHA" \
                  -var "packer-execution-id=$RUN_ID" \
                  -var-file="development-arm.vars.pkr.hcl" \
                  -var-file="common-nix.vars.pkr.hcl" \
                  -var "ansible_arguments=" \
                  -var "postgres-version=$RANDOM_STRING" \
                  -var "region=$REGION" \
                  -var 'ami_regions=["'"$REGION"'"]' \
                  -var "force-deregister=true" \
                  -var "ansible_arguments=-e postgresql_major=$POSTGRES_VERSION" \
                  amazon-arm64-nix.pkr.hcl

                # Build AMI Stage 2
                packer init stage2-nix-psql.pkr.hcl
                packer build \
                  -var "git-head-version=$GIT_SHA" \
                  -var "packer-execution-id=$RUN_ID" \
                  -var "postgres_major_version=$POSTGRES_VERSION" \
                  -var-file="development-arm.vars.pkr.hcl" \
                  -var-file="common-nix.vars.pkr.hcl" \
                  -var "postgres-version=$RANDOM_STRING" \
                  -var "region=$REGION" \
                  -var 'ami_regions=["'"$REGION"'"]' \
                  -var "force-deregister=true" \
                  -var "git_sha=$GIT_SHA" \
                  stage2-nix-psql.pkr.hcl

                # Cleanup instances from AMI builds
                cleanup_instances() {
                  echo "Terminating EC2 instances with tag testinfra-run-id=$RUN_ID..."
                  aws ec2 --region $REGION describe-instances \
                    --filters "Name=tag:testinfra-run-id,Values=$RUN_ID" \
                    --query "Reservations[].Instances[].InstanceId" \
                    --output text | xargs -r aws ec2 terminate-instances \
                    --region $REGION --instance-ids || true
                }

                # Set up traps for various signals to ensure cleanup
                trap cleanup_instances EXIT HUP INT QUIT TERM

                # Create and activate virtual environment
                VENV_DIR=$(mktemp -d)
                trap 'rm -rf "$VENV_DIR"' EXIT HUP INT QUIT TERM
                python3 -m venv "$VENV_DIR"
                source "$VENV_DIR/bin/activate"

                # Install required Python packages
                echo "Installing required Python packages..."
                pip install boto3 boto3-stubs[essential] docker ec2instanceconnectcli pytest paramiko requests

                # Run the tests with aws-vault
                echo "Running tests for AMI: $RANDOM_STRING using AWS Vault profile: $AWS_VAULT_PROFILE"
                aws-vault exec $AWS_VAULT_PROFILE -- pytest -vv -s testinfra/test_ami_nix.py

                # Deactivate virtual environment (cleanup is handled by trap)
                deactivate
                EOL
                chmod +x $out/bin/build-test-ami
              '';

            run-testinfra = pkgs.runCommand "run-testinfra"
              {
                buildInputs = with pkgs; [
                  aws-vault
                  python3
                  python3Packages.pip
                  coreutils
                ];
              } ''
                mkdir -p $out/bin
                cat > $out/bin/run-testinfra << 'EOL'
                #!/usr/bin/env bash
                set -euo pipefail

                show_help() {
                  cat << EOF
                Usage: run-testinfra --ami-name NAME [--aws-vault-profile PROFILE]

                Run the testinfra tests locally against a specific AMI.

                This script will:
                1. Check if aws-vault is installed and configured
                2. Set up the required environment variables
                3. Create and activate a virtual environment
                4. Install required Python packages from pip
                5. Run the tests with aws-vault credentials
                6. Clean up the virtual environment

                Required flags:
                  --ami-name NAME              The name of the AMI to test

                Optional flags:
                  --aws-vault-profile PROFILE  AWS Vault profile to use (default: staging)
                  --help                       Show this help message and exit

                Requirements:
                  - aws-vault installed and configured
                  - Python 3 with pip
                  - Must be run from the repository root

                Examples:
                  run-testinfra --ami-name supabase-postgres-abc123
                  run-testinfra --ami-name supabase-postgres-abc123 --aws-vault-profile production
                EOF
                }

                # Default values
                AWS_VAULT_PROFILE="staging"
                AMI_NAME=""

                # Parse arguments
                while [[ $# -gt 0 ]]; do
                  case $1 in
                    --aws-vault-profile)
                      AWS_VAULT_PROFILE="$2"
                      shift 2
                      ;;
                    --ami-name)
                      AMI_NAME="$2"
                      shift 2
                      ;;
                    --help)
                      show_help
                      exit 0
                      ;;
                    *)
                      echo "Error: Unexpected argument: $1"
                      show_help
                      exit 1
                      ;;
                  esac
                done

                # Check for required tools
                if ! command -v aws-vault &> /dev/null; then
                  echo "Error: aws-vault is required but not found"
                  exit 1
                fi

                # Check for AMI name argument
                if [ -z "$AMI_NAME" ]; then
                  echo "Error: --ami-name is required"
                  show_help
                  exit 1
                fi

                # Set environment variables
                export AWS_REGION="ap-southeast-1"
                export AWS_DEFAULT_REGION="ap-southeast-1"
                export AMI_NAME="$AMI_NAME"  # Export AMI_NAME for pytest
                export RUN_ID="local-$(date +%s)"  # Generate a unique RUN_ID

                # Function to terminate EC2 instances
                terminate_instances() {
                  echo "Terminating EC2 instances with tag testinfra-run-id=$RUN_ID..."
                  aws-vault exec $AWS_VAULT_PROFILE -- aws ec2 --region ap-southeast-1 describe-instances \
                    --filters "Name=tag:testinfra-run-id,Values=$RUN_ID" \
                    --query "Reservations[].Instances[].InstanceId" \
                    --output text | xargs -r aws-vault exec $AWS_VAULT_PROFILE -- aws ec2 terminate-instances \
                    --region ap-southeast-1 --instance-ids || true
                }

                # Set up traps for various signals to ensure cleanup
                trap terminate_instances EXIT HUP INT QUIT TERM

                # Create and activate virtual environment
                VENV_DIR=$(mktemp -d)
                trap 'rm -rf "$VENV_DIR"' EXIT HUP INT QUIT TERM
                python3 -m venv "$VENV_DIR"
                source "$VENV_DIR/bin/activate"

                # Install required Python packages
                echo "Installing required Python packages..."
                pip install boto3 boto3-stubs[essential] docker ec2instanceconnectcli pytest paramiko requests

                # Function to run tests and ensure cleanup
                run_tests() {
                  local exit_code=0
                  echo "Running tests for AMI: $AMI_NAME using AWS Vault profile: $AWS_VAULT_PROFILE"
                  aws-vault exec "$AWS_VAULT_PROFILE" -- pytest -vv -s testinfra/test_ami_nix.py || exit_code=$?
                  return $exit_code
                }

                # Run tests and capture exit code
                run_tests
                test_exit_code=$?

                # Deactivate virtual environment
                deactivate

                # Explicitly call cleanup
                terminate_instances

                # Exit with the test exit code
                exit $test_exit_code
                EOL
                chmod +x $out/bin/run-testinfra
              '';

            cleanup-ami = pkgs.runCommand "cleanup-ami"
              {
                buildInputs = with pkgs; [
                  awscli2
                  aws-vault
                ];
              } ''
                mkdir -p $out/bin
                cat > $out/bin/cleanup-ami << 'EOL'
                #!/usr/bin/env bash
                set -euo pipefail

                export PATH="${pkgs.lib.makeBinPath (with pkgs; [
                  awscli2
                  aws-vault
                ])}:$PATH"

                # Check for required tools
                for cmd in aws-vault; do
                  if ! command -v $cmd &> /dev/null; then
                    echo "Error: $cmd is required but not found"
                    exit 1
                  fi
                done

                # Check AWS Vault profile
                if [ -z "''${AWS_VAULT:-}" ]; then
                  echo "Error: AWS_VAULT environment variable must be set with the profile name"
                  echo "Usage: aws-vault exec <profile-name> -- nix run .#cleanup-ami <ami-name>"
                  exit 1
                fi

                # Check for AMI name argument
                if [ -z "''${1:-}" ]; then
                  echo "Error: AMI name must be provided"
                  echo "Usage: aws-vault exec <profile-name> -- nix run .#cleanup-ami <ami-name>"
                  exit 1
                fi

                AMI_NAME="$1"
                REGION="ap-southeast-1"

                # Deregister AMIs
                for AMI_PATTERN in "supabase-postgres-ci-ami-test-stage-1" "$AMI_NAME"; do
                  aws ec2 describe-images --region $REGION --owners self \
                    --filters "Name=name,Values=$AMI_PATTERN" \
                    --query 'Images[*].ImageId' --output text | while read -r ami_id; do
                      echo "Deregistering AMI: $ami_id"
                      aws ec2 deregister-image --region $REGION --image-id "$ami_id" || true
                    done
                done
                EOL
                chmod +x $out/bin/cleanup-ami
              '';

            trigger-nix-build = pkgs.runCommand "trigger-nix-build"
              {
                buildInputs = with pkgs; [
                  gh
                  git
                  coreutils
                ];
              } ''
                mkdir -p $out/bin
                cat > $out/bin/trigger-nix-build << 'EOL'
                #!/usr/bin/env bash
                set -euo pipefail

                show_help() {
                  cat << EOF
                Usage: trigger-nix-build [--help]

                Trigger the nix-build workflow for the current branch and watch its progress.

                This script will:
                1. Check if you're authenticated with GitHub
                2. Get the current branch and commit
                3. Verify you're on a standard branch (develop or release/*) or prompt for confirmation
                4. Trigger the nix-build workflow
                5. Watch the workflow progress until completion

                Options:
                  --help    Show this help message and exit

                Requirements:
                  - GitHub CLI (gh) installed and authenticated
                  - Git installed
                  - Must be run from a git repository

                Example:
                  trigger-nix-build
                EOF
                }

                # Handle help flag
                if [[ "$#" -gt 0 && "$1" == "--help" ]]; then
                  show_help
                  exit 0
                fi

                export PATH="${pkgs.lib.makeBinPath (with pkgs; [
                  gh
                  git
                  coreutils
                ])}:$PATH"

                # Check for required tools
                for cmd in gh git; do
                  if ! command -v $cmd &> /dev/null; then
                    echo "Error: $cmd is required but not found"
                    exit 1
                  fi
                done

                # Check if user is authenticated with GitHub
                if ! gh auth status &>/dev/null; then
                  echo "Error: Not authenticated with GitHub. Please run 'gh auth login' first."
                  exit 1
                fi

                # Get current branch and commit
                BRANCH=$(git rev-parse --abbrev-ref HEAD)
                COMMIT=$(git rev-parse HEAD)

                # Check if we're on a standard branch
                if [[ "$BRANCH" != "develop" && ! "$BRANCH" =~ ^release/ ]]; then
                  echo "Warning: Running workflow from non-standard branch: $BRANCH"
                  echo "This is supported for testing purposes."
                  read -p "Continue? [y/N] " -n 1 -r
                  echo
                  if [[ ! $REPLY =~ ^[Yy]$ ]]; then
                    echo "Aborted."
                    exit 1
                  fi
                fi

                # Trigger the workflow
                echo "Triggering nix-build workflow for branch $BRANCH (commit: $COMMIT)"
                gh workflow run nix-build.yml --ref "$BRANCH"

                # Wait for workflow to start and get the run ID
                echo "Waiting for workflow to start..."
                sleep 5

                # Get the latest run ID for this workflow
                RUN_ID=$(gh run list --workflow=nix-build.yml --limit 1 --json databaseId --jq '.[0].databaseId')

                if [ -z "$RUN_ID" ]; then
                  echo "Error: Could not find workflow run ID"
                  exit 1
                fi

                echo "Watching workflow run $RUN_ID..."
                echo "The script will automatically exit when the workflow completes."
                echo "Press Ctrl+C to stop watching (workflow will continue running)"
                echo "----------------------------------------"

                # Try to watch the run, but handle network errors gracefully
                while true; do
                  if gh run watch "$RUN_ID" --exit-status; then
                    break
                  else
                    echo "Network error while watching workflow. Retrying in 5 seconds..."
                    echo "You can also check the status manually with: gh run view $RUN_ID"
                    sleep 5
                  fi
                done
                EOL
                chmod +x $out/bin/trigger-nix-build
              '';
          };


        # Create a testing harness for a PostgreSQL package. This is used for
        # 'nix flake check', and works with any PostgreSQL package you hand it.

        makeCheckHarness = pgpkg:
          let
            sqlTests = ./nix/tests/smoke;
            pg_prove = pkgs.perlPackages.TAPParserSourceHandlerpgTAP;
            pg_regress = basePackages.pg_regress;
            getkey-script = pkgs.stdenv.mkDerivation {
              name = "pgsodium-getkey";
              buildCommand = ''
                mkdir -p $out/bin
                cat > $out/bin/pgsodium-getkey << 'EOF'
                #!${pkgs.bash}/bin/bash
                set -euo pipefail

                TMPDIR_BASE=$(mktemp -d)

                KEY_DIR="''${PGSODIUM_KEY_DIR:-$TMPDIR_BASE/pgsodium}"
                KEY_FILE="$KEY_DIR/pgsodium.key"

                if ! mkdir -p "$KEY_DIR" 2>/dev/null; then
                  echo "Error: Could not create key directory $KEY_DIR" >&2
                  exit 1
                fi
                chmod 1777 "$KEY_DIR"

                if [[ ! -f "$KEY_FILE" ]]; then
                  if ! (dd if=/dev/urandom bs=32 count=1 2>/dev/null | od -A n -t x1 | tr -d ' \n' > "$KEY_FILE"); then
                    if ! (openssl rand -hex 32 > "$KEY_FILE"); then
                      echo "00000000000000000000000000000000" > "$KEY_FILE"
                      echo "Warning: Using fallback key" >&2
                    fi
                  fi
                  chmod 644 "$KEY_FILE"
                fi

                if [[ -f "$KEY_FILE" && -r "$KEY_FILE" ]]; then
                  cat "$KEY_FILE"
                else
                  echo "Error: Cannot read key file $KEY_FILE" >&2
                  exit 1
                fi
                EOF
                chmod +x $out/bin/pgsodium-getkey
              '';
            };

            # Use the shared setup but with a test-specific name
            start-postgres-server-bin = makePostgresDevSetup {
              inherit pkgs;
              name = "start-postgres-server-test";
              extraSubstitutions = {
                PGSODIUM_GETKEY = "${getkey-script}/bin/pgsodium-getkey";
                PGSQL_DEFAULT_PORT = pgPort;
              };
            };

            getVersionArg = pkg:
              let
                name = pkg.version;
              in
              if builtins.match "15.*" name != null then "15"
              else if builtins.match "17.*" name != null then "17"
              else if builtins.match "orioledb-17.*" name != null then "orioledb-17"
              else throw "Unsupported PostgreSQL version: ${name}";

            # Helper function to filter SQL files based on version
            filterTestFiles = version: dir:
              let
                files = builtins.readDir dir;
                isValidFile = name:
                  let
                    isVersionSpecific = builtins.match "z_.*" name != null;
                    matchesVersion =
                      if isVersionSpecific
                      then
                        if version == "orioledb-17"
                        then builtins.match "z_orioledb-17_.*" name != null
                        else if version == "17"
                        then builtins.match "z_17_.*" name != null
                        else builtins.match "z_15_.*" name != null
                      else true;
                  in
                  pkgs.lib.hasSuffix ".sql" name && matchesVersion;
              in
              pkgs.lib.filterAttrs (name: _: isValidFile name) files;

            # Get the major version for filtering
            majorVersion =
              let
                version = builtins.trace "pgpkg.version is: ${pgpkg.version}" pgpkg.version;
                _ = builtins.trace "Entering majorVersion logic";
                isOrioledbMatch = builtins.match "^17_[0-9]+$" version != null;
                isSeventeenMatch = builtins.match "^17[.][0-9]+$" version != null;
                result =
                  if isOrioledbMatch
                  then "orioledb-17"
                  else if isSeventeenMatch
                  then "17"
                  else "15";
              in
              builtins.trace "Major version result: ${result}" result; # Trace the result                                             # For "15.8"

            # Filter SQL test files
            filteredSqlTests = filterTestFiles majorVersion ./nix/tests/sql;

            pgPort = if (majorVersion == "17") then
                "5535"
                else if (majorVersion == "15") then
                "5536"
                else "5537";

            # Convert filtered tests to a sorted list of basenames (without extension)
            testList = pkgs.lib.mapAttrsToList
              (name: _:
                builtins.substring 0 (pkgs.lib.stringLength name - 4) name
              )
              filteredSqlTests;
            sortedTestList = builtins.sort (a: b: a < b) testList;

          in
          pkgs.runCommand "postgres-${pgpkg.version}-check-harness"
            {
              nativeBuildInputs = with pkgs; [
                coreutils
                bash
                perl
                pgpkg
                pg_prove
                pg_regress
                procps
                start-postgres-server-bin
                which
                getkey-script
                supabase-groonga
              ];
            } ''
            set -e

            #First we need to create a generic pg cluster for pgtap tests and run those
            export GRN_PLUGINS_DIR=${supabase-groonga}/lib/groonga/plugins
            PGTAP_CLUSTER=$(mktemp -d)
            initdb --locale=C --username=capitala_admin -D "$PGTAP_CLUSTER"
            substitute ${./nix/tests/postgresql.conf.in} "$PGTAP_CLUSTER"/postgresql.conf \
              --subst-var-by PGSODIUM_GETKEY_SCRIPT "${getkey-script}/bin/pgsodium-getkey"
            echo "listen_addresses = '*'" >> "$PGTAP_CLUSTER"/postgresql.conf
            echo "port = ${pgPort}" >> "$PGTAP_CLUSTER"/postgresql.conf
            echo "host all all 127.0.0.1/32 trust" >> $PGTAP_CLUSTER/pg_hba.conf
            echo "Checking shared_preload_libraries setting:"
            grep -rn "shared_preload_libraries" "$PGTAP_CLUSTER"/postgresql.conf
            # Remove timescaledb if running orioledb-17 check
            echo "I AM ${pgpkg.version}===================================================="
            if [[ "${pgpkg.version}" == *"17"* ]]; then
              perl -pi -e 's/ timescaledb,//g' "$PGTAP_CLUSTER/postgresql.conf"
            fi
            #NOTE in the future we may also need to add the orioledb extension to the cluster when cluster is oriole
            echo "PGTAP_CLUSTER directory contents:"
            ls -la "$PGTAP_CLUSTER"

            # Check if postgresql.conf exists
            if [ ! -f "$PGTAP_CLUSTER/postgresql.conf" ]; then
                echo "postgresql.conf is missing!"
                exit 1
            fi

            # PostgreSQL startup
            if [[ "$(uname)" == "Darwin" ]]; then
            pg_ctl -D "$PGTAP_CLUSTER" -l "$PGTAP_CLUSTER"/postgresql.log -o "-k "$PGTAP_CLUSTER" -p ${pgPort} -d 5" start 2>&1
            else
            mkdir -p "$PGTAP_CLUSTER/sockets"
            pg_ctl -D "$PGTAP_CLUSTER" -l "$PGTAP_CLUSTER"/postgresql.log -o "-k $PGTAP_CLUSTER/sockets -p ${pgPort} -d 5" start 2>&1
            fi || {
            echo "pg_ctl failed to start PostgreSQL"
            echo "Contents of postgresql.log:"
            cat "$PGTAP_CLUSTER"/postgresql.log
            exit 1
            }
            for i in {1..60}; do
              if pg_isready -h ${pgsqlDefaultHost} -p ${pgPort}; then
                echo "PostgreSQL is ready"
                break
              fi
              sleep 1
              if [ $i -eq 60 ]; then
                echo "PostgreSQL is not ready after 60 seconds"
                echo "PostgreSQL status:"
                pg_ctl -D "$PGTAP_CLUSTER" status
                echo "PostgreSQL log content:"
                cat "$PGTAP_CLUSTER"/postgresql.log
                exit 1
              fi
            done
            createdb -p ${pgPort} -h ${pgsqlDefaultHost} --username=capitala_admin testing
            if ! psql -p ${pgPort} -h ${pgsqlDefaultHost} --username=capitala_admin -d testing -v ON_ERROR_STOP=1 -Xf ${./nix/tests/prime.sql}; then
              echo "Error executing SQL file. PostgreSQL log content:"
              cat "$PGTAP_CLUSTER"/postgresql.log
              pg_ctl -D "$PGTAP_CLUSTER" stop
              exit 1
            fi
            SORTED_DIR=$(mktemp -d)
            for t in $(printf "%s\n" ${builtins.concatStringsSep " " sortedTestList}); do
              psql -p ${pgPort} -h ${pgsqlDefaultHost} --username=capitala_admin -d testing -f "${./nix/tests/sql}/$t.sql" || true
            done
            rm -rf "$SORTED_DIR"
            pg_ctl -D "$PGTAP_CLUSTER" stop
            rm -rf $PGTAP_CLUSTER

            # End of pgtap tests
            # from here on out we are running pg_regress tests, we use a different cluster for this
            # which is start by the start-postgres-server-bin script
            # start-postgres-server-bin script closely matches our AMI setup, configurations and migrations

            unset GRN_PLUGINS_DIR
            ${start-postgres-server-bin}/bin/start-postgres-server ${getVersionArg pgpkg} --daemonize

            for i in {1..60}; do
                if pg_isready -h ${pgsqlDefaultHost} -p ${pgPort} -U capitala_admin -q; then
                    echo "PostgreSQL is ready"
                    break
                fi
                sleep 1
                if [ $i -eq 60 ]; then
                    echo "PostgreSQL failed to start"
                    exit 1
                fi
            done

            if ! psql -p ${pgPort} -h ${pgsqlDefaultHost} --no-password --username=capitala_admin -d postgres -v ON_ERROR_STOP=1 -Xf ${./nix/tests/prime.sql}; then
              echo "Error executing SQL file"
              exit 1
            fi

            mkdir -p $out/regression_output
            if ! pg_regress \
              --use-existing \
              --dbname=postgres \
              --inputdir=${./nix/tests} \
              --outputdir=$out/regression_output \
              --host=${pgsqlDefaultHost} \
              --port=${pgPort} \
              --user=capitala_admin \
              ${builtins.concatStringsSep " " sortedTestList}; then
              echo "pg_regress tests failed"
              cat $out/regression_output/regression.diffs
              exit 1
            fi

            echo "Running migrations tests"
            pg_prove -p ${pgPort} -U capitala_admin -h ${pgsqlDefaultHost} -d postgres -v ${./migrations/tests}/test.sql

            # Copy logs to output
            for logfile in $(find /tmp -name postgresql.log -type f); do
              cp "$logfile" $out/postgresql.log
            done
            exit 0
          '';
      in
      rec {
        # The list of all packages that can be built with 'nix build'. The list
        # of names that can be used can be shown with 'nix flake show'
        packages = flake-utils.lib.flattenTree basePackages // {
          # Any extra packages we might want to include in our package
          # set can go here.
          inherit (pkgs);
        };

        # The list of exported 'checks' that are run with every run of 'nix
        # flake check'. This is run in the CI system, as well.
        checks = {
          psql_15 = makeCheckHarness basePackages.psql_15.bin;
          psql_17 = makeCheckHarness basePackages.psql_17.bin;
          psql_orioledb-17 = makeCheckHarness basePackages.psql_orioledb-17.bin;
          inherit (basePackages) wal-g-2 wal-g-3 dbmate-tool pg_regress;
        } // pkgs.lib.optionalAttrs (system == "aarch64-linux") {
          inherit (basePackages) postgresql_15_debug postgresql_15_src postgresql_orioledb-17_debug postgresql_orioledb-17_src postgresql_17_debug postgresql_17_src;
        };

        # Apps is a list of names of things that can be executed with 'nix run';
        # these are distinct from the things that can be built with 'nix build',
        # so they need to be listed here too.
        apps =
          let
            mkApp = attrName: binName: {
              type = "app";
              program = "${basePackages."${attrName}"}/bin/${binName}";
            };
          in
          {
            start-server = mkApp "start-server" "start-postgres-server";
            start-client = mkApp "start-client" "start-postgres-client";
            start-replica = mkApp "start-replica" "start-postgres-replica";
            # migrate-postgres = mkApp "migrate-tool" "migrate-postgres";
            # sync-exts-versions = mkApp "sync-exts-versions" "sync-exts-versions";
            pg-restore = mkApp "pg-restore" "pg-restore";
            local-infra-bootstrap = mkApp "local-infra-bootstrap" "local-infra-bootstrap";
            dbmate-tool = mkApp "dbmate-tool" "dbmate-tool";
            update-readme = mkApp "update-readme" "update-readme";
            show-commands = mkApp "show-commands" "show-commands";
            build-test-ami = mkApp "build-test-ami" "build-test-ami";
            run-testinfra = mkApp "run-testinfra" "run-testinfra";
            cleanup-ami = mkApp "cleanup-ami" "cleanup-ami";
            trigger-nix-build = mkApp "trigger-nix-build" "trigger-nix-build";
          };

        # 'devShells.default' lists the set of packages that are included in the
        # ambient $PATH environment when you run 'nix develop'. This is useful
        # for development and puts many convenient devtools instantly within
        # reach.

        devShells =
          let
            mkCargoPgrxDevShell = { pgrxVersion, rustVersion }: pkgs.mkShell {
              packages = with pkgs; [
                basePackages."cargo-pgrx_${pgrxVersion}"
                (rust-bin.stable.${rustVersion}.default.override {
                  extensions = [ "rust-src" ];
                })
              ];
              shellHook = ''
                export HISTFILE=.history
              '';
            };
          in
          {
            default = pkgs.mkShell {
              packages = with pkgs; [
                coreutils
                just
                nix-update
                #pg_prove
                shellcheck
                ansible
                ansible-lint
                (packer.overrideAttrs (oldAttrs: {
                  version = "1.7.8";
                }))

                basePackages.start-server
                basePackages.start-client
                basePackages.start-replica
                basePackages.migrate-tool
                basePackages.sync-exts-versions
                basePackages.build-test-ami
                basePackages.run-testinfra
                basePackages.cleanup-ami
                dbmate
                nushell
                pythonEnv
                ] ++ pkgs.lib.optionals (nixFastBuild != null) [
                nixFastBuild
                ];
              shellHook = ''
                export HISTFILE=.history
              '';
            };
            cargo-pgrx_0_11_3 = mkCargoPgrxDevShell {
              pgrxVersion = "0_11_3";
              rustVersion = "1.80.0";
            };
            cargo-pgrx_0_12_6 = mkCargoPgrxDevShell {
              pgrxVersion = "0_12_6";
              rustVersion = "1.80.0";
            };
          };
      }
    );
}


