The below represents the folders and files from the root paths:
- /Users/barneycook/Desktop/code/ProjectRef/postgres/amazon-arm64-nix.pkr.hcl
- /Users/barneycook/Desktop/code/ProjectRef/postgres/ansible/files/postgresql_config/pg_hba.conf.j2
- /Users/barneycook/Desktop/code/ProjectRef/postgres/ansible/files/postgresql_config/postgresql.conf.j2
- /Users/barneycook/Desktop/code/ProjectRef/postgres/ansible/files/postgresql_config/postgresql.service.j2
- /Users/barneycook/Desktop/code/ProjectRef/postgres/ansible/playbook.yml
- /Users/barneycook/Desktop/code/ProjectRef/postgres/ansible/tasks/setup-postgres.yml
- /Users/barneycook/Desktop/code/ProjectRef/postgres/ansible/tasks/stage2-setup-postgres.yml
- /Users/barneycook/Desktop/code/ProjectRef/postgres/flake.nix
- /Users/barneycook/Desktop/code/ProjectRef/postgres/nix/init.sh
- /Users/barneycook/Desktop/code/ProjectRef/postgres/stage2-nix-psql.pkr.hcl

Each file is separated by '''--- followed by the file path and ending with ---.
File content begins immediately after its path and extends until the next '''---


*File: amazon-arm64-nix.pkr.hcl*
Words: 614


*File: stage2-nix-psql.pkr.hcl*
Words: 535


*File: flake.nix*
Words: 5655


*File: init.sh*
Words: 60


*File: playbook.yml*
Words: 2092


*File: setup-postgres.yml*
Words: 1799


*File: stage2-setup-postgres.yml*
Words: 3238


*File: postgresql.conf.j2*
Words: 3660


*File: postgresql.service.j2*
Words: 39


*File: pg_hba.conf.j2*
Words: 697

'''--- /Users/barneycook/Desktop/code/ProjectRef/postgres/amazon-arm64-nix.pkr.hcl ---
variable "ami" {
  type    = string
  default = "ubuntu/images/hvm-ssd/ubuntu-focal-20.04-arm64-server-*"
}

variable "profile" {
  type    = string
  default = "${env("AWS_PROFILE")}"
}

variable "ami_name" {
  type    = string
  default = "capitala-project-ami"
}

variable "ami_regions" {
  type    = list(string)
  default = ["ap-southeast-2"]
}

variable "ansible_arguments" {
  type    = string
  default = "--skip-tags install-postgrest,install-pgbouncer,install-supabase-internal"
}

variable "aws_access_key" {
  type    = string
  default = ""
}

variable "aws_secret_key" {
  type    = string
  default = ""
}

variable "environment" {
  type    = string
  default = "prod"
}

variable "region" {
  type    = string
}

variable "build-vol" {
  type    = string
  default = "xvdc"
}

# ccache docker image details
variable "docker_user" {
  type    = string
  default = ""
}

variable "docker_passwd" {
  type    = string
  default = ""
}

variable "docker_image" {
  type    = string
  default = ""
}

variable "docker_image_tag" {
  type    = string
  default = "latest"
}

locals {
  creator = "packer"
}

variable "postgres-version" {
  type = string
  default = ""
}

variable "git-head-version" {
  type = string
  default = "unknown"
}

variable "packer-execution-id" {
  type = string
  default = "unknown"
}

variable "force-deregister" {
  type    = bool
  default = false
}

packer {
  required_plugins {
    amazon = {
      source  = "github.com/hashicorp/amazon"
      version = "~> 1"
    }
  }
}

# source block
source "amazon-ebssurrogate" "source" {
  profile = "${var.profile}"
  #access_key    = "${var.aws_access_key}"
  #ami_name = "${var.ami_name}-arm64-${formatdate("YYYY-MM-DD-hhmm", timestamp())}"
  ami_name = "${var.ami_name}-${var.postgres-version}-stage-1"
  ami_virtualization_type = "hvm"
  ami_architecture = "arm64"
  ami_regions   = "${var.ami_regions}"
  instance_type = "c6g.xlarge"
  region       = "${var.region}"
  #secret_key   = "${var.aws_secret_key}"
  force_deregister = var.force-deregister

  # Use latest official ubuntu focal ami owned by Canonical.
  source_ami_filter {
    filters = {
      virtualization-type = "hvm"
      name = "${var.ami}"
      root-device-type = "ebs"
    }
    owners = [ "099720109477" ]
    most_recent = true
   }
  ena_support = true
  launch_block_device_mappings {
    device_name = "/dev/xvdf"
    delete_on_termination = true
    volume_size = 10
    volume_type = "gp3"
   }

  launch_block_device_mappings {
    device_name = "/dev/xvdh"
    delete_on_termination = true
    volume_size = 8
    volume_type = "gp3"
   }

  launch_block_device_mappings {
    device_name           = "/dev/${var.build-vol}"
    delete_on_termination = true
    volume_size           = 16
    volume_type           = "gp2"
    omit_from_artifact    = true
  }

  run_tags = {
    creator           = "packer"
    appType           = "postgres"
    packerExecutionId = "${var.packer-execution-id}"
  }
  run_volume_tags = {
    creator = "packer"
    appType = "postgres"
  }
  snapshot_tags = {
    creator = "packer"
    appType = "postgres"
  }
  tags = {
    creator = "packer"
    appType = "postgres"
    postgresVersion = "${var.postgres-version}-stage1"
    sourceSha = "${var.git-head-version}"
  }

  communicator = "ssh"
  ssh_pty = true
  ssh_username = "ubuntu"
  ssh_timeout = "5m"

  ami_root_device {
    source_device_name = "/dev/xvdf"
    device_name = "/dev/xvda"
    delete_on_termination = true
    volume_size = 10
    volume_type = "gp2"
  }

  associate_public_ip_address = true
}

# a build block invokes sources and runs provisioning steps on them.
build {
  sources = ["source.amazon-ebssurrogate.source"]

  provisioner "file" {
    source = "ebssurrogate/files/sources-arm64.cfg"
    destination = "/tmp/sources.list"
  }

  provisioner "file" {
    source = "ebssurrogate/files/ebsnvme-id"
    destination = "/tmp/ebsnvme-id"
  }

  provisioner "file" {
    source = "ebssurrogate/files/70-ec2-nvme-devices.rules"
    destination = "/tmp/70-ec2-nvme-devices.rules"
  }

  provisioner "file" {
    source = "ebssurrogate/scripts/chroot-bootstrap-nix.sh"
    destination = "/tmp/chroot-bootstrap-nix.sh"
  }

  provisioner "file" {
    source = "ebssurrogate/files/cloud.cfg"
    destination = "/tmp/cloud.cfg"
  }

  provisioner "file" {
    source = "ebssurrogate/files/vector.timer"
    destination = "/tmp/vector.timer"
  }

  provisioner "file" {
    source = "ebssurrogate/files/apparmor_profiles"
    destination = "/tmp"
  }

  provisioner "file" {
    source = "migrations"
    destination = "/tmp"
  }

  provisioner "file" {
    source = "ebssurrogate/files/unit-tests"
    destination = "/tmp"
  }

  # Copy ansible playbook
  provisioner "shell" {
    inline = ["mkdir /tmp/ansible-playbook"]
  }

  provisioner "file" {
    source = "ansible"
    destination = "/tmp/ansible-playbook"
  }

  provisioner "file" {
    source = "scripts"
    destination = "/tmp/ansible-playbook"
  }

  provisioner "file" {
    source = "ansible/vars.yml"
    destination = "/tmp/ansible-playbook/vars.yml"
  }

  provisioner "shell" {
    environment_vars = [
      "ARGS=${var.ansible_arguments}",
      "DOCKER_USER=${var.docker_user}",
      "DOCKER_PASSWD=${var.docker_passwd}",
      "DOCKER_IMAGE=${var.docker_image}",
      "DOCKER_IMAGE_TAG=${var.docker_image_tag}",
      "POSTGRES_SUPABASE_VERSION=${var.postgres-version}"
    ]
    use_env_var_file = true
    script = "ebssurrogate/scripts/surrogate-bootstrap-nix.sh"
    execute_command = "sudo -S sh -c '. {{.EnvVarFile}} && {{.Path}}'"
    start_retry_timeout = "5m"
    skip_clean = true
  }

  provisioner "file" {
    source = "/tmp/ansible.log"
    destination = "/tmp/ansible.log"
    direction = "download"
  }
}

'''

'''--- /Users/barneycook/Desktop/code/ProjectRef/postgres/stage2-nix-psql.pkr.hcl ---
variable "profile" {
  type    = string
  default = "${env("AWS_PROFILE")}"
}

variable "ami_regions" {
  type    = list(string)
  default = ["ap-southeast-2"]
}

variable "environment" {
  type    = string
  default = "prod"
}

variable "region" {
  type    = string
}

variable "ami_name" {
  type    = string
  default = "capitala-postgres"
}

variable "postgres-version" {
  type    = string
  default = ""
}

variable "git-head-version" {
  type    = string
  default = "unknown"
}

variable "postgres_major_version" {
  type    = string
  default = "15"
}

variable "git_commit_sha" {
  type    = string
  default = "local"
}

variable "packer-execution-id" {
  type    = string
  default = "unknown"
}

variable "force-deregister" {
  type    = bool
  default = false
}

variable "git_sha" {
  type    = string
  default = env("GIT_SHA")
}

packer {
  required_plugins {
    amazon = {
      version = ">= 0.0.2"
      source  = "github.com/hashicorp/amazon"
    }
  }
}

source "amazon-ebs" "ubuntu" {
  ami_name      = "${var.ami_name}-${var.postgres-version}"
  instance_type = "c6g.xlarge"
  region        = "${var.region}"
  source_ami_filter {
    filters = {
      name                = "${var.ami_name}-${var.postgres-version}-stage-1"
      root-device-type    = "ebs"
      virtualization-type = "hvm"
    }
    most_recent = true
    owners      = ["amazon", "self"]
  }
  
  communicator = "ssh"
  ssh_pty = true
  ssh_username = "ubuntu"
  ssh_timeout = "15m"
  
  associate_public_ip_address = true
  ena_support = true

  # Root volume - keep existing size
  launch_block_device_mappings {
    device_name           = "/dev/sda1"
    volume_type           = "gp3"
    volume_size           = 20
    delete_on_termination = true
  }
  
  # CRITICAL: 60GB volume for Nix store
  launch_block_device_mappings {
    device_name           = "/dev/sdf"
    volume_type           = "gp3"
    volume_size           = 60
    delete_on_termination = true
  }
  
  run_tags = {
    creator           = "packer"
    appType           = "postgres"
    packerExecutionId = "${var.packer-execution-id}"
  }
  run_volume_tags = {
    creator = "packer"
    appType = "postgres"
  }
  snapshot_tags = {
    creator = "packer"
    appType = "postgres"
  }
  tags = {
    creator = "packer"
    appType = "postgres"
    postgresVersion = "${var.postgres-version}"
    sourceSha = "${var.git-head-version}"
  }
}

build {
  name = "nix-packer-ubuntu"
  sources = [
    "source.amazon-ebs.ubuntu"
  ]

  provisioner "shell" {
    inline = [
      "echo '=== DEFINITIVE FIX: Mount 60GB volume at /nix instead of /nix/store ==='",
      "sudo mkdir -p /nix",
      "sudo mkfs.ext4 -F /dev/nvme2n1",
      "sudo mount /dev/nvme2n1 /nix", 
      "sudo chmod 1775 /nix",
      "sudo mkdir -p /nix/store",
      "sudo chmod 1775 /nix/store",
      "echo '60GB volume mounted at /nix (includes store)'",
      "df -h | grep nvme",
      # Test filesystem operations
      "echo 'test' | sudo tee /tmp/test-file",
      "sudo mkdir -p /nix/test-temp-dir",
      "sudo mv /tmp/test-file /nix/test-temp-dir/",
      "sudo mkdir -p /nix/store/test-final",
      "sudo mv /nix/test-temp-dir/test-file /nix/store/test-final/",
      "sudo rm -rf /nix/test-temp-dir /nix/store/test-final",
      "echo 'Filesystem move test passed'",
      # Prepare directories
      "mkdir -p /tmp/ansible-playbook",
      "rm -rf /tmp/ansible-playbook/nix",
      "mkdir -p /tmp/nix-build"
    ]
  }

  provisioner "file" {
    source = "ansible"
    destination = "/tmp/ansible-playbook"
  }

  provisioner "file" {
    source = "migrations"
    destination = "/tmp"
  }

  provisioner "file" {
    source = "ebssurrogate/files/unit-tests"
    destination = "/tmp/unit-tests"
  }

  provisioner "file" {
    source = "scripts"
    destination = "/tmp/ansible-playbook"
  }

  provisioner "file" {
    source = "flake.nix"
    destination = "/tmp/ansible-playbook/flake.nix"
  }

  provisioner "file" {
    source = "flake.lock"
    destination = "/tmp/ansible-playbook/flake.lock"
  }

  provisioner "shell" {
  inline = [
    "mkdir -p /tmp/ansible-playbook/nix"
  ]
  }

  provisioner "file" {
    source = "nix/"
    destination = "/tmp/ansible-playbook/nix/"
  }
  
  # FIXED: Enhanced script provisioner with proper exit code handling
  provisioner "shell" {
    environment_vars = [
      "GIT_SHA=${var.git_commit_sha}",
      "POSTGRES_MAJOR_VERSION=${var.postgres_major_version}",
      "NIX_BUILD_CORES=2",
      "_NIX_FORCE_HTTP_BINARY_CACHE_UPDATE=1" 
    ]
    script           = "scripts/nix-provision.sh"
    expect_disconnect = true
    # CRITICAL FIX: Added exit code 141 (SIGPIPE) to valid exit codes
    valid_exit_codes  = [0, 2, 141, 2300218]
    # Additional safeguards
    pause_before      = "5s"
    timeout          = "20m"
  }
}
  

'''

'''--- /Users/barneycook/Desktop/code/ProjectRef/postgres/flake.nix ---
{
  description = "Prototype tooling for deploying PostgreSQL";

  inputs = {
    nixpkgs.url = "github:nixos/nixpkgs/nixpkgs-unstable";
    flake-utils.url = "github:numtide/flake-utils";
    nix2container.url = "github:nlewo/nix2container";
    nix-editor.url = "github:snowfallorg/nix-editor";
    rust-overlay.url = "github:oxalica/rust-overlay";
  };

  outputs = { self, nixpkgs, flake-utils, nix-editor, rust-overlay, nix2container, ... }:
    let
      gitRev = "vcs=${self.shortRev or "dirty"}+${builtins.substring 0 8 (self.lastModifiedDate or self.lastModified or "19700101")}";

      ourSystems = with flake-utils.lib; [
        system.x86_64-linux
        system.aarch64-linux
        system.aarch64-darwin
      ];
    in
    flake-utils.lib.eachSystem ourSystems (system:
      let
        pgsqlDefaultPort = "5435";
        pgsqlDefaultHost = "localhost";
        pgsqlSuperuser = "capitala_admin";
  pkgs = import nixpkgs {
          config = {
            allowUnfree = true;
            permittedInsecurePackages = [
              "v8-9.7.106.18"
            ];
            # MINIMAL: Only disable docs globally, no complex overrides
            doCheck = false;
          };
          inherit system;
          overlays = [
            # Keep all existing overlays unchanged - don't modify anything here
            (final: prev: {
              xmrig = throw "The xmrig package has been explicitly disabled in this flake.";
            })
            (import rust-overlay)
            (final: prev: {
              cargo-pgrx = final.callPackage ./nix/cargo-pgrx/default.nix {
                inherit (final) lib;
                inherit (final) darwin;
                inherit (final) fetchCrate;
                inherit (final) openssl;
                inherit (final) pkg-config;
                inherit (final) makeRustPlatform;
                inherit (final) stdenv;
                inherit (final) rust-bin;
              };

              buildPgrxExtension = final.callPackage ./nix/cargo-pgrx/buildPgrxExtension.nix {
                inherit (final) cargo-pgrx;
                inherit (final) lib;
                inherit (final) Security;
                inherit (final) pkg-config;
                inherit (final) makeRustPlatform;
                inherit (final) stdenv;
                inherit (final) writeShellScriptBin;
              };

              buildPgrxExtension_0_11_3 = prev.buildPgrxExtension.override {
                cargo-pgrx = final.cargo-pgrx.cargo-pgrx_0_11_3;
              };

              buildPgrxExtension_0_12_6 = prev.buildPgrxExtension.override {
                cargo-pgrx = final.cargo-pgrx.cargo-pgrx_0_12_6;
              };

              buildPgrxExtension_0_12_9 = prev.buildPgrxExtension.override {
                cargo-pgrx = final.cargo-pgrx.cargo-pgrx_0_12_9;
              };

              buildPgrxExtension_0_14_3 = prev.buildPgrxExtension.override {
                cargo-pgrx = final.cargo-pgrx.cargo-pgrx_0_14_3;
              };

            })
            (final: prev: {
              postgresql = final.callPackage ./nix/postgresql/default.nix {
                inherit (final) lib stdenv fetchurl makeWrapper callPackage buildEnv newScope;
              };
            })
          ];
        };
        # Define pythonEnv here
        pythonEnv = pkgs.python3.withPackages (ps: with ps; [
          boto3
          docker
          pytest
          pytest-testinfra
          requests
          ec2instanceconnectcli
          paramiko
        ]);

        # Add this new definition
        nixFastBuild = pkgs.nix-fast-build or null;

        sfcgal = pkgs.callPackage ./nix/ext/sfcgal/sfcgal.nix { };
        supabase-groonga = pkgs.callPackage ./nix/supabase-groonga.nix { };
        mecab-naist-jdic = pkgs.callPackage ./nix/ext/mecab-naist-jdic/default.nix { };
        inherit (pkgs.callPackage ./nix/wal-g.nix { }) wal-g-2 wal-g-3;
        # Our list of PostgreSQL extensions which come from upstream Nixpkgs.
        # These are maintained upstream and can easily be used here just by
        # listing their name. Anytime the version of nixpkgs is upgraded, these
        # may also bring in new versions of the extensions.
        psqlExtensions = [
          /* pljava */
          /*"postgis"*/
        ];

        #FIXME for now, timescaledb is not included in the orioledb version of supabase extensions, as there is an issue
        # with building timescaledb with the orioledb patched version of postgresql
        orioledbPsqlExtensions = [
          /* pljava */
          /*"timescaledb"*/
        ];

        # Custom extensions that exist in our repository. These aren't upstream
        # either because nobody has done the work, maintaining them here is
        # easier and more expedient, or because they may not be suitable, or are
        # too niche/one-off.
        #
        # Ideally, most of these should have copies upstream for third party
        # use, but even if they did, keeping our own copies means that we can
        # rollout new versions of these critical things easier without having to
        # go through the upstream release engineering process.
 ourExtensions = [
          ./nix/ext/rum.nix
          ./nix/ext/timescaledb.nix
          ./nix/ext/timescaledb-2.9.1.nix
          ./nix/ext/pgroonga.nix
          ./nix/ext/index_advisor.nix
          ./nix/ext/wal2json.nix
          ./nix/ext/pgmq.nix
          ./nix/ext/pg_repack.nix
          ./nix/ext/pg-safeupdate.nix
          ./nix/ext/plpgsql-check.nix
          ./nix/ext/pgjwt.nix
          ./nix/ext/pgaudit.nix
          ./nix/ext/postgis.nix
          ./nix/ext/pgrouting.nix
          ./nix/ext/pgtap.nix
          ./nix/ext/pg_cron.nix
          ./nix/ext/pgsql-http.nix
          ./nix/ext/pg_plan_filter.nix
          ./nix/ext/pg_net.nix
          ./nix/ext/pg_hashids.nix
          ./nix/ext/pgsodium.nix
          ./nix/ext/pg_stat_monitor.nix
          ./nix/ext/pg_jsonschema.nix
          ./nix/ext/pgvector.nix
          ./nix/ext/vault.nix
          ./nix/ext/hypopg.nix
          ./nix/ext/pg_tle.nix
          ./nix/ext/supautils.nix
          ./nix/ext/plv8.nix
          ./nix/ext/age.nix   
          ./nix/ext/pg_backtrace.nix 
        ];

        # Extensions that cannot be cross-compiled (problematic for ARM64 builds)
        crossCompileBlacklist = [
          ./nix/ext/timescaledb.nix
          ./nix/ext/timescaledb-2.9.1.nix
          ./nix/ext/plv8.nix
          ./nix/ext/pgroonga.nix
        ];

        # Helper to check if we're cross-compiling
          isCrossCompiling = pkgs: pkgs.stdenv.buildPlatform != pkgs.stdenv.hostPlatform;

        # Add a helper to check build environment
        checkBuildEnvironment = pkgs.writeScriptBin "check-build-env" ''
          #!${pkgs.stdenv.shell}
          echo "Build Platform: ${pkgs.stdenv.buildPlatform.system}"
          echo "Host Platform: ${pkgs.stdenv.hostPlatform.system}"
          echo "Is Cross Compiling: ${if isCrossCompiling pkgs then "yes" else "no"}"
          echo "Has Remote Builders: $(if [ -f /etc/nix/builders ]; then echo yes; else echo no; fi)"
        '';

        #Where we import and build the orioledb extension, we add on our custom extensions
        # plus the orioledb option
        #we're not using timescaledb or plv8 in the orioledb-17 version or pg 17 of supabase extensions
        orioleFilteredExtensions = builtins.filter
          (
            x:
            x != ./nix/ext/timescaledb.nix &&
            x != ./nix/ext/timescaledb-2.9.1.nix &&
            x != ./nix/ext/plv8.nix &&
            x != ./nix/ext/age.nix &&
            x != ./nix/ext/pgroonga.nix
        ) ourExtensions;

        orioledbExtensions = orioleFilteredExtensions ++ [ ./nix/ext/orioledb.nix ];
        dbExtensions17 = builtins.filter
        (x:
          x != ./nix/ext/timescaledb.nix &&
          x != ./nix/ext/timescaledb-2.9.1.nix &&
          x != ./nix/ext/plv8.nix &&
          x != ./nix/ext/age.nix &&      
          x != ./nix/ext/pgroonga.nix
        ) ourExtensions;

        getPostgresqlPackage = version:
          pkgs.postgresql."postgresql_${version}";
        # Create a 'receipt' file for a given postgresql package. This is a way
        # of adding a bit of metadata to the package, which can be used by other
        # tools to inspect what the contents of the install are: the PSQL
        # version, the installed extensions, et cetera.
        #
        # This takes two arguments:
        #  - pgbin: the postgresql package we are building on top of
        #    not a list of packages, but an attrset containing extension names
        #    mapped to versions.
        #  - ourExts: the list of extensions from upstream nixpkgs. This is not
        #    a list of packages, but an attrset containing extension names
        #    mapped to versions.
        #
        # The output is a package containing the receipt.json file, which can be
        # merged with the PostgreSQL installation using 'symlinkJoin'.
        makeReceipt = pgbin: ourExts: pkgs.writeTextFile {
          name = "receipt";
          destination = "/receipt.json";
          text = builtins.toJSON {
            revision = gitRev;
            psql-version = pgbin.version;
            nixpkgs = {
              revision = nixpkgs.rev;
            };
            extensions = ourExts;

            # NOTE this field can be used to do cache busting (e.g.
            # force a rebuild of the psql packages) but also to helpfully inform
            # tools what version of the schema is being used, for forwards and
            # backwards compatibility
            receipt-version = "1";
          };
        };

        # Add this function to properly handle cross-compilation
        makeCrossAwarePostgresPkgs = version:
          let
            postgresql = getPostgresqlPackage version;
            
            # When cross-compiling, use the correct nixpkgs
            targetPkgs = if (pkgs.stdenv.buildPlatform != pkgs.stdenv.hostPlatform)
              then import nixpkgs {
                system = pkgs.stdenv.hostPlatform.system;
                crossSystem = pkgs.stdenv.hostPlatform;
              }
              else pkgs;
            
            extensionsToUse =
              if version == "15" then ourExtensions
              else if (builtins.elem version [ "orioledb-17" ]) then orioledbExtensions
              else if (builtins.elem version [ "17" ]) then dbExtensions17
              else ourExtensions;
            
            # Build with target packages
            buildExtension = path: targetPkgs.callPackage path { 
              inherit postgresql;
              stdenv = targetPkgs.stdenv;
            };
          in
          map buildExtension extensionsToUse;

# Fixed version of makeOurPostgresPkgs function (around line 190-220)
      makeOurPostgresPkgs = version:
        let
          postgresql = getPostgresqlPackage version;
          extensionsToUse =
            if version == "15" then ourExtensions  # AGE will be included for PG15
            else if (builtins.elem version [ "orioledb-17" ]) then orioledbExtensions
            else if (builtins.elem version [ "17" ]) then dbExtensions17
            else ourExtensions;
          
          # For ARM64 builds (both native and cross-compilation), filter more carefully
          safeExtensions = 
            if pkgs.stdenv.isAarch64 || isCrossCompiling pkgs
            then 
              if version == "15"
              then builtins.filter (ext: 
                # Keep AGE for PostgreSQL 15 even on ARM64
                ext == ./nix/ext/age.nix || 
                !(builtins.elem ext crossCompileBlacklist)
              ) extensionsToUse
              else builtins.filter (ext: !(builtins.elem ext crossCompileBlacklist)) extensionsToUse
            else extensionsToUse;
          
          # Build extensions with error handling
          buildExtension = path:
            let
              name = baseNameOf (toString path);
            in
            builtins.tryEval (pkgs.callPackage path { inherit postgresql; });
          
          # Build all extensions, filtering out failures
          builtExtensions = map buildExtension safeExtensions;
          successfulExtensions = builtins.filter (e: e.success) builtExtensions;
        in
        map (e: e.value) successfulExtensions;

        # Alternative implementation using Nix's tryEval (around line 230-270)
        makeOurPostgresPkgsRobust = version:
          let
            postgresql = getPostgresqlPackage version;
            extensionsToUse =
              if version == "15" then ourExtensions
              else if (builtins.elem version [ "orioledb-17" ]) then orioledbExtensions  
              else if (builtins.elem version [ "17" ]) then dbExtensions17
              else ourExtensions;
            
            # Filter based on system - now includes native ARM64 builds
            systemFilteredExtensions =
              if pkgs.stdenv.isAarch64 || isCrossCompiling pkgs
              then builtins.filter (ext: !(builtins.elem ext crossCompileBlacklist)) extensionsToUse
              else extensionsToUse;
            
            # Try to build each extension
            tryBuildExtension = path:
              let
                result = builtins.tryEval (pkgs.callPackage path { inherit postgresql; });
              in
              if result.success then result.value else null;
            
            # Build and filter
            builtExtensions = map tryBuildExtension systemFilteredExtensions;
            validExtensions = builtins.filter (ext: ext != null) builtExtensions;
          in
          validExtensions;

        # Update makePostgresBin to use the robust version
        makePostgresBin = version:
          let
            postgresql = getPostgresqlPackage version;
            
            # Use the robust version that handles failures
            ourExtsList = makeOurPostgresPkgsRobust version;
            ourExts = map (ext: { name = ext.pname or "unknown"; version = ext.version or "unknown"; }) ourExtsList;

            pgbin = postgresql.withPackages (ps: ourExtsList);
          in
          pkgs.symlinkJoin {
            inherit (pgbin) name version;
            paths = [ pgbin (makeReceipt pgbin ourExts) ];
            passthru = {
              inherit ourExtsList;
              exts = makeOurPostgresPkgsSet version;
            };
          };

        # Update the set builder for consistency
        makeOurPostgresPkgsSet = version:
          let
            extsList = makeOurPostgresPkgsRobust version;
            validExts = builtins.filter (drv: drv != null) extsList;
          in
          (builtins.listToAttrs (map
            (drv: { name = drv.pname; value = drv; })
            validExts))
          // { recurseForDerivations = true; };
        # Create an attribute set, containing all the relevant packages for a
        # PostgreSQL install, wrapped up with a bow on top. There are three
        # packages:
        #
        #  - bin: the postgresql package itself, with all the extensions
        #    installed, and a receipt.json file containing metadata about the
        #    install.
        #  - exts: an attrset containing all the extensions, mapped to their
        #    package names.
        makePostgres = version: rec {
          bin = makePostgresBin version;
          exts = makeOurPostgresPkgsSet version;
          recurseForDerivations = true;
        };

        makePostgresDevSetup = { pkgs, name, extraSubstitutions ? { } }:
          let
            paths = {
              migrationsDir = builtins.path {
                name = "migrations";
                path = ./migrations/db;
              };
              postgresqlSchemaSql = builtins.path {
                name = "postgresql-schema";
                path = ./nix/tools/postgresql_schema.sql;
              };
              pgbouncerAuthSchemaSql = builtins.path {
                name = "pgbouncer-auth-schema";
                path = ./ansible/files/pgbouncer_config/pgbouncer_auth_schema.sql;
              };
              statExtensionSql = builtins.path {
                name = "stat-extension";
                path = ./ansible/files/stat_extension.sql;
              };
              pgconfigFile = builtins.path {
                name = "postgresql.conf";
                path = ./ansible/files/postgresql_config/postgresql.conf.j2;
              };
              supautilsConfigFile = builtins.path {
                name = "supautils.conf";
                path = ./ansible/files/postgresql_config/supautils.conf.j2;
              };
              loggingConfigFile = builtins.path {
                name = "logging.conf";
                path = ./ansible/files/postgresql_config/postgresql-csvlog.conf;
              };
              readReplicaConfigFile = builtins.path {
                name = "readreplica.conf";
                path = ./ansible/files/postgresql_config/custom_read_replica.conf.j2;
              };
              pgHbaConfigFile = builtins.path {
                name = "pg_hba.conf";
                path = ./ansible/files/postgresql_config/pg_hba.conf.j2;
              };
              pgIdentConfigFile = builtins.path {
                name = "pg_ident.conf";
                path = ./ansible/files/postgresql_config/pg_ident.conf.j2;
              };
              postgresqlExtensionCustomScriptsPath = builtins.path {
                name = "extension-custom-scripts";
                path = ./ansible/files/postgresql_extension_custom_scripts;
              };
              getkeyScript = builtins.path {
                name = "pgsodium_getkey.sh";
                path = ./nix/tests/util/pgsodium_getkey.sh;
              };
            };

            localeArchive =
              if pkgs.stdenv.isDarwin
              then "${pkgs.darwin.locale}/share/locale"
              else "${pkgs.glibcLocales}/lib/locale/locale-archive";

            substitutions = {
              SHELL_PATH = "${pkgs.bash}/bin/bash";
              PGSQL_DEFAULT_PORT = "${pgsqlDefaultPort}";
              PGSQL_SUPERUSER = "${pgsqlSuperuser}";
              PSQL15_BINDIR = "${basePackages.psql_15.bin}";
              PSQL17_BINDIR = "${basePackages.psql_17.bin}";
              PSQL_CONF_FILE = "${paths.pgconfigFile}";
              PSQLORIOLEDB17_BINDIR = "${basePackages.psql_orioledb-17.bin}";
              PGSODIUM_GETKEY = "${paths.getkeyScript}";
              READREPL_CONF_FILE = "${paths.readReplicaConfigFile}";
              LOGGING_CONF_FILE = "${paths.loggingConfigFile}";
              SUPAUTILS_CONF_FILE = "${paths.supautilsConfigFile}";
              PG_HBA = "${paths.pgHbaConfigFile}";
              PG_IDENT = "${paths.pgIdentConfigFile}";
              LOCALES = "${localeArchive}";
              EXTENSION_CUSTOM_SCRIPTS_DIR = "${paths.postgresqlExtensionCustomScriptsPath}";
              MECAB_LIB = "${supabase-groonga}/lib/groonga/plugins/tokenizers/tokenizer_mecab.so";
              GROONGA_DIR = "${supabase-groonga}";
              MIGRATIONS_DIR = "${paths.migrationsDir}";
              POSTGRESQL_SCHEMA_SQL = "${paths.postgresqlSchemaSql}";
              PGBOUNCER_AUTH_SCHEMA_SQL = "${paths.pgbouncerAuthSchemaSql}";
              STAT_EXTENSION_SQL = "${paths.statExtensionSql}";
              CURRENT_SYSTEM = "${system}";
            } // extraSubstitutions; # Merge in any extra substitutions
          in
          pkgs.runCommand name
            {
              inherit (paths) migrationsDir postgresqlSchemaSql pgbouncerAuthSchemaSql statExtensionSql;
            } ''
            mkdir -p $out/bin $out/etc/postgresql-custom $out/etc/postgresql $out/extension-custom-scripts

            # Copy config files with error handling
            cp ${paths.supautilsConfigFile} $out/etc/postgresql-custom/supautils.conf || { echo "Failed to copy supautils.conf"; exit 1; }
            cp ${paths.pgconfigFile} $out/etc/postgresql/postgresql.conf || { echo "Failed to copy postgresql.conf"; exit 1; }
            cp ${paths.loggingConfigFile} $out/etc/postgresql-custom/logging.conf || { echo "Failed to copy logging.conf"; exit 1; }
            cp ${paths.readReplicaConfigFile} $out/etc/postgresql-custom/read-replica.conf || { echo "Failed to copy read-replica.conf"; exit 1; }
            cp ${paths.pgHbaConfigFile} $out/etc/postgresql/pg_hba.conf || { echo "Failed to copy pg_hba.conf"; exit 1; }
            cp ${paths.pgIdentConfigFile} $out/etc/postgresql/pg_ident.conf || { echo "Failed to copy pg_ident.conf"; exit 1; }
            cp -r ${paths.postgresqlExtensionCustomScriptsPath}/* $out/extension-custom-scripts/ || { echo "Failed to copy custom scripts"; exit 1; }

            echo "Copy operation completed"
            chmod 644 $out/etc/postgresql-custom/supautils.conf
            chmod 644 $out/etc/postgresql/postgresql.conf
            chmod 644 $out/etc/postgresql-custom/logging.conf
            chmod 644 $out/etc/postgresql/pg_hba.conf

            substitute ${./nix/tools/run-server.sh.in} $out/bin/start-postgres-server \
              ${builtins.concatStringsSep " " (builtins.attrValues (builtins.mapAttrs
                (name: value: "--subst-var-by '${name}' '${value}'")
                substitutions
              ))}
            chmod +x $out/bin/start-postgres-server
          '';

        # The base set of packages that we export from this Nix Flake, that can
        # be used with 'nix build'. Don't use the names listed below; check the
        # name in 'nix flake show' in order to make sure exactly what name you
        # want.
        basePackages =
          let
            # Function to get the PostgreSQL version from the attribute name
            getVersion = name:
              let
                match = builtins.match "psql_([0-9]+)" name;
              in
              if match == null then null else builtins.head match;

            # Define the available PostgreSQL versions
            postgresVersions = {
              psql_15 = makePostgres "15";
              psql_17 = makePostgres "17";
              psql_orioledb-17 = makePostgres "orioledb-17";
            };

            # Find the active PostgreSQL version
            activeVersion = getVersion (builtins.head (builtins.attrNames postgresVersions));

            # Function to create the pg_regress package
            makePgRegress = version:
              let
                postgresqlPackage = pkgs."postgresql_${version}";
              in
              pkgs.callPackage ./nix/ext/pg_regress.nix {
                postgresql = postgresqlPackage;
              };
            postgresql_15 = getPostgresqlPackage "15";
            postgresql_17 = getPostgresqlPackage "17";
            postgresql_orioledb-17 = getPostgresqlPackage "orioledb-17";
          in
          postgresVersions // {
            supabase-groonga = supabase-groonga;
            cargo-pgrx_0_11_3 = pkgs.cargo-pgrx.cargo-pgrx_0_11_3;
            cargo-pgrx_0_12_6 = pkgs.cargo-pgrx.cargo-pgrx_0_12_6;
            cargo-pgrx_0_12_9 = pkgs.cargo-pgrx.cargo-pgrx_0_12_9;
            cargo-pgrx_0_14_3 = pkgs.cargo-pgrx.cargo-pgrx_0_14_3;
            # PostgreSQL versions.
            psql_15 = postgresVersions.psql_15;
            psql_17 = postgresVersions.psql_17;
            psql_orioledb-17 = postgresVersions.psql_orioledb-17;
            wal-g-2 = wal-g-2;
            wal-g-3 = wal-g-3;
            sfcgal = sfcgal;
            pg_prove = pkgs.perlPackages.TAPParserSourceHandlerpgTAP;
            inherit postgresql_15 postgresql_17 postgresql_orioledb-17;
            postgresql_15_debug = if pkgs.stdenv.isLinux then postgresql_15.debug else null;
            postgresql_17_debug = if pkgs.stdenv.isLinux then postgresql_17.debug else null;
            postgresql_orioledb-17_debug = if pkgs.stdenv.isLinux then postgresql_orioledb-17.debug else null;
            postgresql_15_src = pkgs.stdenv.mkDerivation {
              pname = "postgresql-15-src";
              version = postgresql_15.version;

              src = postgresql_15.src;

              nativeBuildInputs = [ pkgs.bzip2 ];

              phases = [ "unpackPhase" "installPhase" ];

              installPhase = ''
                mkdir -p $out
                cp -r . $out
              '';

              meta = with pkgs.lib; {
                description = "PostgreSQL 15 source files";
                homepage = "https://www.postgresql.org/";
                license = licenses.postgresql;
                platforms = platforms.all;
              };
            };
            postgresql_17_src = pkgs.stdenv.mkDerivation {
              pname = "postgresql-17-src";
              version = postgresql_17.version;
              src = postgresql_17.src;

              nativeBuildInputs = [ pkgs.bzip2 ];

              phases = [ "unpackPhase" "installPhase" ];

              installPhase = ''
                mkdir -p $out
                cp -r . $out
              '';
              meta = with pkgs.lib; {
                description = "PostgreSQL 17 source files";
                homepage = "https://www.postgresql.org/";
                license = licenses.postgresql;
                platforms = platforms.all;
              };
            };
            postgresql_orioledb-17_src = pkgs.stdenv.mkDerivation {
              pname = "postgresql-17-src";
              version = postgresql_orioledb-17.version;

              src = postgresql_orioledb-17.src;

              nativeBuildInputs = [ pkgs.bzip2 ];

              phases = [ "unpackPhase" "installPhase" ];

              installPhase = ''
                mkdir -p $out
                cp -r . $out
              '';

              meta = with pkgs.lib; {
                description = "PostgreSQL 15 source files";
                homepage = "https://www.postgresql.org/";
                license = licenses.postgresql;
                platforms = platforms.all;
              };
            };
            mecab_naist_jdic = mecab-naist-jdic;
            supabase_groonga = supabase-groonga;
            pg_regress = makePgRegress activeVersion;
            # Start a version of the server.
            start-server = makePostgresDevSetup {
              inherit pkgs;
              name = "start-postgres-server";
            };

            # Start a version of the client and runs migrations script on server.
            start-client =
              let
                migrationsDir = ./migrations/db;
                postgresqlSchemaSql = ./nix/tools/postgresql_schema.sql;
                pgbouncerAuthSchemaSql = ./ansible/files/pgbouncer_config/pgbouncer_auth_schema.sql;
                statExtensionSql = ./ansible/files/stat_extension.sql;
              in
              pkgs.runCommand "start-postgres-client" { } ''
                mkdir -p $out/bin
                substitute ${./nix/tools/run-client.sh.in} $out/bin/start-postgres-client \
                  --subst-var-by 'PGSQL_DEFAULT_PORT' '${pgsqlDefaultPort}' \
                  --subst-var-by 'PGSQL_SUPERUSER' '${pgsqlSuperuser}' \
                  --subst-var-by 'PSQL15_BINDIR' '${basePackages.psql_15.bin}' \
                  --subst-var-by 'PSQL17_BINDIR' '${basePackages.psql_17.bin}' \
                  --subst-var-by 'PSQLORIOLEDB17_BINDIR' '${basePackages.psql_orioledb-17.bin}' \
                  --subst-var-by 'MIGRATIONS_DIR' '${migrationsDir}' \
                  --subst-var-by 'POSTGRESQL_SCHEMA_SQL' '${postgresqlSchemaSql}' \
                  --subst-var-by 'PGBOUNCER_AUTH_SCHEMA_SQL' '${pgbouncerAuthSchemaSql}' \
                  --subst-var-by 'STAT_EXTENSION_SQL' '${statExtensionSql}'
                chmod +x $out/bin/start-postgres-client
              '';

            # Migrate between two data directories.
            migrate-tool =
              let
                configFile = ./nix/tests/postgresql.conf.in;
                getkeyScript = ./nix/tests/util/pgsodium_getkey.sh;
                primingScript = ./nix/tests/prime.sql;
                migrationData = ./nix/tests/migrations/data.sql;
              in
              pkgs.runCommand "migrate-postgres" { } ''
                mkdir -p $out/bin
                substitute ${./nix/tools/migrate-tool.sh.in} $out/bin/migrate-postgres \
                  --subst-var-by 'PSQL15_BINDIR' '${basePackages.psql_15.bin}' \
                  --subst-var-by 'PSQL_CONF_FILE' '${configFile}' \
                  --subst-var-by 'PGSODIUM_GETKEY' '${getkeyScript}' \
                  --subst-var-by 'PRIMING_SCRIPT' '${primingScript}' \
                  --subst-var-by 'MIGRATION_DATA' '${migrationData}'

                chmod +x $out/bin/migrate-postgres
              '';

            start-replica = pkgs.runCommand "start-postgres-replica" { } ''
              mkdir -p $out/bin
              substitute ${./nix/tools/run-replica.sh.in} $out/bin/start-postgres-replica \
                --subst-var-by 'PGSQL_SUPERUSER' '${pgsqlSuperuser}' \
                --subst-var-by 'PSQL15_BINDIR' '${basePackages.psql_15.bin}'
              chmod +x $out/bin/start-postgres-replica
            '';
            pg-restore =
              pkgs.runCommand "run-pg-restore" { } ''
                mkdir -p $out/bin
                substitute ${./nix/tools/run-restore.sh.in} $out/bin/pg-restore \
                  --subst-var-by PSQL15_BINDIR '${basePackages.psql_15.bin}'
                chmod +x $out/bin/pg-restore
              '';
            sync-exts-versions = pkgs.runCommand "sync-exts-versions" { } ''
              mkdir -p $out/bin
              substitute ${./nix/tools/sync-exts-versions.sh.in} $out/bin/sync-exts-versions \
                --subst-var-by 'YQ' '${pkgs.yq}/bin/yq' \
                --subst-var-by 'JQ' '${pkgs.jq}/bin/jq' \
                --subst-var-by 'NIX_EDITOR' '${nix-editor.packages.${system}.nix-editor}/bin/nix-editor' \
                --subst-var-by 'NIXPREFETCHURL' '${pkgs.nixVersions.nix_2_20}/bin/nix-prefetch-url' \
                --subst-var-by 'NIX' '${pkgs.nixVersions.nix_2_20}/bin/nix'
              chmod +x $out/bin/sync-exts-versions
            '';

            local-infra-bootstrap = pkgs.runCommand "local-infra-bootstrap" { } ''
              mkdir -p $out/bin
              substitute ${./nix/tools/local-infra-bootstrap.sh.in} $out/bin/local-infra-bootstrap
              chmod +x $out/bin/local-infra-bootstrap
            '';
            dbmate-tool =
              let
                migrationsDir = ./migrations/db;
                ansibleVars = ./ansible/vars.yml;
                pgbouncerAuthSchemaSql = ./ansible/files/pgbouncer_config/pgbouncer_auth_schema.sql;
                statExtensionSql = ./ansible/files/stat_extension.sql;
              in
              pkgs.runCommand "dbmate-tool"
                {
                  buildInputs = with pkgs; [
                    overmind
                    dbmate
                    nix
                    jq
                    yq
                  ];
                  nativeBuildInputs = with pkgs; [
                    makeWrapper
                  ];
                } ''
                mkdir -p $out/bin $out/migrations
                cp -r ${migrationsDir}/* $out
                substitute ${./nix/tools/dbmate-tool.sh.in} $out/bin/dbmate-tool \
                  --subst-var-by 'PGSQL_DEFAULT_PORT' '${pgsqlDefaultPort}' \
                  --subst-var-by 'MIGRATIONS_DIR' $out \
                  --subst-var-by 'PGSQL_SUPERUSER' '${pgsqlSuperuser}' \
                  --subst-var-by 'ANSIBLE_VARS' ${ansibleVars} \
                  --subst-var-by 'CURRENT_SYSTEM' '${system}' \
                  --subst-var-by 'PGBOUNCER_AUTH_SCHEMA_SQL' '${pgbouncerAuthSchemaSql}' \
                  --subst-var-by 'STAT_EXTENSION_SQL' '${statExtensionSql}'
                chmod +x $out/bin/dbmate-tool
                wrapProgram $out/bin/dbmate-tool \
                  --prefix PATH : ${pkgs.lib.makeBinPath [ pkgs.overmind pkgs.dbmate pkgs.nix pkgs.jq pkgs.yq ]}
              '';
            show-commands = pkgs.runCommand "show-commands"
              {
                nativeBuildInputs = [ pkgs.makeWrapper ];
                buildInputs = [ pkgs.nushell ];
              } ''
              mkdir -p $out/bin
              cat > $out/bin/show-commands << 'EOF'
              #!${pkgs.nushell}/bin/nu
              let json_output = (nix flake show --json --quiet --all-systems | from json)
              let apps = ($json_output | get apps.${system})
              $apps | transpose name info | select name | each { |it| echo $"Run this app with: nix run .#($it.name)" }
              EOF
              chmod +x $out/bin/show-commands
              wrapProgram $out/bin/show-commands \
                --prefix PATH : ${pkgs.nushell}/bin
            '';
            update-readme = pkgs.runCommand "update-readme"
              {
                nativeBuildInputs = [ pkgs.makeWrapper ];
                buildInputs = [ pkgs.nushell ];
              } ''
              mkdir -p $out/bin
              cp ${./nix/tools/update_readme.nu} $out/bin/update-readme
              chmod +x $out/bin/update-readme
              wrapProgram $out/bin/update-readme \
                --prefix PATH : ${pkgs.nushell}/bin
            '';
            # Script to run the AMI build and tests locally
            build-test-ami = pkgs.runCommand "build-test-ami"
              {
                buildInputs = with pkgs; [
                  packer
                  awscli2
                  yq
                  jq
                  openssl
                  git
                  coreutils
                  aws-vault
                ];
              } ''
                mkdir -p $out/bin
                cat > $out/bin/build-test-ami << 'EOL'
                #!/usr/bin/env bash
                set -euo pipefail

                show_help() {
                  cat << EOF
                Usage: build-test-ami [--help] <postgres-version>

                Build AMI images for PostgreSQL testing.

                This script will:
                1. Check for required tools and AWS authentication
                2. Build two AMI stages using Packer
                3. Clean up any temporary instances
                4. Output the final AMI name for use with run-testinfra

                Arguments:
                  postgres-version    PostgreSQL major version to build (required)

                Options:
                  --help    Show this help message and exit

                Requirements:
                  - AWS Vault profile must be set in AWS_VAULT environment variable
                  - Packer, AWS CLI, yq, jq, and OpenSSL must be installed
                  - Must be run from a git repository

                Example:
                  aws-vault exec <profile-name> -- nix run .#build-test-ami 15
                EOF
                }

                # Handle help flag
                if [[ "$#" -gt 0 && "$1" == "--help" ]]; then
                  show_help
                  exit 0
                fi

                export PATH="${pkgs.lib.makeBinPath (with pkgs; [
                  packer
                  awscli2
                  yq
                  jq
                  openssl
                  git
                  coreutils
                  aws-vault
                ])}:$PATH"

                # Check for required tools
                for cmd in packer aws-vault yq jq openssl; do
                  if ! command -v $cmd &> /dev/null; then
                    echo "Error: $cmd is required but not found"
                    exit 1
                  fi
                done

                # Check AWS Vault profile
                if [ -z "''${AWS_VAULT:-}" ]; then
                  echo "Error: AWS_VAULT environment variable must be set with the profile name"
                  echo "Usage: aws-vault exec <profile-name> -- nix run .#build-test-ami <postgres-version>"
                  exit 1
                fi

                # Set values
                REGION="ap-southeast-1"
                POSTGRES_VERSION="$1"
                RANDOM_STRING=$(openssl rand -hex 8)
                GIT_SHA=$(git rev-parse HEAD)
                RUN_ID=$(date +%s)

                # Generate common-nix.vars.pkr.hcl
                PG_VERSION=$(yq -r ".postgres_release[\"postgres$POSTGRES_VERSION\"]" ansible/vars.yml)
                echo "postgres-version = \"$PG_VERSION\"" > common-nix.vars.pkr.hcl

                # Build AMI Stage 1
                packer init amazon-arm64-nix.pkr.hcl
                packer build \
                  -var "git-head-version=$GIT_SHA" \
                  -var "packer-execution-id=$RUN_ID" \
                  -var-file="development-arm.vars.pkr.hcl" \
                  -var-file="common-nix.vars.pkr.hcl" \
                  -var "ansible_arguments=" \
                  -var "postgres-version=$RANDOM_STRING" \
                  -var "region=$REGION" \
                  -var 'ami_regions=["'"$REGION"'"]' \
                  -var "force-deregister=true" \
                  -var "ansible_arguments=-e postgresql_major=$POSTGRES_VERSION" \
                  amazon-arm64-nix.pkr.hcl

                # Build AMI Stage 2
                packer init stage2-nix-psql.pkr.hcl
                packer build \
                  -var "git-head-version=$GIT_SHA" \
                  -var "packer-execution-id=$RUN_ID" \
                  -var "postgres_major_version=$POSTGRES_VERSION" \
                  -var-file="development-arm.vars.pkr.hcl" \
                  -var-file="common-nix.vars.pkr.hcl" \
                  -var "postgres-version=$RANDOM_STRING" \
                  -var "region=$REGION" \
                  -var 'ami_regions=["'"$REGION"'"]' \
                  -var "force-deregister=true" \
                  -var "git_sha=$GIT_SHA" \
                  stage2-nix-psql.pkr.hcl

                # Cleanup instances from AMI builds
                cleanup_instances() {
                  echo "Terminating EC2 instances with tag testinfra-run-id=$RUN_ID..."
                  aws ec2 --region $REGION describe-instances \
                    --filters "Name=tag:testinfra-run-id,Values=$RUN_ID" \
                    --query "Reservations[].Instances[].InstanceId" \
                    --output text | xargs -r aws ec2 terminate-instances \
                    --region $REGION --instance-ids || true
                }

                # Set up traps for various signals to ensure cleanup
                trap cleanup_instances EXIT HUP INT QUIT TERM

                # Create and activate virtual environment
                VENV_DIR=$(mktemp -d)
                trap 'rm -rf "$VENV_DIR"' EXIT HUP INT QUIT TERM
                python3 -m venv "$VENV_DIR"
                source "$VENV_DIR/bin/activate"

                # Install required Python packages
                echo "Installing required Python packages..."
                pip install boto3 boto3-stubs[essential] docker ec2instanceconnectcli pytest paramiko requests

                # Run the tests with aws-vault
                echo "Running tests for AMI: $RANDOM_STRING using AWS Vault profile: $AWS_VAULT_PROFILE"
                aws-vault exec $AWS_VAULT_PROFILE -- pytest -vv -s testinfra/test_ami_nix.py

                # Deactivate virtual environment (cleanup is handled by trap)
                deactivate
                EOL
                chmod +x $out/bin/build-test-ami
              '';

            run-testinfra = pkgs.runCommand "run-testinfra"
              {
                buildInputs = with pkgs; [
                  aws-vault
                  python3
                  python3Packages.pip
                  coreutils
                ];
              } ''
                mkdir -p $out/bin
                cat > $out/bin/run-testinfra << 'EOL'
                #!/usr/bin/env bash
                set -euo pipefail

                show_help() {
                  cat << EOF
                Usage: run-testinfra --ami-name NAME [--aws-vault-profile PROFILE]

                Run the testinfra tests locally against a specific AMI.

                This script will:
                1. Check if aws-vault is installed and configured
                2. Set up the required environment variables
                3. Create and activate a virtual environment
                4. Install required Python packages from pip
                5. Run the tests with aws-vault credentials
                6. Clean up the virtual environment

                Required flags:
                  --ami-name NAME              The name of the AMI to test

                Optional flags:
                  --aws-vault-profile PROFILE  AWS Vault profile to use (default: staging)
                  --help                       Show this help message and exit

                Requirements:
                  - aws-vault installed and configured
                  - Python 3 with pip
                  - Must be run from the repository root

                Examples:
                  run-testinfra --ami-name supabase-postgres-abc123
                  run-testinfra --ami-name supabase-postgres-abc123 --aws-vault-profile production
                EOF
                }

                # Default values
                AWS_VAULT_PROFILE="staging"
                AMI_NAME=""

                # Parse arguments
                while [[ $# -gt 0 ]]; do
                  case $1 in
                    --aws-vault-profile)
                      AWS_VAULT_PROFILE="$2"
                      shift 2
                      ;;
                    --ami-name)
                      AMI_NAME="$2"
                      shift 2
                      ;;
                    --help)
                      show_help
                      exit 0
                      ;;
                    *)
                      echo "Error: Unexpected argument: $1"
                      show_help
                      exit 1
                      ;;
                  esac
                done

                # Check for required tools
                if ! command -v aws-vault &> /dev/null; then
                  echo "Error: aws-vault is required but not found"
                  exit 1
                fi

                # Check for AMI name argument
                if [ -z "$AMI_NAME" ]; then
                  echo "Error: --ami-name is required"
                  show_help
                  exit 1
                fi

                # Set environment variables
                export AWS_REGION="ap-southeast-1"
                export AWS_DEFAULT_REGION="ap-southeast-1"
                export AMI_NAME="$AMI_NAME"  # Export AMI_NAME for pytest
                export RUN_ID="local-$(date +%s)"  # Generate a unique RUN_ID

                # Function to terminate EC2 instances
                terminate_instances() {
                  echo "Terminating EC2 instances with tag testinfra-run-id=$RUN_ID..."
                  aws-vault exec $AWS_VAULT_PROFILE -- aws ec2 --region ap-southeast-1 describe-instances \
                    --filters "Name=tag:testinfra-run-id,Values=$RUN_ID" \
                    --query "Reservations[].Instances[].InstanceId" \
                    --output text | xargs -r aws-vault exec $AWS_VAULT_PROFILE -- aws ec2 terminate-instances \
                    --region ap-southeast-1 --instance-ids || true
                }

                # Set up traps for various signals to ensure cleanup
                trap terminate_instances EXIT HUP INT QUIT TERM

                # Create and activate virtual environment
                VENV_DIR=$(mktemp -d)
                trap 'rm -rf "$VENV_DIR"' EXIT HUP INT QUIT TERM
                python3 -m venv "$VENV_DIR"
                source "$VENV_DIR/bin/activate"

                # Install required Python packages
                echo "Installing required Python packages..."
                pip install boto3 boto3-stubs[essential] docker ec2instanceconnectcli pytest paramiko requests

                # Function to run tests and ensure cleanup
                run_tests() {
                  local exit_code=0
                  echo "Running tests for AMI: $AMI_NAME using AWS Vault profile: $AWS_VAULT_PROFILE"
                  aws-vault exec "$AWS_VAULT_PROFILE" -- pytest -vv -s testinfra/test_ami_nix.py || exit_code=$?
                  return $exit_code
                }

                # Run tests and capture exit code
                run_tests
                test_exit_code=$?

                # Deactivate virtual environment
                deactivate

                # Explicitly call cleanup
                terminate_instances

                # Exit with the test exit code
                exit $test_exit_code
                EOL
                chmod +x $out/bin/run-testinfra
              '';

            cleanup-ami = pkgs.runCommand "cleanup-ami"
              {
                buildInputs = with pkgs; [
                  awscli2
                  aws-vault
                ];
              } ''
                mkdir -p $out/bin
                cat > $out/bin/cleanup-ami << 'EOL'
                #!/usr/bin/env bash
                set -euo pipefail

                export PATH="${pkgs.lib.makeBinPath (with pkgs; [
                  awscli2
                  aws-vault
                ])}:$PATH"

                # Check for required tools
                for cmd in aws-vault; do
                  if ! command -v $cmd &> /dev/null; then
                    echo "Error: $cmd is required but not found"
                    exit 1
                  fi
                done

                # Check AWS Vault profile
                if [ -z "''${AWS_VAULT:-}" ]; then
                  echo "Error: AWS_VAULT environment variable must be set with the profile name"
                  echo "Usage: aws-vault exec <profile-name> -- nix run .#cleanup-ami <ami-name>"
                  exit 1
                fi

                # Check for AMI name argument
                if [ -z "''${1:-}" ]; then
                  echo "Error: AMI name must be provided"
                  echo "Usage: aws-vault exec <profile-name> -- nix run .#cleanup-ami <ami-name>"
                  exit 1
                fi

                AMI_NAME="$1"
                REGION="ap-southeast-1"

                # Deregister AMIs
                for AMI_PATTERN in "supabase-postgres-ci-ami-test-stage-1" "$AMI_NAME"; do
                  aws ec2 describe-images --region $REGION --owners self \
                    --filters "Name=name,Values=$AMI_PATTERN" \
                    --query 'Images[*].ImageId' --output text | while read -r ami_id; do
                      echo "Deregistering AMI: $ami_id"
                      aws ec2 deregister-image --region $REGION --image-id "$ami_id" || true
                    done
                done
                EOL
                chmod +x $out/bin/cleanup-ami
              '';

            trigger-nix-build = pkgs.runCommand "trigger-nix-build"
              {
                buildInputs = with pkgs; [
                  gh
                  git
                  coreutils
                ];
              } ''
                mkdir -p $out/bin
                cat > $out/bin/trigger-nix-build << 'EOL'
                #!/usr/bin/env bash
                set -euo pipefail

                show_help() {
                  cat << EOF
                Usage: trigger-nix-build [--help]

                Trigger the nix-build workflow for the current branch and watch its progress.

                This script will:
                1. Check if you're authenticated with GitHub
                2. Get the current branch and commit
                3. Verify you're on a standard branch (develop or release/*) or prompt for confirmation
                4. Trigger the nix-build workflow
                5. Watch the workflow progress until completion

                Options:
                  --help    Show this help message and exit

                Requirements:
                  - GitHub CLI (gh) installed and authenticated
                  - Git installed
                  - Must be run from a git repository

                Example:
                  trigger-nix-build
                EOF
                }

                # Handle help flag
                if [[ "$#" -gt 0 && "$1" == "--help" ]]; then
                  show_help
                  exit 0
                fi

                export PATH="${pkgs.lib.makeBinPath (with pkgs; [
                  gh
                  git
                  coreutils
                ])}:$PATH"

                # Check for required tools
                for cmd in gh git; do
                  if ! command -v $cmd &> /dev/null; then
                    echo "Error: $cmd is required but not found"
                    exit 1
                  fi
                done

                # Check if user is authenticated with GitHub
                if ! gh auth status &>/dev/null; then
                  echo "Error: Not authenticated with GitHub. Please run 'gh auth login' first."
                  exit 1
                fi

                # Get current branch and commit
                BRANCH=$(git rev-parse --abbrev-ref HEAD)
                COMMIT=$(git rev-parse HEAD)

                # Check if we're on a standard branch
                if [[ "$BRANCH" != "develop" && ! "$BRANCH" =~ ^release/ ]]; then
                  echo "Warning: Running workflow from non-standard branch: $BRANCH"
                  echo "This is supported for testing purposes."
                  read -p "Continue? [y/N] " -n 1 -r
                  echo
                  if [[ ! $REPLY =~ ^[Yy]$ ]]; then
                    echo "Aborted."
                    exit 1
                  fi
                fi

                # Trigger the workflow
                echo "Triggering nix-build workflow for branch $BRANCH (commit: $COMMIT)"
                gh workflow run nix-build.yml --ref "$BRANCH"

                # Wait for workflow to start and get the run ID
                echo "Waiting for workflow to start..."
                sleep 5

                # Get the latest run ID for this workflow
                RUN_ID=$(gh run list --workflow=nix-build.yml --limit 1 --json databaseId --jq '.[0].databaseId')

                if [ -z "$RUN_ID" ]; then
                  echo "Error: Could not find workflow run ID"
                  exit 1
                fi

                echo "Watching workflow run $RUN_ID..."
                echo "The script will automatically exit when the workflow completes."
                echo "Press Ctrl+C to stop watching (workflow will continue running)"
                echo "----------------------------------------"

                # Try to watch the run, but handle network errors gracefully
                while true; do
                  if gh run watch "$RUN_ID" --exit-status; then
                    break
                  else
                    echo "Network error while watching workflow. Retrying in 5 seconds..."
                    echo "You can also check the status manually with: gh run view $RUN_ID"
                    sleep 5
                  fi
                done
                EOL
                chmod +x $out/bin/trigger-nix-build
              '';
          };


        # Create a testing harness for a PostgreSQL package. This is used for
        # 'nix flake check', and works with any PostgreSQL package you hand it.

        makeCheckHarness = pgpkg:
          let
            sqlTests = ./nix/tests/smoke;
            pg_prove = pkgs.perlPackages.TAPParserSourceHandlerpgTAP;
            pg_regress = basePackages.pg_regress;
            getkey-script = pkgs.stdenv.mkDerivation {
              name = "pgsodium-getkey";
              buildCommand = ''
                mkdir -p $out/bin
                cat > $out/bin/pgsodium-getkey << 'EOF'
                #!${pkgs.bash}/bin/bash
                set -euo pipefail

                TMPDIR_BASE=$(mktemp -d)

                KEY_DIR="''${PGSODIUM_KEY_DIR:-$TMPDIR_BASE/pgsodium}"
                KEY_FILE="$KEY_DIR/pgsodium.key"

                if ! mkdir -p "$KEY_DIR" 2>/dev/null; then
                  echo "Error: Could not create key directory $KEY_DIR" >&2
                  exit 1
                fi
                chmod 1777 "$KEY_DIR"

                if [[ ! -f "$KEY_FILE" ]]; then
                  if ! (dd if=/dev/urandom bs=32 count=1 2>/dev/null | od -A n -t x1 | tr -d ' \n' > "$KEY_FILE"); then
                    if ! (openssl rand -hex 32 > "$KEY_FILE"); then
                      echo "00000000000000000000000000000000" > "$KEY_FILE"
                      echo "Warning: Using fallback key" >&2
                    fi
                  fi
                  chmod 644 "$KEY_FILE"
                fi

                if [[ -f "$KEY_FILE" && -r "$KEY_FILE" ]]; then
                  cat "$KEY_FILE"
                else
                  echo "Error: Cannot read key file $KEY_FILE" >&2
                  exit 1
                fi
                EOF
                chmod +x $out/bin/pgsodium-getkey
              '';
            };

            # Use the shared setup but with a test-specific name
            start-postgres-server-bin = makePostgresDevSetup {
              inherit pkgs;
              name = "start-postgres-server-test";
              extraSubstitutions = {
                PGSODIUM_GETKEY = "${getkey-script}/bin/pgsodium-getkey";
                PGSQL_DEFAULT_PORT = pgPort;
              };
            };

            getVersionArg = pkg:
              let
                name = pkg.version;
              in
              if builtins.match "15.*" name != null then "15"
              else if builtins.match "17.*" name != null then "17"
              else if builtins.match "orioledb-17.*" name != null then "orioledb-17"
              else throw "Unsupported PostgreSQL version: ${name}";

            # Helper function to filter SQL files based on version
            filterTestFiles = version: dir:
              let
                files = builtins.readDir dir;
                isValidFile = name:
                  let
                    isVersionSpecific = builtins.match "z_.*" name != null;
                    matchesVersion =
                      if isVersionSpecific
                      then
                        if version == "orioledb-17"
                        then builtins.match "z_orioledb-17_.*" name != null
                        else if version == "17"
                        then builtins.match "z_17_.*" name != null
                        else builtins.match "z_15_.*" name != null
                      else true;
                  in
                  pkgs.lib.hasSuffix ".sql" name && matchesVersion;
              in
              pkgs.lib.filterAttrs (name: _: isValidFile name) files;

            # Get the major version for filtering
            majorVersion =
              let
                version = builtins.trace "pgpkg.version is: ${pgpkg.version}" pgpkg.version;
                _ = builtins.trace "Entering majorVersion logic";
                isOrioledbMatch = builtins.match "^17_[0-9]+$" version != null;
                isSeventeenMatch = builtins.match "^17[.][0-9]+$" version != null;
                result =
                  if isOrioledbMatch
                  then "orioledb-17"
                  else if isSeventeenMatch
                  then "17"
                  else "15";
              in
              builtins.trace "Major version result: ${result}" result; # Trace the result                                             # For "15.8"

            # Filter SQL test files
            filteredSqlTests = filterTestFiles majorVersion ./nix/tests/sql;

            pgPort = if (majorVersion == "17") then
                "5535"
                else if (majorVersion == "15") then
                "5536"
                else "5537";

            # Convert filtered tests to a sorted list of basenames (without extension)
            testList = pkgs.lib.mapAttrsToList
              (name: _:
                builtins.substring 0 (pkgs.lib.stringLength name - 4) name
              )
              filteredSqlTests;
            sortedTestList = builtins.sort (a: b: a < b) testList;

          in
          pkgs.runCommand "postgres-${pgpkg.version}-check-harness"
            {
              nativeBuildInputs = with pkgs; [
                coreutils
                bash
                perl
                pgpkg
                pg_prove
                pg_regress
                procps
                start-postgres-server-bin
                which
                getkey-script
                supabase-groonga
              ];
            } ''
            set -e

            #First we need to create a generic pg cluster for pgtap tests and run those
            export GRN_PLUGINS_DIR=${supabase-groonga}/lib/groonga/plugins
            PGTAP_CLUSTER=$(mktemp -d)
            initdb --locale=C --username=capitala_admin -D "$PGTAP_CLUSTER"
            substitute ${./nix/tests/postgresql.conf.in} "$PGTAP_CLUSTER"/postgresql.conf \
              --subst-var-by PGSODIUM_GETKEY_SCRIPT "${getkey-script}/bin/pgsodium-getkey"
            echo "listen_addresses = '*'" >> "$PGTAP_CLUSTER"/postgresql.conf
            echo "port = ${pgPort}" >> "$PGTAP_CLUSTER"/postgresql.conf
            echo "host all all 127.0.0.1/32 trust" >> $PGTAP_CLUSTER/pg_hba.conf
            echo "Checking shared_preload_libraries setting:"
            grep -rn "shared_preload_libraries" "$PGTAP_CLUSTER"/postgresql.conf
            # Remove timescaledb if running orioledb-17 check
            echo "I AM ${pgpkg.version}===================================================="
            if [[ "${pgpkg.version}" == *"17"* ]]; then
              perl -pi -e 's/ timescaledb,//g' "$PGTAP_CLUSTER/postgresql.conf"
            fi
            #NOTE in the future we may also need to add the orioledb extension to the cluster when cluster is oriole
            echo "PGTAP_CLUSTER directory contents:"
            ls -la "$PGTAP_CLUSTER"

            # Check if postgresql.conf exists
            if [ ! -f "$PGTAP_CLUSTER/postgresql.conf" ]; then
                echo "postgresql.conf is missing!"
                exit 1
            fi

            # PostgreSQL startup
            if [[ "$(uname)" == "Darwin" ]]; then
            pg_ctl -D "$PGTAP_CLUSTER" -l "$PGTAP_CLUSTER"/postgresql.log -o "-k "$PGTAP_CLUSTER" -p ${pgPort} -d 5" start 2>&1
            else
            mkdir -p "$PGTAP_CLUSTER/sockets"
            pg_ctl -D "$PGTAP_CLUSTER" -l "$PGTAP_CLUSTER"/postgresql.log -o "-k $PGTAP_CLUSTER/sockets -p ${pgPort} -d 5" start 2>&1
            fi || {
            echo "pg_ctl failed to start PostgreSQL"
            echo "Contents of postgresql.log:"
            cat "$PGTAP_CLUSTER"/postgresql.log
            exit 1
            }
            for i in {1..60}; do
              if pg_isready -h ${pgsqlDefaultHost} -p ${pgPort}; then
                echo "PostgreSQL is ready"
                break
              fi
              sleep 1
              if [ $i -eq 60 ]; then
                echo "PostgreSQL is not ready after 60 seconds"
                echo "PostgreSQL status:"
                pg_ctl -D "$PGTAP_CLUSTER" status
                echo "PostgreSQL log content:"
                cat "$PGTAP_CLUSTER"/postgresql.log
                exit 1
              fi
            done
            createdb -p ${pgPort} -h ${pgsqlDefaultHost} --username=capitala_admin testing
            if ! psql -p ${pgPort} -h ${pgsqlDefaultHost} --username=capitala_admin -d testing -v ON_ERROR_STOP=1 -Xf ${./nix/tests/prime.sql}; then
              echo "Error executing SQL file. PostgreSQL log content:"
              cat "$PGTAP_CLUSTER"/postgresql.log
              pg_ctl -D "$PGTAP_CLUSTER" stop
              exit 1
            fi
            SORTED_DIR=$(mktemp -d)
            for t in $(printf "%s\n" ${builtins.concatStringsSep " " sortedTestList}); do
              psql -p ${pgPort} -h ${pgsqlDefaultHost} --username=capitala_admin -d testing -f "${./nix/tests/sql}/$t.sql" || true
            done
            rm -rf "$SORTED_DIR"
            pg_ctl -D "$PGTAP_CLUSTER" stop
            rm -rf $PGTAP_CLUSTER

            # End of pgtap tests
            # from here on out we are running pg_regress tests, we use a different cluster for this
            # which is start by the start-postgres-server-bin script
            # start-postgres-server-bin script closely matches our AMI setup, configurations and migrations

            unset GRN_PLUGINS_DIR
            ${start-postgres-server-bin}/bin/start-postgres-server ${getVersionArg pgpkg} --daemonize

            for i in {1..60}; do
                if pg_isready -h ${pgsqlDefaultHost} -p ${pgPort} -U capitala_admin -q; then
                    echo "PostgreSQL is ready"
                    break
                fi
                sleep 1
                if [ $i -eq 60 ]; then
                    echo "PostgreSQL failed to start"
                    exit 1
                fi
            done

            if ! psql -p ${pgPort} -h ${pgsqlDefaultHost} --no-password --username=capitala_admin -d postgres -v ON_ERROR_STOP=1 -Xf ${./nix/tests/prime.sql}; then
              echo "Error executing SQL file"
              exit 1
            fi

            mkdir -p $out/regression_output
            if ! pg_regress \
              --use-existing \
              --dbname=postgres \
              --inputdir=${./nix/tests} \
              --outputdir=$out/regression_output \
              --host=${pgsqlDefaultHost} \
              --port=${pgPort} \
              --user=capitala_admin \
              ${builtins.concatStringsSep " " sortedTestList}; then
              echo "pg_regress tests failed"
              cat $out/regression_output/regression.diffs
              exit 1
            fi

            echo "Running migrations tests"
            pg_prove -p ${pgPort} -U capitala_admin -h ${pgsqlDefaultHost} -d postgres -v ${./migrations/tests}/test.sql

            # Copy logs to output
            for logfile in $(find /tmp -name postgresql.log -type f); do
              cp "$logfile" $out/postgresql.log
            done
            exit 0
          '';
      in
      rec {
        # The list of all packages that can be built with 'nix build'. The list
        # of names that can be used can be shown with 'nix flake show'
        packages = flake-utils.lib.flattenTree basePackages // {
          # Any extra packages we might want to include in our package
          # set can go here.
          inherit (pkgs);
        };

        # The list of exported 'checks' that are run with every run of 'nix
        # flake check'. This is run in the CI system, as well.
        checks = {
          psql_15 = makeCheckHarness basePackages.psql_15.bin;
          psql_17 = makeCheckHarness basePackages.psql_17.bin;
          psql_orioledb-17 = makeCheckHarness basePackages.psql_orioledb-17.bin;
          inherit (basePackages) wal-g-2 wal-g-3 dbmate-tool pg_regress;
        } // pkgs.lib.optionalAttrs (system == "aarch64-linux") {
          inherit (basePackages) postgresql_15_debug postgresql_15_src postgresql_orioledb-17_debug postgresql_orioledb-17_src postgresql_17_debug postgresql_17_src;
        };

        # Apps is a list of names of things that can be executed with 'nix run';
        # these are distinct from the things that can be built with 'nix build',
        # so they need to be listed here too.
        apps =
          let
            mkApp = attrName: binName: {
              type = "app";
              program = "${basePackages."${attrName}"}/bin/${binName}";
            };
          in
          {
            start-server = mkApp "start-server" "start-postgres-server";
            start-client = mkApp "start-client" "start-postgres-client";
            start-replica = mkApp "start-replica" "start-postgres-replica";
            # migrate-postgres = mkApp "migrate-tool" "migrate-postgres";
            # sync-exts-versions = mkApp "sync-exts-versions" "sync-exts-versions";
            pg-restore = mkApp "pg-restore" "pg-restore";
            local-infra-bootstrap = mkApp "local-infra-bootstrap" "local-infra-bootstrap";
            dbmate-tool = mkApp "dbmate-tool" "dbmate-tool";
            update-readme = mkApp "update-readme" "update-readme";
            show-commands = mkApp "show-commands" "show-commands";
            build-test-ami = mkApp "build-test-ami" "build-test-ami";
            run-testinfra = mkApp "run-testinfra" "run-testinfra";
            cleanup-ami = mkApp "cleanup-ami" "cleanup-ami";
            trigger-nix-build = mkApp "trigger-nix-build" "trigger-nix-build";
          };

        # 'devShells.default' lists the set of packages that are included in the
        # ambient $PATH environment when you run 'nix develop'. This is useful
        # for development and puts many convenient devtools instantly within
        # reach.

        devShells =
          let
            mkCargoPgrxDevShell = { pgrxVersion, rustVersion }: pkgs.mkShell {
              packages = with pkgs; [
                basePackages."cargo-pgrx_${pgrxVersion}"
                (rust-bin.stable.${rustVersion}.default.override {
                  extensions = [ "rust-src" ];
                })
              ];
              shellHook = ''
                export HISTFILE=.history
              '';
            };
          in
          {
            default = pkgs.mkShell {
              packages = with pkgs; [
                coreutils
                just
                nix-update
                #pg_prove
                shellcheck
                ansible
                ansible-lint
                (packer.overrideAttrs (oldAttrs: {
                  version = "1.7.8";
                }))

                basePackages.start-server
                basePackages.start-client
                basePackages.start-replica
                basePackages.migrate-tool
                basePackages.sync-exts-versions
                basePackages.build-test-ami
                basePackages.run-testinfra
                basePackages.cleanup-ami
                dbmate
                nushell
                pythonEnv
                ] ++ pkgs.lib.optionals (nixFastBuild != null) [
                nixFastBuild
                ];
              shellHook = ''
                export HISTFILE=.history
              '';
            };
            cargo-pgrx_0_11_3 = mkCargoPgrxDevShell {
              pgrxVersion = "0_11_3";
              rustVersion = "1.80.0";
            };
            cargo-pgrx_0_12_6 = mkCargoPgrxDevShell {
              pgrxVersion = "0_12_6";
              rustVersion = "1.80.0";
            };
          };
      }
    );
}

'''

'''--- /Users/barneycook/Desktop/code/ProjectRef/postgres/nix/init.sh ---
#!/bin/bash
# shellcheck shell=bash

export PGUSER=capitala_admin
export PGDATA=$PWD/postgres_data
export PGHOST=$PWD/postgres
export PGPORT=5432
export PGPASS=postgres
export LOG_PATH=$PGHOST/LOG
export PGDATABASE=testdb
export DATABASE_URL="postgresql:///$PGDATABASE?host=$PGHOST&port=$PGPORT"
mkdir -p $PGHOST
if [ ! -d $PGDATA ]; then
    echo 'Initializing postgresql database...'
    initdb $PGDATA --locale=C --username $PGUSER -A md5 --pwfile=<(echo $PGPASS) --auth=trust
    echo "listen_addresses='*'" >> $PGDATA/postgresql.conf
    echo "unix_socket_directories='$PGHOST'" >> $PGDATA/postgresql.conf
    echo "unix_socket_permissions=0700" >> $PGDATA/postgresql.conf
fi
chmod o-rwx $PGDATA

'''

'''--- /Users/barneycook/Desktop/code/ProjectRef/postgres/ansible/playbook.yml ---
- hosts: all
  become: yes
  gather_facts: yes

  pre_tasks:
    - import_tasks: tasks/setup-system.yml
  vars_files:
    - ./vars.yml

  vars:
    sql_files:
      - {
          source: "pgbouncer_config/pgbouncer_auth_schema.sql",
          dest: "00-schema.sql",
        }
      - { source: "stat_extension.sql", dest: "01-extension.sql" }
    
  environment:
    PATH: /usr/lib/postgresql/bin:{{ ansible_env.PATH }}

  tasks:
    # New tasks to ensure git is installed and clone the repository
    - name: Ensure git is installed
      apt:
        name: git
        state: present

    # - name: Clone advaluepartners/postgres repo
    #   git:
    #     repo: 'https://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@github.com/advaluepartners/postgres.git'
    #     dest: /usr/local/src/advaluepartners-postgres
    #     version: main
  
    - set_fact:
        supabase_internal: true
      tags:
        - install-supabase-internal

    - set_fact:
        parallel_jobs: 16
        
    - name: Set system state for user management
      block:
        - name: Ensure nscd is installed (if using glibc)
          apt:
            name: nscd
            state: present
          when: ansible_os_family == "Debian"
          ignore_errors: yes

        - name: Clear system user/group cache
          shell: |
            if command -v nscd >/dev/null 2>&1; then
              nscd -i group
              nscd -i passwd
            fi
            systemctl daemon-reload
          ignore_errors: yes

    - name: Install Postgres from source
      import_tasks: tasks/setup-postgres.yml

    - name: Install PgBouncer
      import_tasks: tasks/setup-pgbouncer.yml
      tags:
        - install-pgbouncer
        - install-supabase-internal
      when: debpkg_mode or nixpkg_mode or stage2_nix

    - name: Install WAL-G
      import_tasks: tasks/setup-wal-g.yml
      when: debpkg_mode or nixpkg_mode or stage2_nix

    - name: Install Gotrue
      import_tasks: tasks/setup-gotrue.yml
      tags:
        - install-gotrue
        - install-supabase-internal
      when: debpkg_mode or nixpkg_mode or stage2_nix
      
    - name: Install PostgREST
      import_tasks: tasks/setup-postgrest.yml
      vars:
        postgresql_major: "{{ postgresql_major_version }}"
      tags:
        - install-postgrest
        - install-supabase-internal
      when: debpkg_mode or nixpkg_mode or stage2_nix

    - name: Install Envoy
      import_tasks: tasks/setup-envoy.yml
      tags:
        - install-supabase-internal
      when: debpkg_mode or nixpkg_mode or stage2_nix

    - name: Install Kong
      import_tasks: tasks/setup-kong.yml
      tags:
        - install-supabase-internal
      when: debpkg_mode or nixpkg_mode or stage2_nix

    - name: Install nginx
      import_tasks: tasks/setup-nginx.yml
      tags:
        - install-supabase-internal
      when: debpkg_mode or nixpkg_mode or stage2_nix

    - name: Install Vector
      import_tasks: tasks/setup-vector.yml
      tags:
        - install-supabase-internal
      when: debpkg_mode or nixpkg_mode or stage2_nix

    - name: Install Supabase specific content
      import_tasks: tasks/setup-supabase-internal.yml
      tags:
        - install-supabase-internal
      when: debpkg_mode or nixpkg_mode or stage2_nix

    - name: Fix IPv6 NDisc issues
      import_tasks: tasks/fix_ipv6_ndisc.yml
      tags:
        - install-supabase-internal
      when: debpkg_mode or nixpkg_mode

    - name: Start Postgres Database without Systemd
      become: yes
      become_user: postgres
      shell:
        cmd: /usr/lib/postgresql/bin/pg_ctl -D /var/lib/postgresql/data start
      when: debpkg_mode

    - name: Adjust APT update intervals
      copy:
        src: files/apt_periodic
        dest: /etc/apt/apt.conf.d/10periodic
      when: debpkg_mode or nixpkg_mode
      
    - name: Transfer init SQL files
      copy:
        src: files/{{ item.source }}
        dest: /tmp/{{ item.dest }}
      loop: "{{ sql_files }}"
      when: debpkg_mode or stage2_nix

    - name: Create postgres role
      become: yes
      become_user: postgres
      shell:
        cmd: /usr/lib/postgresql/bin/psql --username=capitala_admin -d postgres -c "create role postgres superuser login; alter database postgres owner to postgres;"
      when: debpkg_mode or stage2_nix

    - name: Execute init SQL files
      become: yes
      become_user: postgres
      shell:
        cmd: /usr/lib/postgresql/bin/psql -f /tmp/{{ item.dest }}
      loop: "{{ sql_files }}"
      when: debpkg_mode or stage2_nix

    - name: Delete SQL scripts
      file:
        path: /tmp/{{ item.dest }}
        state: absent
      loop: "{{ sql_files }}"
      when: debpkg_mode or stage2_nix

    - name: First boot optimizations
      import_tasks: tasks/internal/optimizations.yml
      tags:
        - install-supabase-internal
      when: debpkg_mode or stage2_nix
      
    - name: Finalize AMI
      import_tasks: tasks/finalize-ami.yml
      tags:
        - install-supabase-internal
      when: debpkg_mode or nixpkg_mode
      
    - name: Enhance fail2ban
      import_tasks: tasks/setup-fail2ban.yml
      when: debpkg_mode or nixpkg_mode

    - name: Install Admin API
      import_tasks: tasks/internal/admin-api.yml
      tags:
        - install-supabase-internal
      when: debpkg_mode or nixpkg_mode or stage2_nix

    - name: Internal tasks setup
      block:
        - name: Install supautils
          import_tasks: tasks/internal/supautils.yml
        - name: Setup postgresql-prestart
          import_tasks: tasks/internal/postgresql-prestart.yml
        - name: Setup admin-api
          import_tasks: tasks/internal/admin-api.yml
        - name: Install salt
          import_tasks: tasks/internal/install-salt.yml
        - name: Setup pg_egress_collect
          import_tasks: tasks/internal/pg_egress_collect.yml
        - name: Setup admin-mgr
          import_tasks: tasks/internal/admin-mgr.yml
        - name: Setup postgres-exporter
          import_tasks: tasks/internal/postgres-exporter.yml
        - name: Setup nftables
          import_tasks: tasks/internal/setup-nftables.yml
      when: debpkg_mode or nixpkg_mode or stage2_nix
      tags:
        - install-supabase-internal

    - name: install EC2 instance connect
      become: yes
      apt:
        pkg:
          - ec2-instance-connect
      tags:
        - aws-only

    - name: Install security tools
      become: yes
      apt:
        pkg:
          - unattended-upgrades
        update_cache: yes
        cache_valid_time: 3600

    - name: Clean out build dependencies
      import_tasks: tasks/clean-build-dependencies.yml

    - name: Ensure /run/postgresql exists for lock file creation
      become: yes
      file:
        path: /run/postgresql
        state: directory
        owner: postgres
        group: postgres
        mode: '2775'
      when: stage2_nix

    - name: Check if PostgreSQL is running
      become: yes
      become_user: postgres
      shell: /usr/lib/postgresql/bin/pg_ctl -D /var/lib/postgresql/data status
      args:
        executable: /bin/bash
      register: pg_status
      ignore_errors: yes
      when: stage2_nix

    - name: Force kill PostgreSQL process if running and remove stale PID file
      become: yes
      become_user: postgres
      shell: |
        if [ -f /var/lib/postgresql/data/postmaster.pid ]; then
          PID=$(head -n 1 /var/lib/postgresql/data/postmaster.pid)
          if ps -p $PID > /dev/null 2>&1; then
            echo "PostgreSQL process $PID is still running. Force killing..."
            kill -9 $PID
            sleep 2
          fi
          echo "Removing stale PID file"
          rm -f /var/lib/postgresql/data/postmaster.pid
        fi
      args:
        executable: /bin/bash
      when: stage2_nix

    - name: Ensure PostgreSQL is not running (double-check)
      become: yes
      become_user: postgres
      shell: /usr/lib/postgresql/bin/pg_ctl -D /var/lib/postgresql/data status
      args:
        executable: /bin/bash
      register: pg_status_after
      ignore_errors: yes
      when: stage2_nix

    - name: Fail if PostgreSQL is still running
      fail:
        msg: "PostgreSQL is still running after force kill; cannot start a new instance."
      when: stage2_nix and (pg_status_after.rc == 0)

    - name: Restart PostgreSQL without Systemd
      become: yes
      become_user: postgres
      ansible.builtin.shell: |
        export LANG=C
        export LANGUAGE=C
        export LC_ALL=C
        export LC_CTYPE=C
        export LOCALE_ARCHIVE=/usr/lib/locale/locale-archive
        . /var/lib/postgresql/.bashrc
        /usr/lib/postgresql/bin/pg_ctl -D /var/lib/postgresql/data start
      args:
        executable: /bin/bash
      when: stage2_nix

    - name: Setup Apache AGE extension (PRODUCTION FIX)
      become: yes
      become_user: postgres
      shell: |
        echo "=== AGE Extension Setup Started ==="
        
        # Wait for PostgreSQL to be fully ready
        echo "Waiting for PostgreSQL to be ready..."
        for i in {1..30}; do
          if psql -d postgres -c "SELECT 1;" > /dev/null 2>&1; then
            echo "PostgreSQL is ready after $i attempts"
            break
          fi
          echo "Attempt $i: PostgreSQL not ready, waiting..."
          sleep 2
          if [ $i -eq 30 ]; then
            echo "ERROR: PostgreSQL failed to become ready after 30 attempts"
            exit 1
          fi
        done
        
        # Verify AGE files exist before trying to create extension
        echo "=== Verifying AGE extension files ==="
        
        REQUIRED_FILES=(
          "/usr/lib/postgresql/lib/age.so"
          "/usr/lib/postgresql/share/postgresql/extension/age.control"
          "/usr/lib/postgresql/share/postgresql/extension/age--1.5.0.sql"
        )
        
        for file in "${REQUIRED_FILES[@]}"; do
          if [ ! -f "$file" ]; then
            echo "ERROR: Required file missing: $file"
            echo "Available AGE files:"
            ls -la /usr/lib/postgresql/share/postgresql/extension/age* 2>/dev/null || echo "No AGE extension files found"
            ls -la /usr/lib/postgresql/lib/age* 2>/dev/null || echo "No AGE library found"
            
            # Check if files are still in Nix store but not copied
            echo "Files still in Nix store:"
            find /nix/store -name "age--1.5.0.sql" || echo "Main script not in Nix store either"
            find /nix/store -name "age.control" || echo "Control file not in Nix store either"
            
            exit 1
          else
            echo " Found: $file"
          fi
        done
        
        # Critical verification: check main installation script content
        SCRIPT_SIZE=$(wc -l < "/usr/lib/postgresql/share/postgresql/extension/age--1.5.0.sql")
        if [ "$SCRIPT_SIZE" -lt 100 ]; then
          echo "ERROR: Main installation script too small ($SCRIPT_SIZE lines)"
          echo "This indicates the AGE build process failed to generate the proper script"
          echo "Expected: concatenated content from 16 SQL files (should be several hundred lines)"
          head -20 /usr/lib/postgresql/share/postgresql/extension/age--1.5.0.sql
          exit 1
        fi
        
        echo " Main installation script has $SCRIPT_SIZE lines (proper size)"
        echo "All required AGE files verified successfully"
        
        # Display control file content for debugging
        echo "=== AGE Control File Content ==="
        cat /usr/lib/postgresql/share/postgresql/extension/age.control
        
        # Check available extensions before creation
        echo "=== Checking available extensions ==="
        psql -d postgres -c "SELECT name, default_version, installed_version FROM pg_available_extensions WHERE name LIKE '%age%';"
        
        # Create AGE extension with detailed error handling
        echo "=== Creating AGE extension ==="
        if psql -d postgres -c "CREATE EXTENSION IF NOT EXISTS age CASCADE;" 2>&1; then
          echo "SUCCESS: AGE extension created successfully"
        else
          echo "ERROR: Failed to create AGE extension"
          echo "Checking PostgreSQL logs for errors..."
          tail -20 /var/lib/postgresql/data/log/postgresql*.log 2>/dev/null || echo "No PostgreSQL logs found"
          echo "Checking available extensions again..."
          psql -d postgres -c "SELECT name FROM pg_available_extensions WHERE name LIKE '%age%';"
          echo "Checking installed extensions..."
          psql -d postgres -c "\dx"
          exit 1
        fi
        
        # Load AGE library
        echo "=== Loading AGE library ==="
        if psql -d postgres -c "LOAD 'age';" 2>&1; then
          echo "SUCCESS: AGE library loaded successfully"
        else
          echo "ERROR: Failed to load AGE library"
          exit 1
        fi
        
        # Verify ag_catalog schema exists and set search path
        echo "=== Configuring AGE search path ==="
        psql -d postgres -c "DO \$\$ 
        BEGIN 
          IF EXISTS (SELECT 1 FROM pg_namespace WHERE nspname = 'ag_catalog') THEN 
            EXECUTE 'SET search_path = ag_catalog, \"\$user\", public'; 
            RAISE NOTICE 'AGE extension successfully configured with ag_catalog schema';
          ELSE
            RAISE WARNING 'ag_catalog schema not found - this may indicate AGE installation issues';
          END IF; 
        END \$\$;" 2>&1
        
        # Final verification of AGE installation
        echo "=== Final AGE Installation Verification ==="
        
        # Check extension is installed
        EXT_CHECK=$(psql -d postgres -t -c "SELECT extname, extversion FROM pg_extension WHERE extname = 'age';")
        if [ -n "$EXT_CHECK" ]; then
          echo "SUCCESS: AGE extension is installed: $EXT_CHECK"
        else
          echo "ERROR: AGE extension not found in pg_extension"
          psql -d postgres -c "\dx"
          exit 1
        fi
        
        # Check ag_catalog schema exists
        SCHEMA_CHECK=$(psql -d postgres -t -c "SELECT nspname FROM pg_namespace WHERE nspname = 'ag_catalog';")
        if [ -n "$SCHEMA_CHECK" ]; then
          echo "SUCCESS: ag_catalog schema exists"
        else
          echo "WARNING: ag_catalog schema not found"
        fi
        
        # Test basic AGE functionality
        echo "=== Testing basic AGE functionality ==="
        if psql -d postgres -c "SELECT ag_catalog.create_graph('test_graph');" 2>&1; then
          echo "SUCCESS: AGE basic functionality test passed"
          # Clean up test graph
          psql -d postgres -c "SELECT ag_catalog.drop_graph('test_graph', true);" 2>/dev/null || true
        else
          echo "WARNING: AGE basic functionality test failed, but extension is installed"
        fi
        
        echo "=== AGE Extension Setup Completed Successfully ==="
      args:
        executable: /bin/bash
      when: stage2_nix and postgresql_major_version == "15"
      register: age_setup_production
      changed_when: "'CREATE EXTENSION' in age_setup_production.stdout"
      failed_when: age_setup_production.rc != 0

    - name: Setup and add extensions
      import_tasks: tasks/setup-extensions.yml
      when: stage2_nix

    - name: Check if PostgreSQL PID file exists
      stat:
        path: /var/lib/postgresql/data/postmaster.pid
      register: pg_pid_file
      when: stage2_nix

    - name: Stop Postgres Database without Systemd (force shutdown)
      become: yes
      become_user: postgres
      shell: /usr/lib/postgresql/bin/pg_ctl -D /var/lib/postgresql/data stop -m immediate
      args:
        executable: /bin/bash
      when: stage2_nix and pg_pid_file.stat.exists

    - name: Run unit tests
      import_tasks: tasks/test-image.yml
      tags:
        - unit-tests
      when: debpkg_mode or stage2_nix

    - name: Collect Postgres binaries
      import_tasks: tasks/internal/collect-pg-binaries.yml
      tags:
        - collect-binaries
      when: debpkg_mode

    - name: Install osquery from nixpkgs binary cache
      become: yes
      shell: |
        sudo -u ubuntu bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix profile install github:nixos/nixpkgs/f98ec4f73c762223d62bee706726138cb6ea27cc#osquery"
      when: stage2_nix

    - name: Pre-check before osquery - Verify system state  
      shell: |
        echo "=== Final System State Check ==="
        echo "User details:"
        id pgbouncer
        echo "\nGroup memberships:"
        for group in postgres ssl-cert pgbouncer; do
          echo "$group:" $(getent group $group)
        done
      args:
        executable: /bin/bash
      register: final_system_check

    - name: Display final system state
      debug:
        var: final_system_check.stdout_lines

    - name: Ensure pgbouncer has correct group memberships
      fail:
        msg: "pgbouncer user is missing required group memberships"
      when: >
        final_system_check.stdout is not search('postgres') or
        final_system_check.stdout is not search('ssl-cert') or
        final_system_check.stdout is not search('pgbouncer')

    # - name: Run osquery permission checks
    #   become: yes
    #   shell: |
    #     sudo -u ubuntu bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && /usr/bin/python3 /tmp/ansible-playbook/ansible/files/permission_check.py"
    #   when: stage2_nix

    #  SAFE VERSION: Non-blocking permission checks with comprehensive error handling
    - name: Check if osquery is available
      shell: |
        sudo -u ubuntu bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && which osqueryi"
      register: osquery_available
      failed_when: false
      changed_when: false
      when: stage2_nix

    - name: Check if permission check script exists
      stat:
        path: /tmp/ansible-playbook/ansible/files/permission_check.py
      register: permission_script_exists
      when: stage2_nix

    - name: Run osquery permission checks
      become: yes
      shell: |
        echo "=== Starting osquery permission validation ==="
        sudo -u ubuntu bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && /usr/bin/python3 /tmp/ansible-playbook/ansible/files/permission_check.py"
      register: osquery_permission_result
      failed_when: false  #  CRITICAL: Never fail the build on permission issues
      changed_when: false
      when: 
        - stage2_nix
        - osquery_available.rc == 0
        - permission_script_exists.stat.exists
      timeout: 300  # 5 minute timeout for safety

    - name: Report osquery permission check results
      debug:
        msg: |
           osquery Permission Check Results:
          {% if osquery_available.rc != 0 %}
            osquery not available - permission checks skipped
          {% elif not permission_script_exists.stat.exists %}
            Permission check script not found - checks skipped
          {% elif osquery_permission_result.rc == 0 %}
           All permission checks passed successfully
          {% else %}
            Some permission issues detected (non-critical):
          {{ osquery_permission_result.stdout | default('No output') }}
          
          This is informational only and won't affect the build.
          {% endif %}
      when: stage2_nix

    - name: Display permission check details (when available)
      debug:
        var: osquery_permission_result.stdout_lines
      when: 
        - stage2_nix
        - osquery_permission_result is defined
        - osquery_permission_result.stdout is defined

    - name: Log permission check issues for investigation (if any)
      debug:
        msg: |
           Permission Check Details for Investigation:
          - Exit Code: {{ osquery_permission_result.rc | default('N/A') }}
          - stderr: {{ osquery_permission_result.stderr | default('None') }}
          
          Note: These issues do not affect the build and are for informational purposes only.
      when: 
        - stage2_nix
        - osquery_permission_result is defined
        - osquery_permission_result.rc != 0

    - name: Remove osquery
      become: yes
      shell: |
        sudo -u ubuntu bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix profile remove osquery"
      when: stage2_nix

    - name: nix collect garbage
      become: yes
      shell: |
        sudo -u ubuntu bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix-collect-garbage -d"
      when: stage2_nix

    - name: FINAL VERIFICATION - Check for pg_ctl after all cleanup
      become: yes
      shell: |
        echo "=== Verifying final existence of pg_ctl ==="
        find / -name pg_ctl 2>/dev/null
        echo "=== Verifying symlink in /usr/lib/postgresql/bin ==="
        ls -la /usr/lib/postgresql/bin/pg_ctl
      register: final_verification_check
      ignore_errors: true

    - name: FINAL VERIFICATION - Display results
      debug:
        var: final_verification_check.stdout_lines

'''

'''--- /Users/barneycook/Desktop/code/ProjectRef/postgres/ansible/tasks/setup-postgres.yml ---
- name: Debug - PostgreSQL pre-setup
  shell: |
    echo "=== System State ==="
    echo "Groups:"
    getent group postgres ssl-cert || echo "Groups not found"
    echo "====="
  register: pre_postgres_debug
  changed_when: false

- name: Show PostgreSQL pre-setup debug
  debug:
    var: pre_postgres_debug.stdout_lines

- name: Postgres - copy package
  copy:
    src: files/postgres/
    dest: /tmp/build/
  when: debpkg_mode

- name: Postgres - add PPA
  apt_repository:
    repo: "deb [ trusted=yes ] file:///tmp/build ./"
    state: present
  when: debpkg_mode

- name: Postgres - install commons
  apt:
    name: postgresql-common
    install_recommends: no
  when: debpkg_mode

- name: Do not create main cluster
  shell:
    cmd: sed -ri 's/#(create_main_cluster) .*$/\1 = false/' /etc/postgresql-common/createcluster.conf
  when: debpkg_mode

- name: Postgres - install server
  apt:
    name: postgresql-{{ postgresql_major }}={{ postgresql_release }}-1.pgdg20.04+1
    install_recommends: no
  when: debpkg_mode

- name: Postgres - remove PPA
  apt_repository:
    repo: "deb [ trusted=yes ] file:///tmp/build ./"
    state: absent
  when: debpkg_mode

- name: Postgres - cleanup package
  file:
    path: /tmp/build
    state: absent
  when: debpkg_mode

- name: install locales
  apt:
    name: locales
    state: present
  become: yes
  when: stage2_nix

- name: configure locales
  copy:
    dest: /etc/locale.gen
    content: |
      C.UTF-8 UTF-8
      en_US.UTF-8 UTF-8
  become: yes
  when: stage2_nix

- name: locale-gen
  command: sudo locale-gen
  when: stage2_nix

- name: update-locale
  command: sudo update-locale
  when: stage2_nix

- name: Ensure required locales are installed
  become: yes
  shell: |
    apt-get update
    apt-get install -y locales
    echo "en_US.UTF-8 UTF-8" >> /etc/locale.gen
    locale-gen
    update-locale LANG=en_US.UTF-8 LC_ALL=en_US.UTF-8
  when: stage2_nix

- name: Create symlink to /usr/lib/postgresql/bin
  shell:
    cmd: ln -s /usr/lib/postgresql/{{ postgresql_major }}/bin /usr/lib/postgresql/bin
  when: debpkg_mode

- name: Ensure PostgreSQL include/server directory exists
  file:
    path: /usr/lib/postgresql/include/server
    state: directory
    owner: postgres
    group: postgres
    mode: '0755'
  when: stage2_nix


- name: Create symlinks for PostgreSQL headers
  shell: |
    ln -sf /var/lib/postgresql/.nix-profile/include/* /usr/lib/postgresql/include/server/
  become: yes
  when: stage2_nix

- name: Create symbolic links for PostgreSQL header files
  file:
    src: "{{ item }}"
    dest: "/usr/lib/postgresql/include/server/{{ item | basename }}"
    state: link
  with_fileglob:
    - "/var/lib/postgresql/.nix-profile/include/*.h"
  become: yes
  when: stage2_nix


# - name: create ssl-cert group
#   group:
#     name: ssl-cert
#     state: present
#   when: nixpkg_mode

# - name: create postgres group
#   group:
#     name: postgres
#     state: present
#   when: nixpkg_mode

# - name: create postgres user
#   shell: adduser --system  --home /var/lib/postgresql --no-create-home --shell /bin/bash --group --gecos "PostgreSQL administrator" postgres
#   args:
#     executable: /bin/bash
#   become: yes
#   when: nixpkg_mode

# - name: add postgres user to postgres group
#   shell: usermod -a -G ssl-cert postgres
#   args:
#     executable: /bin/bash
#   become: yes
#   when: nixpkg_mode

- name: create ssl-cert group
  group:
    name: ssl-cert
    state: present
    gid: 1001
  when: nixpkg_mode

- name: create postgres group
  group:
    name: postgres
    state: present
    gid: 1002
  when: nixpkg_mode

- name: Create postgres user and set primary group
  user:
    name: postgres
    system: yes
    home: /var/lib/postgresql
    shell: /bin/bash
    group: postgres
    groups: []
  when: nixpkg_mode

- name: Add postgres to additional groups
  user:
    name: postgres
    group: postgres
    groups: ssl-cert
    append: yes
  when: nixpkg_mode

- name: Verify postgres user groups
  shell: |
    echo "=== Verifying postgres user groups ==="
    id postgres
    echo "Group memberships:"
    getent group postgres
    getent group ssl-cert
  register: verify_postgres
  changed_when: false
  when: nixpkg_mode

- name: Show verification results
  debug:
    var: verify_postgres.stdout_lines
  when: nixpkg_mode

- name: Force system to recognize group changes
  shell: |
    # Reload system group cache
    systemctl daemon-reload
    # Force group membership update
    pkill -SIGHUP -u postgres || true
  changed_when: false
  when: nixpkg_mode

- name: Create relevant directories
  file:
    path: '{{ item }}'
    recurse: yes
    state: directory
    owner: postgres
    group: postgres
  with_items:
    - '/home/postgres'
    - '/var/log/postgresql'
    - '/var/lib/postgresql'
  when: debpkg_mode or nixpkg_mode

- name: Allow adminapi to write custom config
  file:
    path: '{{ item }}'
    recurse: yes
    state: directory
    owner: postgres
    group: postgres
    mode: 0775
  with_items:
    - '/etc/postgresql'
    - '/etc/postgresql-custom'
  when: debpkg_mode or nixpkg_mode

- name: create placeholder config files
  file:
    path: '/etc/postgresql-custom/{{ item }}'
    state: touch
    owner: postgres
    group: postgres
    mode: 0664
  with_items:
    - 'generated-optimizations.conf'
    - 'custom-overrides.conf'
  when: debpkg_mode or nixpkg_mode

# Move Postgres configuration files into /etc/postgresql
# Add postgresql.conf
- name: import postgresql.conf
  template:
    src: files/postgresql_config/postgresql.conf.j2
    dest: /etc/postgresql/postgresql.conf
    group: postgres
  when: debpkg_mode or nixpkg_mode

# Add pg_hba.conf
- name: import pg_hba.conf
  template:
    src: files/postgresql_config/pg_hba.conf.j2
    dest: /etc/postgresql/pg_hba.conf
    group: postgres
  when: debpkg_mode or nixpkg_mode

# Add pg_ident.conf
- name: import pg_ident.conf
  template:
    src: files/postgresql_config/pg_ident.conf.j2
    dest: /etc/postgresql/pg_ident.conf
    group: postgres
  when: debpkg_mode or nixpkg_mode

# Add custom config for read replicas set up
- name: Move custom read-replica.conf file to /etc/postgresql-custom/read-replica.conf
  template:
    src: "files/postgresql_config/custom_read_replica.conf.j2"
    dest: /etc/postgresql-custom/read-replica.conf
    mode: 0664
    owner: postgres
    group: postgres
  when: debpkg_mode or nixpkg_mode

# Install extensions before init
- name: Install Postgres extensions
  import_tasks: tasks/setup-docker.yml
  when: debpkg_mode or stage2_nix


#stage 2 postgres tasks
- name: stage2 postgres tasks
  import_tasks: tasks/stage2-setup-postgres.yml
  when: stage2_nix

- name: Create directory on data volume
  file:
    path: '{{ item }}'
    recurse: yes
    state: directory
    owner: postgres
    group: postgres
    mode: 0750
  with_items:
    - "/data/pgdata"
  when: debpkg_mode or nixpkg_mode

- name: Link database data_dir to data volume directory
  file:
    src: "/data/pgdata"
    path: "/var/lib/postgresql/data"
    state: link
    force: yes
  when: debpkg_mode or nixpkg_mode

### Test1 Block Sunday 23 -- added the below 
- name: Debug pg_config sharedir
  shell: "/usr/bin/pg_config --sharedir"
  register: pg_config_sharedir
  become: yes
  when: stage2_nix

- name: Display pg_config sharedir
  debug:
    var: pg_config_sharedir.stdout
  when: stage2_nix

- name: Debug pg_config from bin directory
  shell: "/usr/lib/postgresql/bin/pg_config --sharedir"
  register: pg_config_bin_sharedir
  become: yes
  when: stage2_nix

- name: Display pg_config from bin directory
  debug:
    var: pg_config_bin_sharedir.stdout
  when: stage2_nix

- name: Ensure extension directory exists
  file:
    path: "/usr/lib/postgresql/share/postgresql/extension"
    state: directory
    owner: postgres
    group: postgres
    mode: '0755'
  become: yes
  when: stage2_nix

- name: Debug source extension directory
  shell: "ls -l /var/lib/postgresql/.nix-profile/share/postgresql/extension/"
  register: source_ext_debug
  become: yes
  when: stage2_nix

- name: Display source extension directory contents
  debug:
    var: source_ext_debug.stdout_lines
  when: stage2_nix

- name: Copy extension files from Nix profile
  shell: |
    cp -rf /var/lib/postgresql/.nix-profile/share/postgresql/extension/* /usr/lib/postgresql/share/postgresql/extension/
  become: yes
  when: stage2_nix

# - name: Set ownership of extension files
#   file:
#     path: "/usr/lib/postgresql/share/postgresql/extension"
#     owner: postgres
#     group: postgres
#     recurse: yes
#   become: yes
#   when: stage2_nix

- name: Set ownership and permissions of extension files
  file:
    path: "/usr/lib/postgresql/share/postgresql/extension"
    owner: postgres
    group: postgres
    mode: '0755'
    recurse: yes
  become: yes
  when: stage2_nix


- name: Debug plpgsql.control file status
  shell: "ls -l /usr/lib/postgresql/share/postgresql/extension/plpgsql.control || echo 'File not found'"
  register: plpgsql_file_debug
  become: yes
  when: stage2_nix

- name: Display plpgsql.control file details
  debug:
    var: plpgsql_file_debug.stdout
  when: stage2_nix


- name: Debug extension file status
  shell: "ls -l /usr/lib/postgresql/share/postgresql/extension/uuid-ossp.control || echo 'File not found'"
  register: ext_file_debug
  become: yes
  when: stage2_nix

- name: Display extension file details
  debug:
    var: ext_file_debug.stdout
  when: stage2_nix

- name: Test access to plpgsql.control
  become: yes
  become_user: postgres
  shell: "cat /usr/lib/postgresql/share/postgresql/extension/plpgsql.control > /dev/null || echo 'Access denied'"
  register: access_test
  ignore_errors: yes
  when: stage2_nix

- name: Display access test result
  debug:
    var: access_test.stdout
  when: stage2_nix

- name: Debug parent directory permissions
  shell: "ls -ld /usr/lib/postgresql /usr/lib/postgresql/share /usr/lib/postgresql/share/postgresql /usr/lib/postgresql/share/postgresql/extension"
  register: parent_dir_debug
  become: yes
  when: stage2_nix

- name: Display parent directory permissions
  debug:
    var: parent_dir_debug.stdout_lines
  when: stage2_nix


### Test1 Block Sunday 23 -- added the below 

### last added
- name: Ensure parent directories are accessible
  file:
    path: "{{ item }}"
    state: directory
    owner: postgres
    group: postgres
    mode: '0755'
  loop:
    - "/usr/lib/postgresql"
    - "/usr/lib/postgresql/share"
    - "/usr/lib/postgresql/share/postgresql"
    - "/usr/lib/postgresql/share/postgresql/extension"
  become: yes
  when: stage2_nix

- name: Test access to plpgsql.control
  become: yes
  become_user: postgres
  shell: "cat /usr/lib/postgresql/share/postgresql/extension/plpgsql.control > /dev/null || echo 'Access denied'"
  register: access_test
  ignore_errors: yes
  when: stage2_nix

- name: Display access test result
  debug:
    var: access_test.stdout
  when: stage2_nix

- name: Initialize the database
  become: yes
  become_user: postgres
  shell: /usr/lib/postgresql/bin/pg_ctl -D /var/lib/postgresql/data initdb -o "--allow-group-access" -o "--username=capitala_admin"
  vars:
    ansible_command_timeout: 60
  when: debpkg_mode

- name: Check psql_version and modify supautils.conf and postgresql.conf if necessary
  block:
    - name: Check if psql_version is psql_orioledb
      set_fact:
        is_psql_oriole: "{{ psql_version in ['psql_orioledb-16', 'psql_orioledb-17'] }}"

    ##  Wednesday 26th -- capitala config -- 
    # - name: Initialize the database stage2_nix (non-orioledb)
    #   become: yes
    #   become_user: postgres
    #   shell: source /var/lib/postgresql/.bashrc && /usr/lib/postgresql/bin/pg_ctl -D /var/lib/postgresql/data initdb -o "--allow-group-access" -o "--username=capitala_admin"
    #   args:
    #     executable: /bin/bash
    #   environment:
    #     LANG: en_US.UTF-8
    #     LANGUAGE: en_US.UTF-8
    #     LC_ALL: en_US.UTF-8
    #     LC_CTYPE: en_US.UTF-8
    #     LOCALE_ARCHIVE: /usr/lib/locale/locale-archive
    #   vars:
    #     ansible_command_timeout: 60
    #   when: stage2_nix and not is_psql_oriole

    - name: Initialize the database stage2_nix (non-orioledb)
      become: yes
      become_user: postgres
      shell: source /var/lib/postgresql/.bashrc && /usr/lib/postgresql/bin/pg_ctl -D /var/lib/postgresql/data initdb -o "--allow-group-access" -o "--username=capitala_admin" -o "--locale=C"
      args:
        executable: /bin/bash
      environment:
        LANG: C
        LC_ALL: C
      vars:
        ansible_command_timeout: 60
      when: stage2_nix and not is_psql_oriole

    # - name: Initialize the database stage2_nix (orioledb)
    #   become: yes
    #   become_user: postgres
    #   shell: >
    #     source /var/lib/postgresql/.bashrc && initdb -D /var/lib/postgresql/data 
    #     --allow-group-access 
    #     --username=capitala_admin 
    #     --locale-provider=icu 
    #     --encoding=UTF-8 
    #     --icu-locale=en_US.UTF-8 
    #   args:
    #     executable: /bin/bash
    #   environment:
    #     LANG: en_US.UTF-8
    #     LANGUAGE: en_US.UTF-8
    #     LC_ALL: en_US.UTF-8
    #     LC_CTYPE: en_US.UTF-8
    #     LOCALE_ARCHIVE: /usr/lib/locale/locale-archive
    #   vars:
    #     ansible_command_timeout: 60
    #   when: stage2_nix and is_psql_oriole

- name: Initialize the database stage2_nix (orioledb)
  become: yes
  become_user: postgres
  shell: >
    source /var/lib/postgresql/.bashrc && initdb -D /var/lib/postgresql/data 
    --allow-group-access 
    --username=capitala_admin 
    --locale=C
    --encoding=UTF8
  args:
    executable: /bin/bash
  environment:
    LANG: C
    LC_ALL: C
  vars:
    ansible_command_timeout: 60
  when: stage2_nix and is_psql_oriole

- name: Ensure postgresql.conf uses C locale
  become: yes
  lineinfile:
    path: /etc/postgresql/postgresql.conf
    line: "{{ item }}"
    state: present
  with_items:
    - "lc_messages = 'C'"
    - "lc_monetary = 'C'"
    - "lc_numeric = 'C'"
    - "lc_time = 'C'"
  when: stage2_nix

############ Wednesday 26th Capital a 

- name: Create systemd service file for PostgreSQL
  become: yes
  template:
    src: /tmp/ansible-playbook/ansible/files/postgresql_config/postgresql.service.j2
    dest: /etc/systemd/system/postgresql.service
    owner: root
    group: root
    mode: '0644'
  when: stage2_nix

- name: Reload systemd daemon
  become: yes
  systemd:
    daemon_reload: yes
  when: stage2_nix

- name: copy PG systemd unit
  template:
    src: files/postgresql_config/postgresql.service.j2
    dest: /etc/systemd/system/postgresql.service
  when: debpkg_mode or stage2_nix

- name: copy optimizations systemd unit
  template:
    src: files/database-optimizations.service.j2
    dest: /etc/systemd/system/database-optimizations.service
  when: debpkg_mode or stage2_nix

- name: Ensure /run/postgresql exists for lock file creation
  become: yes
  file:
    path: /run/postgresql
    state: directory
    owner: postgres
    group: postgres
    mode: '2775'
  when: stage2_nix

- name: Check if PostgreSQL PID file exists
  stat:
    path: /var/lib/postgresql/data/postmaster.pid
  register: pg_pid_file
  when: stage2_nix

- name: Stop Postgres Database without Systemd (force shutdown)
  become: yes
  become_user: postgres
  shell: /usr/lib/postgresql/bin/pg_ctl -D /var/lib/postgresql/data stop -m immediate
  args:
    executable: /bin/bash
  when: stage2_nix and pg_pid_file.stat.exists

- name: Restart Postgres Database without Systemd
  become: yes
  become_user: postgres
  ansible.builtin.shell: |
    # Export environment variables inline
    # export LANG=en_US.UTF-8
    # export LANGUAGE=en_US:en
    # export LC_ALL=en_US.UTF-8
    # export LC_CTYPE=en_US.UTF-8
    export LOCALE_ARCHIVE=/usr/lib/locale/locale-archive
    export LANG=C
    export LANGUAGE=C
    export LC_ALL=C
    export LC_CTYPE=C
    export LOCALE_ARCHIVE=/usr/lib/locale/locale-archive
    # Use the POSIX . operator instead of source
    . /var/lib/postgresql/.bashrc
    /usr/lib/postgresql/bin/pg_ctl -D /var/lib/postgresql/data start
  args:
    executable: /bin/bash
  when: stage2_nix


# Reload
- name: System - systemd reload
  systemd:
    enabled: yes
    name: postgresql
    daemon_reload: yes
  when: debpkg_mode or stage2_nix

- name: Make sure .bashrc exists
  file: 
    path: /var/lib/postgresql/.bashrc 
    state: touch
    owner: postgres
    group: postgres
  when: nixpkg_mode 

- name: Add LOCALE_ARCHIVE to .bashrc
  lineinfile:
    dest: "/var/lib/postgresql/.bashrc"
    line: 'export LOCALE_ARCHIVE=/usr/lib/locale/locale-archive'
    create: yes
  become: yes
  when: nixpkg_mode

- name: Add LANG items to .bashrc
  lineinfile:
    dest: "/var/lib/postgresql/.bashrc"
    line: "{{ item }}"
  loop: 
    - 'export LANG="en_US.UTF-8"'
    - 'export LANGUAGE="en_US.UTF-8"'
    - 'export LC_ALL="en_US.UTF-8"'
    - 'export LANG="en_US.UTF-8"'
    - 'export LC_CTYPE="en_US.UTF-8"'
  become: yes
  when: nixpkg_mode

- name: Ensure pg_config symlink points to nix installation
  file:
    src: "/var/lib/postgresql/.nix-profile/bin/pg_config"
    dest: "/usr/bin/pg_config"
    state: link
    force: yes
  when: stage2_nix
'''

'''--- /Users/barneycook/Desktop/code/ProjectRef/postgres/ansible/tasks/stage2-setup-postgres.yml ---
# - name: Install openjdk11 for pljava from nix binary cache
#   become: yes
#   shell: |
#     sudo -u postgres bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix profile install nixpkgs#openjdk11"
# It was decided to leave pljava disabled at https://github.com/supabase/postgres/pull/690 therefore removing this task

- name: Check psql_version and modify supautils.conf and postgresql.conf if necessary
  block:
    - name: Check if psql_version is psql_orioledb-16
      set_fact:
        is_psql_oriole: "{{ psql_version in ['psql_orioledb-16', 'psql_orioledb-17'] }}"

    - name: Remove specified extensions from postgresql.conf if oriole-16 build
      ansible.builtin.command:
        cmd: >
          sed -i 's/ timescaledb,//g' 
          /etc/postgresql/postgresql.conf
      when: is_psql_oriole and stage2_nix
      become: yes

    - name: Remove specified extensions from supautils.conf if oriole-16 build
      ansible.builtin.command:
        cmd: >
          sed -i 's/ timescaledb,//g; s/ vector,//g; s/ plv8,//g; s/ postgis,//g; s/ pgrouting,//g' 
          /etc/postgresql-custom/supautils.conf
      when: is_psql_oriole and stage2_nix
      become: yes

    - name: Remove db_user_namespace from postgresql.conf if oriole-xx build
      ansible.builtin.command:
        cmd: >
          sed -i 's/db_user_namespace = off/#db_user_namespace = off/g;' 
          /etc/postgresql/postgresql.conf
      when: is_psql_oriole and stage2_nix
      become: yes

    - name: Append orioledb to shared_preload_libraries append within closing quote
      ansible.builtin.command:
        cmd: >
          sed -i 's/\(shared_preload_libraries.*\)'\''\(.*\)$/\1, orioledb'\''\2/'
          /etc/postgresql/postgresql.conf
      when: is_psql_oriole and stage2_nix
      become: yes

    - name: Add default_table_access_method setting
      ansible.builtin.lineinfile:
        path: /etc/postgresql/postgresql.conf
        line: "default_table_access_method = 'orioledb'"
        state: present
      when: is_psql_oriole and stage2_nix
      become: yes
    
    - name: Add ORIOLEDB_ENABLED environment variable
      ansible.builtin.lineinfile:
        path: /etc/environment
        line: 'ORIOLEDB_ENABLED=true'
      when: is_psql_oriole and stage2_nix
      become: yes

- name: Ensure /tmp/ansible-playbook is writable by postgres
  become: yes
  file:
    path: /tmp/ansible-playbook
    owner: postgres
    group: postgres
    mode: '0755'
    recurse: yes
  when: stage2_nix

- name: Debug supabase-groonga.nix contents
  become: yes
  shell: |
    cat /tmp/ansible-playbook/nix/supabase-groonga.nix || echo "File not found"
    ls -l /tmp/ansible-playbook/nix/
    sha256sum /tmp/ansible-playbook/nix/supabase-groonga.nix || echo "Checksum failed"
  when: stage2_nix
  register: groonga_debug
- debug:
    var: groonga_debug.stdout_lines
  when: stage2_nix

- name: Debug Nix environment before install
  shell: |
    echo "=== Environment Variables ==="
    env | grep -E "(TMPDIR|NIX_|BUILD)"
    echo "=== Nix Config ==="
    sudo -u postgres bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix show-config | head -20"
    echo "=== Available Space ==="
    df -h
    echo "=== Nix Store Location ==="
    sudo -u postgres bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix-store --version && nix eval --expr 'builtins.storeDir'"
  register: debug_nix_env

- name: Show debug output
  debug:
    var: debug_nix_env.stdout_lines

- name: Verify nix directory structure
  shell: |
    echo "=== Checking /tmp/ansible-playbook structure ==="
    ls -la /tmp/ansible-playbook/
    echo "=== Checking for nix directory ==="
    ls -la /tmp/ansible-playbook/nix/ || echo "nix directory missing"
    echo "=== Checking for cargo-pgrx ==="
    ls -la /tmp/ansible-playbook/nix/cargo-pgrx/ || echo "cargo-pgrx directory missing"
    echo "=== Checking for default.nix ==="
    ls -la /tmp/ansible-playbook/nix/cargo-pgrx/default.nix || echo "default.nix missing"
  when: stage2_nix
  register: nix_structure_check

- name: Show nix structure check results
  debug:
    var: nix_structure_check.stdout_lines
  when: stage2_nix

- name: Install Postgres from local flake
  become: yes
  shell: |
    chown -R postgres:postgres /var/lib/postgresql
    sudo -u postgres bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix --extra-experimental-features 'nix-command flakes' profile install --accept-flake-config /tmp/ansible-playbook#{{ psql_version }}/bin"
  when: stage2_nix
  register: install_postgres
  retries: 3
  delay: 5
  until: install_postgres.rc == 0

- name: Debug Nix profile contents
  become: yes
  shell: |
    sudo -u postgres bash -c "ls -l /var/lib/postgresql/.nix-profile"
    sudo -u postgres bash -c "ls -l /var/lib/postgresql/.nix-profile/lib || true"
    sudo -u postgres bash -c "ls -l /var/lib/postgresql/.nix-profile/include || true"
  when: stage2_nix
  register: nix_profile_debug
- debug:
    var: nix_profile_debug.stdout_lines
  when: stage2_nix

- name: Ensure PostgreSQL include subdirectories exist
  file:
    path: /usr/lib/postgresql/include/server
    state: directory
    owner: postgres
    group: postgres
    mode: '0755'
  when: stage2_nix

- name: Remove existing PostgreSQL include directory (ARM64 fix)
  file:
    path: /usr/lib/postgresql/include
    state: absent
  when: ansible_architecture == 'aarch64' and stage2_nix
  become: yes

- name: Debug contents of /var/lib/postgresql/.nix-profile/lib
  shell: ls -l /var/lib/postgresql/.nix-profile/lib
  register: lib_contents
  become: yes
  when: stage2_nix

- name: Show lib contents
  debug:
    var: lib_contents.stdout_lines
  when: stage2_nix

- name: Create ARM64 specific symlinks
  file:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
    state: link
  with_items:
    - { src: "/var/lib/postgresql/.nix-profile/lib", dest: "/usr/lib/postgresql/lib" }
    - { src: "/var/lib/postgresql/.nix-profile/include", dest: "/usr/lib/postgresql/include" }
  become: yes
  when: stage2_nix

- name: Create robust symbolic links for all Nix binaries
  become: yes
  file:
    src: "{{ item }}"
    dest: "/usr/local/bin/{{ item | basename }}"
    state: link
  with_fileglob:
    - "/var/lib/postgresql/.nix-profile/bin/*"

- name: Create symlinks for PostgreSQL headers
  file:
    src: "{{ item }}"
    dest: "/usr/lib/postgresql/include/server/{{ item | basename }}"
    state: link
  with_fileglob:
    - "/var/lib/postgresql/.nix-profile/include/*.h"
  become: yes
  when:
    - stage2_nix
    - ansible_architecture != 'aarch64'

- name: Install pg_prove from local flake
  become: yes
  shell: |
    sudo -u postgres bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix profile install /tmp/ansible-playbook#pg_prove"
  when: stage2_nix
  register: install_pg_prove
  retries: 3
  delay: 5
  until: install_pg_prove.rc == 0

- name: Install supabase-groonga from local flake  
  become: yes
  shell: |
    sudo -u postgres bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix profile install /tmp/ansible-playbook#supabase_groonga"
  when: stage2_nix and ansible_architecture != 'aarch64'
  register: install_supabase_groonga
  retries: 3
  delay: 5
  until: install_supabase_groonga.rc == 0

- name: Skip supabase-groonga on ARM64 (using local alternative)
  debug:
    msg: "Skipping supabase-groonga installation on ARM64 - using local supabase_groonga package"
  when: stage2_nix and ansible_architecture == 'aarch64'


- name: Skip supabase-groonga on ARM
  debug:
    msg: "Skipping supabase-groonga installation on ARM architecture"
  when: stage2_nix and ansible_architecture == 'aarch64'

- name: Configure ARM-specific settings
  set_fact:
    platform_specific_paths:
      lib_dir: "/lib/aarch64-linux-gnu"
      include_dir: "/usr/include/aarch64-linux-gnu"
  when: ansible_architecture == 'arm64'

- name: Install debug symbols from local flake (optional)
  become: yes
  shell: |
    sudo -u postgres bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix profile install /tmp/ansible-playbook#postgresql_{{ postgresql_major_version }}_debug"
  when:
    - stage2_nix
    - ansible_architecture != 'aarch64'
    - install_debug_symbols | default(false)  # Make this optional
  register: install_debug_symbols_result
  retries: 3
  delay: 5
  until: install_debug_symbols_result.rc == 0
  ignore_errors: yes  # Don't fail build if debug symbols fail

  
- name: Set ownership and permissions for /etc/ssl/private
  become: yes
  file:
    path: /etc/ssl/private
    owner: root
    group: postgres
    mode: '0750'
  when: stage2_nix

- name: Set permissions for postgresql.env
  become: yes
  file:
    path: /etc/environment.d/postgresql.env
    owner: postgres
    group: postgres
    mode: '0644'
  when: stage2_nix

- name: Ensure /usr/lib/postgresql/bin directory exists
  file:
    path: /usr/lib/postgresql/bin
    state: directory
    owner: postgres
    group: postgres
  when: stage2_nix

- name: Ensure /usr/lib/postgresql/share directory exists
  file:
    path: /usr/lib/postgresql/share/postgresql
    state: directory
    owner: postgres
    group: postgres
  when: stage2_nix

- name: Ensure /usr/lib/postgresql/share/contrib directory exists
  file:
    path: /usr/lib/postgresql/share/postgresql/contrib
    state: directory
    owner: postgres
    group: postgres
  when: stage2_nix

- name: Ensure /usr/lib/postgresql/share/timezonesets directory exists
  file:
    path: /usr/lib/postgresql/share/postgresql/timezonesets
    state: directory
    owner: postgres
    group: postgres
  when: stage2_nix

- name: Ensure /usr/lib/postgresql/share/tsearch_data directory exists
  file:
    path: /usr/lib/postgresql/share/postgresql/tsearch_data
    state: directory
    owner: postgres
    group: postgres
  when: stage2_nix

- name: Ensure /usr/lib/postgresql/share/extension directory exists
  file:
    path: /usr/lib/postgresql/share/postgresql/extension
    state: directory
    owner: postgres
    group: postgres
  when: stage2_nix

# - name: Ensure /usr/lib/postgresql/share/postgresql/pljava directory exists
#   file:
#     path: /usr/lib/postgresql/share/postgresql/pljava
#     state: directory
#     owner: postgres
#     group: postgres
#   when: stage2_nix
# It was decided to leave pljava disabled at https://github.com/supabase/postgres/pull/690 therefore removing this task

- name: import pgsodium_getkey script
  template:
    src: /tmp/ansible-playbook/ansible/files/pgsodium_getkey_readonly.sh.j2
    dest: "/usr/lib/postgresql/bin/pgsodium_getkey.sh"
    owner: postgres
    group: postgres
    mode: 0700
  when: stage2_nix

- name: Create symbolic links from /var/lib/postgresql/.nix-profile/bin to /usr/lib/postgresql/bin
  file:
    src: "{{ item }}"
    dest: "/usr/lib/postgresql/bin/{{ item | basename }}"
    state: link
  with_fileglob:
    - "/var/lib/postgresql/.nix-profile/bin/*"
  become: yes
  when: stage2_nix

- name: Check if /usr/bin/pg_config exists
  stat:
    path: /usr/bin/pg_config
  register: pg_config_stat
  when: stage2_nix

- name: Remove existing /usr/bin/pg_config if it is not a symlink
  file:
    path: /usr/bin/pg_config
    state: absent
  when: pg_config_stat.stat.exists and not pg_config_stat.stat.islnk and stage2_nix
  become: yes

- name: Create symbolic links from /var/lib/postgresql/.nix-profile/bin to /usr/bin
  file:
    src: "{{ item }}"
    dest: "/usr/bin/{{ item | basename }}"
    state: link
  with_fileglob:
    - "/var/lib/postgresql/.nix-profile/bin/*"
  become: yes
  when: stage2_nix

- name: Ensure postgres user has ownership of symlink
  file:
    path: "/usr/bin/{{ item | basename }}"
    owner: postgres
    group: postgres
  with_fileglob:
    - "/var/lib/postgresql/.nix-profile/bin/*"
  become: yes
  when: stage2_nix

# - name: Create symbolic links from /var/lib/postgresql/.nix-profile/share/pljava to /usr/lib/postgresql/share/postgresql/pljava
#   file:
#     src: "{{ item }}"
#     dest: "/usr/lib/postgresql/share/postgresql/pljava/{{ item | basename }}"
#     state: link
#   with_fileglob:
#     - "/var/lib/postgresql/.nix-profile/share/pljava/*"
#   become: yes
# It was decided to leave pljava disabled at https://github.com/supabase/postgres/pull/690 therefore removing this task

- name: Create symbolic links from /var/lib/postgresql/.nix-profile/share/postgresql to /usr/lib/postgresql/share/postgresql
  file:
    src: "{{ item }}"
    dest: "/usr/lib/postgresql/share/postgresql/{{ item | basename }}"
    state: link
  with_fileglob:
    - "/var/lib/postgresql/.nix-profile/share/postgresql/*"
  become: yes
  when: stage2_nix

- name: Ensure all PostgreSQL extensions are properly linked from Nix
  block:
    - name: Create required PostgreSQL library directories
      file:
        path: "{{ item }}"
        state: directory
        owner: postgres
        group: postgres
        mode: '0755'
      loop:
        - "/usr/lib/postgresql/lib"
        - "/usr/lib/postgresql/share/postgresql/extension"

    # First find all extension libraries (.so files)
    - name: Find all extension shared libraries in Nix profile
      shell: |
        find /var/lib/postgresql/.nix-profile -name "*.so" | grep -v "lib/lib"
      register: extension_libs_search
      changed_when: false
      failed_when: false

    - name: Show found extension libraries
      debug:
        var: extension_libs_search.stdout_lines

    # Copy all extension libraries to PostgreSQL lib directory
    - name: Link all extension shared libraries to PostgreSQL lib directory
      shell: |
        if [ -n "{{ extension_libs_search.stdout }}" ]; then
          for lib in {{ extension_libs_search.stdout_lines | join(' ') }}; do
            # Get the basename of the library
            lib_name=$(basename "$lib")
            # Copy the library to PostgreSQL lib directory
            cp -f "$lib" /usr/lib/postgresql/lib/
            chmod 755 /usr/lib/postgresql/lib/"$lib_name"
            chown postgres:postgres /usr/lib/postgresql/lib/"$lib_name"
            echo "Copied $lib_name"
          done
        else
          echo "No extension libraries found"
        fi
      register: extension_libs_copy
      when: extension_libs_search.stdout != ""

    # Find all extension files (.control, .sql)
    - name: Find all extension control files in Nix profile
      shell: |
        find /var/lib/postgresql/.nix-profile -path "*/extension/*" | grep -E '\.control$|\.sql$'
      register: extension_files_search
      changed_when: false
      failed_when: false

    - name: Show found extension files
      debug:
        var: extension_files_search.stdout_lines

    # Copy all extension files to PostgreSQL extension directory
    - name: Link all extension files to PostgreSQL extension directory
      shell: |
        if [ -n "{{ extension_files_search.stdout }}" ]; then
          for ext_file in {{ extension_files_search.stdout_lines | join(' ') }}; do
            # Get the basename of the extension file
            ext_name=$(basename "$ext_file")
            # Copy the extension file to PostgreSQL extension directory
            cp -f "$ext_file" /usr/lib/postgresql/share/postgresql/extension/
            chmod 644 /usr/lib/postgresql/share/postgresql/extension/"$ext_name"
            chown postgres:postgres /usr/lib/postgresql/share/postgresql/extension/"$ext_name"
            echo "Copied $ext_name"
          done
        else
          echo "No extension files found"
        fi
      register: extension_files_copy
      when: extension_files_search.stdout != ""

    # Special handling for extension-specific directories (like postgis)
    - name: Find extension directories in Nix profile
      shell: |
        find /var/lib/postgresql/.nix-profile -path "*/postgresql/contrib/*" -type d
      register: extension_dirs_search
      changed_when: false
      failed_when: false

    - name: Show found extension directories
      debug:
        var: extension_dirs_search.stdout_lines

    - name: Create extension directories in PostgreSQL
      file:
        path: "/usr/lib/postgresql/share/postgresql/contrib"
        state: directory
        owner: postgres
        group: postgres
        mode: '0755'
      when: extension_dirs_search.stdout != ""

    - name: Copy extension directories to PostgreSQL
      shell: |
        if [ -n "{{ extension_dirs_search.stdout }}" ]; then
          for dir in {{ extension_dirs_search.stdout_lines | join(' ') }}; do
            # Get the basename of the directory
            dir_name=$(basename "$dir")
            # Create the directory in PostgreSQL contrib directory
            mkdir -p /usr/lib/postgresql/share/postgresql/contrib/"$dir_name"
            # Copy all files from the directory
            cp -rf "$dir"/* /usr/lib/postgresql/share/postgresql/contrib/"$dir_name"/
            chmod -R 755 /usr/lib/postgresql/share/postgresql/contrib/"$dir_name"
            chown -R postgres:postgres /usr/lib/postgresql/share/postgresql/contrib/"$dir_name"
            echo "Copied directory $dir_name"
          done
        else
          echo "No extension directories found"
        fi
      register: extension_dirs_copy
      when: extension_dirs_search.stdout != ""

    # Verify key extensions
    - name: Verify key extension files
      shell: |
        echo "=== Checking Extension Files ==="
        echo "PgAudit:"
        ls -la /usr/lib/postgresql/lib/pgaudit* 2>/dev/null || echo "PgAudit lib not found"
        ls -la /usr/lib/postgresql/share/postgresql/extension/pgaudit* 2>/dev/null || echo "PgAudit extension not found"
        
        echo "PostGIS:"
        ls -la /usr/lib/postgresql/lib/postgis* 2>/dev/null || echo "PostGIS lib not found"
        ls -la /usr/lib/postgresql/share/postgresql/extension/postgis* 2>/dev/null || echo "PostGIS extension not found"
        
        echo "plpgsql:"
        ls -la /usr/lib/postgresql/share/postgresql/extension/plpgsql* 2>/dev/null || echo "plpgsql extension not found"
      register: extension_check
      changed_when: false
      ignore_errors: yes

    - name: Show extension check results
      debug:
        var: extension_check.stdout_lines

    # As a fallback, try a more direct approach for copying all extension files
    - name: Direct copy of extension files from Nix profile (fallback)
      shell: |
        cp -rf /var/lib/postgresql/.nix-profile/share/postgresql/extension/* /usr/lib/postgresql/share/postgresql/extension/ || echo "No extension files to copy"
        if [ -d "/var/lib/postgresql/.nix-profile/lib/postgresql" ]; then
          cp -rf /var/lib/postgresql/.nix-profile/lib/postgresql/* /usr/lib/postgresql/lib/ || echo "No library files to copy"
        fi
        find /var/lib/postgresql/.nix-profile -name "*.so" -exec cp -f {} /usr/lib/postgresql/lib/ \; || echo "No .so files found"
        chown -R postgres:postgres /usr/lib/postgresql/lib/
        chown -R postgres:postgres /usr/lib/postgresql/share/
        chmod -R 755 /usr/lib/postgresql/lib/
        chmod -R 755 /usr/lib/postgresql/share/
      ignore_errors: yes
  when: stage2_nix

- name: Direct install of pgaudit as fallback
  block:
    - name: Temporarily remove pgaudit from shared_preload_libraries
      become: yes
      become_user: postgres
      replace:
        path: /etc/postgresql/postgresql.conf
        regexp: '(shared_preload_libraries\s*=\s*[''"].*),?\s*pgaudit(.*[''"])'
        replace: '\1\2'
      
    - name: Create pgaudit directory
      file:
        path: "/usr/lib/postgresql/lib"
        state: directory
        owner: postgres
        group: postgres
        mode: '0755'

    - name: Find all extensions inside Nix store
      shell: |
        find /nix/store -name "pgaudit.so" -o -name "pgaudit*control" 2>/dev/null || echo "Not found"
      register: nix_store_search
      changed_when: false

    - name: Show Nix store search results
      debug:
        var: nix_store_search.stdout_lines
  
    - name: Use an alternative approach to copy extensions from Nix
      shell: |
        echo "=== Finding Nix packages ==="
        cp -v /var/lib/postgresql/.nix-profile/lib/*.so* /usr/lib/postgresql/lib/ 2>/dev/null || echo "No .so files found"
        mkdir -p /usr/lib/postgresql/share/postgresql/extension
        cp -v /var/lib/postgresql/.nix-profile/share/postgresql/extension/* /usr/lib/postgresql/share/postgresql/extension/ 2>/dev/null || echo "No extension files found"
        find /nix/store -path "*/postgresql/extension/pgaudit*.control" -exec cp -v {} /usr/lib/postgresql/share/postgresql/extension/ \; 2>/dev/null || echo "No control files found"
        find /nix/store -path "*/lib/pgaudit.so" -exec cp -v {} /usr/lib/postgresql/lib/ \; 2>/dev/null || echo "No lib files found"
        chmod 755 /usr/lib/postgresql/lib/*.so* 2>/dev/null || true
        chmod 644 /usr/lib/postgresql/share/postgresql/extension/* 2>/dev/null || true
        chown -R postgres:postgres /usr/lib/postgresql/lib/
        chown -R postgres:postgres /usr/lib/postgresql/share/
      ignore_errors: yes

    - name: Verify installation after direct copy
      shell: |
        echo "=== Library files ==="
        ls -la /usr/lib/postgresql/lib/ || echo "No directory"
        echo "=== Extension files ==="
        ls -la /usr/lib/postgresql/share/postgresql/extension/ || echo "No directory"
      register: direct_copy_check
      changed_when: false

    - name: Show direct copy results
      debug:
        var: direct_copy_check.stdout_lines
  when: stage2_nix

- name: Fix permissions for all PostgreSQL extension files
  block:
    - name: Ensure correct permissions for extension directory
      file:
        path: "/usr/lib/postgresql/share/postgresql/extension"
        state: directory
        owner: postgres
        group: postgres
        mode: '0755'
        recurse: no

    - name: Fix permissions for extension files
      shell: |
        find /usr/lib/postgresql/share/postgresql/extension -type f -exec chmod 644 {} \;
        find /usr/lib/postgresql/share/postgresql/extension -type f -exec chown postgres:postgres {} \;
        find /usr/lib/postgresql/lib -name "*.so*" -exec chmod 755 {} \; 2>/dev/null || true
        find /usr/lib/postgresql/lib -name "*.so*" -exec chown postgres:postgres {} \; 2>/dev/null || true
      become: yes

    - name: Verify fixed permissions
      shell: |
        echo "=== Extension directory permissions ==="
        ls -la /usr/lib/postgresql/share/postgresql/extension/
        echo "=== pgtap.control permissions ==="
        ls -la /usr/lib/postgresql/share/postgresql/extension/pgtap.control 2>/dev/null || echo "File not found"
      register: perm_check
      changed_when: false

    - name: Show permissions check results
      debug:
        var: perm_check.stdout_lines
  when: stage2_nix

- name: create destination directory
  file:
    path: /usr/lib/postgresql/share/postgresql/contrib/
    state: directory
    recurse: yes
  when: stage2_nix

- name: Check psql_version and run postgis linking if not oriole-xx
  block:
    - name: Check if psql_version is psql_orioledb-17
      set_fact:
        is_psql_oriole: "{{ psql_version == 'psql_orioledb-17' }}"

    - name: Install PostGIS from nixpkgs
      become: yes
      shell: |
        sudo -u postgres bash -c ". /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh && nix profile install nixpkgs#postgresql15Packages.postgis"
      when: stage2_nix and not is_psql_oriole and ansible_architecture != 'aarch64'
      register: install_postgis
      retries: 3
      delay: 5
      until: install_postgis.rc == 0

    - name: Skip PostGIS on ARM64
      debug:
        msg: "Skipping PostGIS installation on ARM64 as it's not available in nixpkgs"
      when: stage2_nix and not is_psql_oriole and ansible_architecture == 'aarch64'

    - name: Debug contrib directory contents
      shell: "ls -l /var/lib/postgresql/.nix-profile/share/postgresql/contrib/ || echo 'Contrib directory not found'"
      register: contrib_debug
      become: yes
      when: stage2_nix and not is_psql_oriole and ansible_architecture != 'aarch64'

    - name: Show contrib directory contents
      debug:
        var: contrib_debug.stdout_lines
      when: stage2_nix and not is_psql_oriole and ansible_architecture != 'aarch64'

    - name: Recursively create symbolic links and set permissions for the contrib/postgis-* dir
      shell: >
        sudo mkdir -p /usr/lib/postgresql/share/postgresql/contrib && \
        sudo find /var/lib/postgresql/.nix-profile/share/postgresql/contrib/ -mindepth 1 -type d -exec sh -c 'for dir do sudo ln -s "$dir" "/usr/lib/postgresql/share/postgresql/contrib/$(basename "$dir")"; done' sh {} + \
        && chown -R postgres:postgres "/usr/lib/postgresql/share/postgresql/contrib/"
      become: yes
      when: stage2_nix and not is_psql_oriole and ansible_architecture != 'aarch64'

- name: Create symbolic links from /var/lib/postgresql/.nix-profile/share/postgresql/timezonesets to /usr/lib/postgresql/share/postgresql/timeszonesets
  file:
    src: "{{ item }}"
    dest: "/usr/lib/postgresql/share/postgresql/timezonesets/{{ item | basename }}"
    state: link
  with_fileglob:
    - "/var/lib/postgresql/.nix-profile/share/postgresql/timezonesets/*"
  become: yes
  when: stage2_nix

- name: Create symbolic links from /var/lib/postgresql/.nix-profile/share/postgresql/tsearch_data to /usr/lib/postgresql/share/postgresql/tsearch_data
  file:
    src: "{{ item }}"
    dest: "/usr/lib/postgresql/share/postgresql/tsearch_data/{{ item | basename }}"
    state: link
  with_fileglob:
    - "/var/lib/postgresql/.nix-profile/share/postgresql/tsearch_data/*"
  become: yes
  when: stage2_nix

- set_fact:
    pg_bindir: "/usr/lib/postgresql/bin"
  when: stage2_nix

- name: pgsodium - set pgsodium.getkey_script
  become: yes
  lineinfile:
    path: /etc/postgresql/postgresql.conf
    state: present
    line: pgsodium.getkey_script= '{{ pg_bindir }}/pgsodium_getkey.sh'
  when: stage2_nix

- name: Create symbolic link for pgsodium_getkey script
  file:
    src: "/usr/lib/postgresql/bin/pgsodium_getkey.sh"
    dest: "/usr/lib/postgresql/share/postgresql/extension/pgsodium_getkey"
    state: link
  become: yes
  when: stage2_nix

- name: Append GRN_PLUGINS_DIR to /etc/environment.d/postgresql.env
  ansible.builtin.lineinfile:
    path: /etc/environment.d/postgresql.env
    line: 'GRN_PLUGINS_DIR=/var/lib/postgresql/.nix-profile/lib/groonga/plugins'
  become: yes

- name: Ensure AGE extension is properly installed for PostgreSQL 15
  block:
    - name: Create AGE extension directories with proper permissions
      file:
        path: "{{ item }}"
        state: directory
        owner: postgres
        group: postgres
        mode: '0755'
      loop:
        - "/usr/lib/postgresql/lib"
        - "/usr/lib/postgresql/share/postgresql/extension"

    - name: Find AGE extension files in Nix store
      shell: |
        echo "=== Finding AGE files in Nix store ==="
        find /nix/store -path "*age-1.5.0*/share/postgresql/extension/*" -type f
      register: age_nix_files
      changed_when: false

    - name: Display found AGE files
      debug:
        var: age_nix_files.stdout_lines

    - name: Verify AGE main installation script exists in Nix store
      shell: |
        echo "=== Searching for AGE main installation script ==="
        MAIN_SCRIPT=$(find /nix/store -name "age--1.5.0.sql" | head -1)
        if [ -n "$MAIN_SCRIPT" ] && [ -f "$MAIN_SCRIPT" ]; then
          echo "SUCCESS: Main installation script found at: $MAIN_SCRIPT"
          echo "Script size: $(wc -l < "$MAIN_SCRIPT") lines"
          echo "First 5 lines of script:"
          head -5 "$MAIN_SCRIPT"
        else
          echo "ERROR: Main installation script age--1.5.0.sql not found in Nix store"
          echo "This indicates the AGE build process failed."
          echo "Available AGE SQL files in Nix store:"
          find /nix/store -path "*age-1.5.0*" -name "*.sql" | head -20
          echo "Checking if individual component files exist:"
          find /nix/store -path "*age-1.5.0*" -name "age_main.sql" || echo "age_main.sql missing"
          find /nix/store -path "*age-1.5.0*" -name "age_agtype.sql" || echo "age_agtype.sql missing"
          exit 1
        fi
      register: age_main_script_check
      failed_when: age_main_script_check.rc != 0

    - name: Display main script verification
      debug:
        var: age_main_script_check.stdout_lines

    - name: Copy AGE shared library from Nix store
      shell: |
        AGE_LIB=$(find /nix/store -path "*age-1.5.0*/lib/age.so" | head -1)
        if [ -n "$AGE_LIB" ] && [ -f "$AGE_LIB" ]; then
          cp -f "$AGE_LIB" /usr/lib/postgresql/lib/
          chmod 755 /usr/lib/postgresql/lib/age.so
          chown postgres:postgres /usr/lib/postgresql/lib/age.so
          echo "SUCCESS: AGE library copied"
          ls -la /usr/lib/postgresql/lib/age.so
        else
          echo "ERROR: AGE library not found in Nix store"
          find /nix/store -path "*age*" -name "age.so" || echo "No age.so found"
          exit 1
        fi
      register: age_lib_copy
      failed_when: age_lib_copy.rc != 0

    - name: Copy AGE extension files from Nix store
      shell: |
        echo "=== Copying AGE extension files ==="
        AGE_EXT_DIR=$(find /nix/store -path "*age-1.5.0*/share/postgresql/extension" -type d | head -1)
        
        if [ -z "$AGE_EXT_DIR" ]; then
          echo "ERROR: AGE extension directory not found in Nix store"
          exit 1
        fi
        
        echo "Found AGE extension directory: $AGE_EXT_DIR"
        
        # Copy all AGE extension files
        cp -f "$AGE_EXT_DIR"/* /usr/lib/postgresql/share/postgresql/extension/
        
        # Set proper permissions
        chmod 644 /usr/lib/postgresql/share/postgresql/extension/age*
        chown postgres:postgres /usr/lib/postgresql/share/postgresql/extension/age*
        
        echo "SUCCESS: AGE extension files copied"
        echo "Copied files:"
        ls -la /usr/lib/postgresql/share/postgresql/extension/age*
      register: age_ext_copy
      failed_when: age_ext_copy.rc != 0

    - name: Verify AGE installation completeness
      shell: |
        echo "=== AGE Installation Verification ==="
        
        # Check for required files (using sh-compatible syntax)
        all_found=true
        
        # Check each file individually (sh-compatible)
        if [ -f "/usr/lib/postgresql/lib/age.so" ]; then
          echo " Found: /usr/lib/postgresql/lib/age.so"
          ls -la "/usr/lib/postgresql/lib/age.so"
        else
          echo " Missing: /usr/lib/postgresql/lib/age.so"
          all_found=false
        fi
        
        if [ -f "/usr/lib/postgresql/share/postgresql/extension/age.control" ]; then
          echo " Found: /usr/lib/postgresql/share/postgresql/extension/age.control"
          ls -la "/usr/lib/postgresql/share/postgresql/extension/age.control"
        else
          echo " Missing: /usr/lib/postgresql/share/postgresql/extension/age.control"
          all_found=false
        fi
        
        if [ -f "/usr/lib/postgresql/share/postgresql/extension/age--1.5.0.sql" ]; then
          echo " Found: /usr/lib/postgresql/share/postgresql/extension/age--1.5.0.sql"
          ls -la "/usr/lib/postgresql/share/postgresql/extension/age--1.5.0.sql"
        else
          echo " Missing: /usr/lib/postgresql/share/postgresql/extension/age--1.5.0.sql"
          all_found=false
        fi
        
        if [ "$all_found" = true ]; then
          echo "SUCCESS: All required AGE files are present"
          
          # Critical check: verify main installation script has proper content
          if [ -f "/usr/lib/postgresql/share/postgresql/extension/age--1.5.0.sql" ]; then
            SCRIPT_SIZE=$(wc -l < "/usr/lib/postgresql/share/postgresql/extension/age--1.5.0.sql")
            if [ "$SCRIPT_SIZE" -lt 100 ]; then
              echo "ERROR: Main installation script too small ($SCRIPT_SIZE lines)"
              echo "This indicates the script was not properly generated"
              exit 1
            fi
            echo " Main installation script has $SCRIPT_SIZE lines (expected >100)"
          fi
          
          # Display control file content
          echo "=== AGE Control File Content ==="
          cat /usr/lib/postgresql/share/postgresql/extension/age.control
          
          # Display main script header
          echo "=== AGE Main Script (first 10 lines) ==="
          head -10 /usr/lib/postgresql/share/postgresql/extension/age--1.5.0.sql
          
          # Verify it contains key AGE components
          if grep -q "ag_catalog" /usr/lib/postgresql/share/postgresql/extension/age--1.5.0.sql; then
            echo " Main script contains ag_catalog schema"
          else
            echo " Main script missing ag_catalog schema - build issue detected"
            exit 1
          fi
          
        else
          echo "ERROR: AGE installation incomplete"
          exit 1
        fi
      args:
        executable: /bin/bash
      register: age_verification
      failed_when: age_verification.rc != 0

    - name: Display AGE verification results
      debug:
        var: age_verification.stdout_lines

  when: stage2_nix and postgresql_major_version == "15"
  become: yes

'''

'''--- /Users/barneycook/Desktop/code/ProjectRef/postgres/ansible/files/postgresql_config/postgresql.conf.j2 ---
# -----------------------------
# PostgreSQL configuration file
# -----------------------------
#
# This file consists of lines of the form:
#
#   name = value
#
# (The "=" is optional.)  Whitespace may be used.  Comments are introduced with
# "#" anywhere on a line.  The complete list of parameter names and allowed
# values can be found in the PostgreSQL documentation.
#
# The commented-out settings shown in this file represent the default values.
# Re-commenting a setting is NOT sufficient to revert it to the default value;
# you need to reload the server.
#
# This file is read on server startup and when the server receives a SIGHUP
# signal.  If you edit the file on a running system, you have to SIGHUP the
# server for the changes to take effect, run "pg_ctl reload", or execute
# "SELECT pg_reload_conf()".  Some parameters, which are marked below,
# require a server shutdown and restart to take effect.
#
# Any parameter can also be given as a command-line option to the server, e.g.,
# "postgres -c log_connections=on".  Some parameters can be changed at run time
# with the "SET" SQL command.
#
# Memory units:  B  = bytes            Time units:  us  = microseconds
#                kB = kilobytes                     ms  = milliseconds
#                MB = megabytes                     s   = seconds
#                GB = gigabytes                     min = minutes
#                TB = terabytes                     h   = hours
#                                                   d   = days


#------------------------------------------------------------------------------
# FILE LOCATIONS
#------------------------------------------------------------------------------

# The default values of these variables are driven from the -D command-line
# option or PGDATA environment variable, represented here as ConfigDir.

data_directory = '/var/lib/postgresql/data'		# use data in another directory
					# (change requires restart)
hba_file = '/etc/postgresql/pg_hba.conf'	# host-based authentication file
					# (change requires restart)
ident_file = '/etc/postgresql/pg_ident.conf'	# ident configuration file
					# (change requires restart)

# If external_pid_file is not explicitly set, no extra PID file is written.
#external_pid_file = ''			# write an extra PID file
					# (change requires restart)


#------------------------------------------------------------------------------
# CONNECTIONS AND AUTHENTICATION
#------------------------------------------------------------------------------

# - Connection Settings -

listen_addresses = '*'		# what IP address(es) to listen on;
					# comma-separated list of addresses;
					# defaults to 'localhost'; use '*' for all
					# (change requires restart)
#port = 5432				# (change requires restart)
#max_connections = 100			# (change requires restart)
#superuser_reserved_connections = 3	# (change requires restart)
#unix_socket_directories = '/tmp'	# comma-separated list of directories
					# (change requires restart)
#unix_socket_group = ''			# (change requires restart)
#unix_socket_permissions = 0777		# begin with 0 to use octal notation
					# (change requires restart)
#bonjour = off				# advertise server via Bonjour
					# (change requires restart)
#bonjour_name = ''			# defaults to the computer name
					# (change requires restart)

# - TCP settings -
# see "man tcp" for details

#tcp_keepalives_idle = 0		# TCP_KEEPIDLE, in seconds;
					# 0 selects the system default
#tcp_keepalives_interval = 0		# TCP_KEEPINTVL, in seconds;
					# 0 selects the system default
#tcp_keepalives_count = 0		# TCP_KEEPCNT;
					# 0 selects the system default
#tcp_user_timeout = 0			# TCP_USER_TIMEOUT, in milliseconds;
					# 0 selects the system default

#client_connection_check_interval = 0	# time between checks for client
					# disconnection while running queries;
					# 0 for never

# - Authentication -

authentication_timeout = 1min		# 1s-600s
password_encryption = scram-sha-256	# scram-sha-256 or md5
db_user_namespace = off

# GSSAPI using Kerberos
#krb_server_keyfile = 'FILE:${sysconfdir}/krb5.keytab'
#krb_caseins_users = off

# - SSL -

ssl = off
ssl_ca_file = ''
ssl_cert_file = ''
ssl_crl_file = ''
ssl_crl_dir = ''
ssl_key_file = ''
ssl_ciphers = 'HIGH:MEDIUM:+3DES:!aNULL' # allowed SSL ciphers
ssl_prefer_server_ciphers = on
ssl_ecdh_curve = 'prime256v1'
ssl_min_protocol_version = 'TLSv1.2'
ssl_max_protocol_version = ''
ssl_dh_params_file = ''
ssl_passphrase_command = ''
ssl_passphrase_command_supports_reload = off


#------------------------------------------------------------------------------
# RESOURCE USAGE (except WAL)
#------------------------------------------------------------------------------

# - Memory -

shared_buffers = 128MB			# min 128kB
					# (change requires restart)
#huge_pages = try			# on, off, or try
					# (change requires restart)
#huge_page_size = 0			# zero for system default
					# (change requires restart)
#temp_buffers = 8MB			# min 800kB
#max_prepared_transactions = 0		# zero disables the feature
					# (change requires restart)
# Caution: it is not advisable to set max_prepared_transactions nonzero unless
# you actively intend to use prepared transactions.
#work_mem = 4MB				# min 64kB
#hash_mem_multiplier = 1.0		# 1-1000.0 multiplier on hash table work_mem
#maintenance_work_mem = 64MB		# min 1MB
#autovacuum_work_mem = -1		# min 1MB, or -1 to use maintenance_work_mem
#logical_decoding_work_mem = 64MB	# min 64kB
#max_stack_depth = 2MB			# min 100kB
#shared_memory_type = mmap		# the default is the first option
					# supported by the operating system:
					#   mmap
					#   sysv
					#   windows
					# (change requires restart)
#dynamic_shared_memory_type = posix	# the default is the first option
					# supported by the operating system:
					#   posix
					#   sysv
					#   windows
					#   mmap
					# (change requires restart)
#min_dynamic_shared_memory = 0MB	# (change requires restart)

# - Disk -

#temp_file_limit = -1			# limits per-process temp file space
					# in kilobytes, or -1 for no limit

# - Kernel Resources -

#max_files_per_process = 1000		# min 64
					# (change requires restart)

# - Cost-Based Vacuum Delay -

#vacuum_cost_delay = 0			# 0-100 milliseconds (0 disables)
#vacuum_cost_page_hit = 1		# 0-10000 credits
#vacuum_cost_page_miss = 2		# 0-10000 credits
#vacuum_cost_page_dirty = 20		# 0-10000 credits
#vacuum_cost_limit = 200		# 1-10000 credits

# - Background Writer -

#bgwriter_delay = 200ms			# 10-10000ms between rounds
#bgwriter_lru_maxpages = 100		# max buffers written/round, 0 disables
#bgwriter_lru_multiplier = 2.0		# 0-10.0 multiplier on buffers scanned/round
#bgwriter_flush_after = 0		# measured in pages, 0 disables

# - Asynchronous Behavior -

#backend_flush_after = 0		# measured in pages, 0 disables
#effective_io_concurrency = 1		# 1-1000; 0 disables prefetching
#maintenance_io_concurrency = 10	# 1-1000; 0 disables prefetching
#max_worker_processes = 8		# (change requires restart)
#max_parallel_workers_per_gather = 2	# taken from max_parallel_workers
#max_parallel_maintenance_workers = 2	# taken from max_parallel_workers
#max_parallel_workers = 8		# maximum number of max_worker_processes that
					# can be used in parallel operations
#parallel_leader_participation = on
#old_snapshot_threshold = -1		# 1min-60d; -1 disables; 0 is immediate
					# (change requires restart)


#------------------------------------------------------------------------------
# WRITE-AHEAD LOG
#------------------------------------------------------------------------------

# - Settings -

wal_level = logical			# minimal, replica, or logical
					# (change requires restart)
#fsync = on				# flush data to disk for crash safety
					# (turning this off can cause
					# unrecoverable data corruption)
#synchronous_commit = on		# synchronization level;
					# off, local, remote_write, remote_apply, or on
#wal_sync_method = fsync		# the default is the first option
					# supported by the operating system:
					#   open_datasync
					#   fdatasync (default on Linux and FreeBSD)
					#   fsync
					#   fsync_writethrough
					#   open_sync
#full_page_writes = on			# recover from partial page writes
#wal_log_hints = off			# also do full page writes of non-critical updates
					# (change requires restart)
#wal_compression = off			# enable compression of full-page writes
#wal_init_zero = on			# zero-fill new WAL files
#wal_recycle = on			# recycle WAL files
#wal_buffers = -1			# min 32kB, -1 sets based on shared_buffers
					# (change requires restart)
#wal_writer_delay = 200ms		# 1-10000 milliseconds
#wal_writer_flush_after = 1MB		# measured in pages, 0 disables
#wal_skip_threshold = 2MB

#commit_delay = 0			# range 0-100000, in microseconds
#commit_siblings = 5			# range 1-1000

# - Checkpoints -

#checkpoint_timeout = 5min		# range 30s-1d
checkpoint_completion_target = 0.5	# checkpoint target duration, 0.0 - 1.0
checkpoint_flush_after = 256kB		# measured in pages, 0 disables
#checkpoint_warning = 30s		# 0 disables
#max_wal_size = 1GB
#min_wal_size = 80MB

# - Archiving -

#archive_mode = off		# enables archiving; off, on, or always
				# (change requires restart)
#archive_command = ''		# command to use to archive a logfile segment
				# placeholders: %p = path of file to archive
				#               %f = file name only
				# e.g. 'test ! -f /mnt/server/archivedir/%f && cp %p /mnt/server/archivedir/%f'
#archive_timeout = 0		# force a logfile segment switch after this
				# number of seconds; 0 disables

# - Archive Recovery -

# These are only used in recovery mode.

#restore_command = ''		# command to use to restore an archived logfile segment
				# placeholders: %p = path of file to restore
				#               %f = file name only
				# e.g. 'cp /mnt/server/archivedir/%f %p'
#archive_cleanup_command = ''	# command to execute at every restartpoint
#recovery_end_command = ''	# command to execute at completion of recovery

# - Recovery Target -

# Set these only when performing a targeted recovery.

#recovery_target = ''		# 'immediate' to end recovery as soon as a
                                # consistent state is reached
				# (change requires restart)
#recovery_target_name = ''	# the named restore point to which recovery will proceed
				# (change requires restart)
#recovery_target_time = ''	# the time stamp up to which recovery will proceed
				# (change requires restart)
#recovery_target_xid = ''	# the transaction ID up to which recovery will proceed
				# (change requires restart)
#recovery_target_lsn = ''	# the WAL LSN up to which recovery will proceed
				# (change requires restart)
#recovery_target_inclusive = on # Specifies whether to stop:
				# just after the specified recovery target (on)
				# just before the recovery target (off)
				# (change requires restart)
#recovery_target_timeline = 'latest'	# 'current', 'latest', or timeline ID
				# (change requires restart)
#recovery_target_action = 'pause'	# 'pause', 'promote', 'shutdown'
				# (change requires restart)


#------------------------------------------------------------------------------
# REPLICATION
#------------------------------------------------------------------------------

# - Sending Servers -

# Set these on the primary and on any standby that will send replication data.

max_wal_senders = 10		# max number of walsender processes
				# (change requires restart)
max_replication_slots = 5	# max number of replication slots
				# (change requires restart)
#wal_keep_size = 0		# in megabytes; 0 disables
max_slot_wal_keep_size = 4096   # in megabytes; -1 disables
#wal_sender_timeout = 60s	# in milliseconds; 0 disables
#track_commit_timestamp = off	# collect timestamp of transaction commit
				# (change requires restart)

# - Primary Server -

# These settings are ignored on a standby server.

#synchronous_standby_names = ''	# standby servers that provide sync rep
				# method to choose sync standbys, number of sync standbys,
				# and comma-separated list of application_name
				# from standby(s); '*' = all
#vacuum_defer_cleanup_age = 0	# number of xacts by which cleanup is delayed

# - Standby Servers -

# These settings are ignored on a primary server.

#primary_conninfo = ''			# connection string to sending server
#primary_slot_name = ''			# replication slot on sending server
#promote_trigger_file = ''		# file name whose presence ends recovery
#hot_standby = on			# "off" disallows queries during recovery
					# (change requires restart)
#max_standby_archive_delay = 30s	# max delay before canceling queries
					# when reading WAL from archive;
					# -1 allows indefinite delay
#max_standby_streaming_delay = 30s	# max delay before canceling queries
					# when reading streaming WAL;
					# -1 allows indefinite delay
#wal_receiver_create_temp_slot = off	# create temp slot if primary_slot_name
					# is not set
#wal_receiver_status_interval = 10s	# send replies at least this often
					# 0 disables
#hot_standby_feedback = off		# send info from standby to prevent
					# query conflicts
#wal_receiver_timeout = 60s		# time that receiver waits for
					# communication from primary
					# in milliseconds; 0 disables
#wal_retrieve_retry_interval = 5s	# time to wait before retrying to
					# retrieve WAL after a failed attempt
#recovery_min_apply_delay = 0		# minimum delay for applying changes during recovery

# - Subscribers -

# These settings are ignored on a publisher.

#max_logical_replication_workers = 4	# taken from max_worker_processes
					# (change requires restart)
#max_sync_workers_per_subscription = 2	# taken from max_logical_replication_workers


#------------------------------------------------------------------------------
# QUERY TUNING
#------------------------------------------------------------------------------

# - Planner Method Configuration -

#enable_async_append = on
#enable_bitmapscan = on
#enable_gathermerge = on
#enable_hashagg = on
#enable_hashjoin = on
#enable_incremental_sort = on
#enable_indexscan = on
#enable_indexonlyscan = on
#enable_material = on
#enable_resultcache = on
#enable_mergejoin = on
#enable_nestloop = on
#enable_parallel_append = on
#enable_parallel_hash = on
#enable_partition_pruning = on
#enable_partitionwise_join = off
#enable_partitionwise_aggregate = off
#enable_seqscan = on
#enable_sort = on
#enable_tidscan = on

# - Planner Cost Constants -

#seq_page_cost = 1.0			# measured on an arbitrary scale
#random_page_cost = 4.0			# same scale as above
#cpu_tuple_cost = 0.01			# same scale as above
#cpu_index_tuple_cost = 0.005		# same scale as above
#cpu_operator_cost = 0.0025		# same scale as above
#parallel_setup_cost = 1000.0	# same scale as above
#parallel_tuple_cost = 0.1		# same scale as above
#min_parallel_table_scan_size = 8MB
#min_parallel_index_scan_size = 512kB
effective_cache_size = 128MB

#jit_above_cost = 100000		# perform JIT compilation if available
					# and query more expensive than this;
					# -1 disables
#jit_inline_above_cost = 500000		# inline small functions if query is
					# more expensive than this; -1 disables
#jit_optimize_above_cost = 500000	# use expensive JIT optimizations if
					# query is more expensive than this;
					# -1 disables

# - Genetic Query Optimizer -

#geqo = on
#geqo_threshold = 12
#geqo_effort = 5			# range 1-10
#geqo_pool_size = 0			# selects default based on effort
#geqo_generations = 0			# selects default based on effort
#geqo_selection_bias = 2.0		# range 1.5-2.0
#geqo_seed = 0.0			# range 0.0-1.0

# - Other Planner Options -

#default_statistics_target = 100	# range 1-10000
#constraint_exclusion = partition	# on, off, or partition
#cursor_tuple_fraction = 0.1		# range 0.0-1.0
#from_collapse_limit = 8
#jit = on				# allow JIT compilation
#join_collapse_limit = 8		# 1 disables collapsing of explicit
					# JOIN clauses
#plan_cache_mode = auto			# auto, force_generic_plan or
					# force_custom_plan


#------------------------------------------------------------------------------
# REPORTING AND LOGGING
#------------------------------------------------------------------------------

include = '/etc/postgresql/logging.conf'

# These are relevant when logging to syslog:
#syslog_facility = 'LOCAL0'
#syslog_ident = 'postgres'
#syslog_sequence_numbers = on
#syslog_split_messages = on

# This is only relevant when logging to eventlog (Windows):
# (change requires restart)
#event_source = 'PostgreSQL'

# - When to Log -

#log_min_messages = warning		# values in order of decreasing detail:
					#   debug5
					#   debug4
					#   debug3
					#   debug2
					#   debug1
					#   info
					#   notice
					#   warning
					#   error
					#   log
					#   fatal
					#   panic

#log_min_error_statement = error	# values in order of decreasing detail:
					#   debug5
					#   debug4
					#   debug3
					#   debug2
					#   debug1
					#   info
					#   notice
					#   warning
					#   error
					#   log
					#   fatal
					#   panic (effectively off)

#log_min_duration_statement = -1	# -1 is disabled, 0 logs all statements
					# and their durations, > 0 logs only
					# statements running at least this number
					# of milliseconds

#log_min_duration_sample = -1		# -1 is disabled, 0 logs a sample of statements
					# and their durations, > 0 logs only a sample of
					# statements running at least this number
					# of milliseconds;
					# sample fraction is determined by log_statement_sample_rate

#log_statement_sample_rate = 1.0	# fraction of logged statements exceeding
					# log_min_duration_sample to be logged;
					# 1.0 logs all such statements, 0.0 never logs


#log_transaction_sample_rate = 0.0	# fraction of transactions whose statements
					# are logged regardless of their duration; 1.0 logs all
					# statements from all transactions, 0.0 never logs

# - What to Log -

#debug_print_parse = off
#debug_print_rewritten = off
#debug_print_plan = off
#debug_pretty_print = on
#log_autovacuum_min_duration = -1	# log autovacuum activity;
					# -1 disables, 0 logs all actions and
					# their durations, > 0 logs only
					# actions running at least this number
					# of milliseconds.
#log_checkpoints = off
#log_connections = off
#log_disconnections = off
#log_duration = off
#log_error_verbosity = default		# terse, default, or verbose messages
#log_hostname = off
log_line_prefix = '%h %m [%p] %q%u@%d '		# special values:
					#   %a = application name
					#   %u = user name
					#   %d = database name
					#   %r = remote host and port
					#   %h = remote host
					#   %b = backend type
					#   %p = process ID
					#   %P = process ID of parallel group leader
					#   %t = timestamp without milliseconds
					#   %m = timestamp with milliseconds
					#   %n = timestamp with milliseconds (as a Unix epoch)
					#   %Q = query ID (0 if none or not computed)
					#   %i = command tag
					#   %e = SQL state
					#   %c = session ID
					#   %l = session line number
					#   %s = session start timestamp
					#   %v = virtual transaction ID
					#   %x = transaction ID (0 if none)
					#   %q = stop here in non-session
					#        processes
					#   %% = '%'
					# e.g. '<%u%%%d> '
#log_lock_waits = off			# log lock waits >= deadlock_timeout
#log_recovery_conflict_waits = off	# log standby recovery conflict waits
					# >= deadlock_timeout
#log_parameter_max_length = -1		# when logging statements, limit logged
					# bind-parameter values to N bytes;
					# -1 means print in full, 0 disables
#log_parameter_max_length_on_error = 0	# when logging an error, limit logged
					# bind-parameter values to N bytes;
					# -1 means print in full, 0 disables
log_statement = 'none'			# none, ddl, mod, all
#log_replication_commands = off
#log_temp_files = -1			# log temporary files equal or larger
					# than the specified size in kilobytes;
					# -1 disables, 0 logs all temp files
log_timezone = 'UTC'

#------------------------------------------------------------------------------
# PROCESS TITLE
#------------------------------------------------------------------------------

cluster_name = 'main'			# added to process titles if nonempty
					# (change requires restart)
#update_process_title = on


#------------------------------------------------------------------------------
# STATISTICS
#------------------------------------------------------------------------------

# - Query and Index Statistics Collector -

#track_activities = on
#track_activity_query_size = 1024	# (change requires restart)
#track_counts = on
#track_io_timing = off
#track_wal_io_timing = off
#track_functions = none			# none, pl, all
#stats_temp_directory = 'pg_stat_tmp'


# - Monitoring -

#compute_query_id = auto
#log_statement_stats = off
#log_parser_stats = off
#log_planner_stats = off
#log_executor_stats = off


#------------------------------------------------------------------------------
# AUTOVACUUM
#------------------------------------------------------------------------------

#autovacuum = on			# Enable autovacuum subprocess?  'on'
					# requires track_counts to also be on.
#autovacuum_max_workers = 3		# max number of autovacuum subprocesses
					# (change requires restart)
#autovacuum_naptime = 1min		# time between autovacuum runs
#autovacuum_vacuum_threshold = 50	# min number of row updates before
					# vacuum
#autovacuum_vacuum_insert_threshold = 1000	# min number of row inserts
					# before vacuum; -1 disables insert
					# vacuums
#autovacuum_analyze_threshold = 50	# min number of row updates before
					# analyze
#autovacuum_vacuum_scale_factor = 0.2	# fraction of table size before vacuum
#autovacuum_vacuum_insert_scale_factor = 0.2	# fraction of inserts over table
					# size before insert vacuum
#autovacuum_analyze_scale_factor = 0.1	# fraction of table size before analyze
#autovacuum_freeze_max_age = 200000000	# maximum XID age before forced vacuum
					# (change requires restart)
#autovacuum_multixact_freeze_max_age = 400000000	# maximum multixact age
					# before forced vacuum
					# (change requires restart)
#autovacuum_vacuum_cost_delay = 2ms	# default vacuum cost delay for
					# autovacuum, in milliseconds;
					# -1 means use vacuum_cost_delay
#autovacuum_vacuum_cost_limit = -1	# default vacuum cost limit for
					# autovacuum, -1 means use
					# vacuum_cost_limit


#------------------------------------------------------------------------------
# CLIENT CONNECTION DEFAULTS
#------------------------------------------------------------------------------

# - Statement Behavior -

#client_min_messages = notice		# values in order of decreasing detail:
					#   debug5
					#   debug4
					#   debug3
					#   debug2
					#   debug1
					#   log
					#   notice
					#   warning
					#   error
#search_path = '"$user", public'	# schema names
row_security = on
#default_table_access_method = 'heap'
#default_tablespace = ''		# a tablespace name, '' uses the default
#default_toast_compression = 'pglz'	# 'pglz' or 'lz4'
#temp_tablespaces = ''			# a list of tablespace names, '' uses
					# only default tablespace
#check_function_bodies = on
#default_transaction_isolation = 'read committed'
#default_transaction_read_only = off
#default_transaction_deferrable = off
#session_replication_role = 'origin'
#statement_timeout = 0			# in milliseconds, 0 is disabled
#lock_timeout = 0			# in milliseconds, 0 is disabled
#idle_in_transaction_session_timeout = 0	# in milliseconds, 0 is disabled
#idle_session_timeout = 0		# in milliseconds, 0 is disabled
#vacuum_freeze_table_age = 150000000
#vacuum_freeze_min_age = 50000000
#vacuum_failsafe_age = 1600000000
#vacuum_multixact_freeze_table_age = 150000000
#vacuum_multixact_freeze_min_age = 5000000
#vacuum_multixact_failsafe_age = 1600000000
#bytea_output = 'hex'			# hex, escape
#xmlbinary = 'base64'
#xmloption = 'content'
#gin_pending_list_limit = 4MB

# - Locale and Formatting -

#datestyle = 'iso, mdy'
#intervalstyle = 'postgres'
timezone = 'UTC'
#timezone_abbreviations = 'Default'     # Select the set of available time zone
					# abbreviations.  Currently, there are
					#   Default
					#   Australia (historical usage)
					#   India
					# You can create your own file in
					# share/timezonesets/.
extra_float_digits = 0			# min -15, max 3; any value >0 actually
					# selects precise output mode
#client_encoding = sql_ascii		# actually, defaults to database
					# encoding

# These settings are initialized by initdb, but they can be changed.
#lc_messages = 'en_US.UTF-8'			# locale for system error message
					# strings
#lc_monetary = 'en_US.UTF-8'			# locale for monetary formatting
#lc_numeric = 'en_US.UTF-8'			# locale for number formatting
#lc_time = 'en_US.UTF-8'				# locale for time formatting

# These settings are initialized by initdb, but they can be changed.
lc_messages = 'C'			# locale for system error message
					# strings
lc_monetary = 'C'			# locale for monetary formatting
lc_numeric = 'C'			# locale for number formatting
lc_time = 'C'				# locale for time formatting

# default configuration for text search
default_text_search_config = 'pg_catalog.english'

# - Shared Library Preloading -

#local_preload_libraries = ''
#session_preload_libraries = ''

shared_preload_libraries = 'pg_stat_statements, pgaudit, plpgsql, plpgsql_check, pg_cron, pg_net, pgsodium, timescaledb, auto_explain, pg_tle, plan_filter'	# (change requires restart)
jit_provider = 'llvmjit'		# JIT library to use

# - Other Defaults -

#dynamic_library_path = '$libdir'
#gin_fuzzy_search_limit = 0

#------------------------------------------------------------------------------
# LOCK MANAGEMENT
#------------------------------------------------------------------------------

#deadlock_timeout = 1s
#max_locks_per_transaction = 64		# min 10
					# (change requires restart)
#max_pred_locks_per_transaction = 64	# min 10
					# (change requires restart)
#max_pred_locks_per_relation = -2	# negative values mean
					# (max_pred_locks_per_transaction
					#  / -max_pred_locks_per_relation) - 1
#max_pred_locks_per_page = 2            # min 0


#------------------------------------------------------------------------------
# VERSION AND PLATFORM COMPATIBILITY
#------------------------------------------------------------------------------

# - Previous PostgreSQL Versions -

#array_nulls = on
#backslash_quote = safe_encoding	# on, off, or safe_encoding
#escape_string_warning = on
#lo_compat_privileges = off
#quote_all_identifiers = off
#standard_conforming_strings = on
#synchronize_seqscans = on

# - Other Platforms and Clients -

#transform_null_equals = off


#------------------------------------------------------------------------------
# ERROR HANDLING
#------------------------------------------------------------------------------

#exit_on_error = off			# terminate session on any error?
#restart_after_crash = on		# reinitialize after backend crash?
#data_sync_retry = off			# retry or panic on failure to fsync
					# data?
					# (change requires restart)
#recovery_init_sync_method = fsync	# fsync, syncfs (Linux 5.8+)


#------------------------------------------------------------------------------
# CONFIG FILE INCLUDES
#------------------------------------------------------------------------------

# These options allow settings to be loaded from files other than the
# default postgresql.conf.  Note that these are directives, not variable
# assignments, so they can usefully be given more than once.

#include_dir = '...'			# include files ending in '.conf' from
					# a directory, e.g., 'conf.d'
#include_if_exists = '...'		# include file only if it exists
#include = '...'			# include file

# Automatically generated optimizations
#include = '/etc/postgresql-custom/generated-optimizations.conf'
# User-supplied custom parameters, override any automatically generated ones
#include = '/etc/postgresql-custom/custom-overrides.conf'

# WAL-G specific configurations
#include = '/etc/postgresql-custom/wal-g.conf'

# read replica specific configurations
include = '/etc/postgresql-custom/read-replica.conf'

# supautils specific configurations
#include = '/etc/postgresql-custom/supautils.conf'

#------------------------------------------------------------------------------
# CUSTOMIZED OPTIONS
#------------------------------------------------------------------------------

# Add settings for extensions here
auto_explain.log_min_duration = 10s
cron.database_name = 'postgres'

'''

'''--- /Users/barneycook/Desktop/code/ProjectRef/postgres/ansible/files/postgresql_config/postgresql.service.j2 ---
[Unit]
Description=PostgreSQL database server
Documentation=man:postgres(1)
{% if supabase_internal is defined %}
Requires=database-optimizations.service
After=database-optimizations.service
{% endif %}

[Service]
Type=notify
User=postgres
Group=postgres
Environment="LANG=C"
Environment="LC_ALL=C"
ExecStart=/var/lib/postgresql/.nix-profile/bin/postgres -D /var/lib/postgresql/data
ExecStartPre=+/usr/local/bin/postgres_prestart.sh
ExecReload=/bin/kill -HUP $MAINPID
KillMode=mixed
KillSignal=SIGINT
TimeoutStopSec=90
TimeoutStartSec=86400
Restart=always
RestartSec=5
OOMScoreAdjust=-1000
EnvironmentFile=-/etc/environment.d/postgresql.env

[Install]
WantedBy=multi-user.target

'''

'''--- /Users/barneycook/Desktop/code/ProjectRef/postgres/ansible/files/postgresql_config/pg_hba.conf.j2 ---
# PostgreSQL Client Authentication Configuration File
# ===================================================
#
# Refer to the "Client Authentication" section in the PostgreSQL
# documentation for a complete description of this file.  A short
# synopsis follows.
#
# This file controls: which hosts are allowed to connect, how clients
# are authenticated, which PostgreSQL user names they can use, which
# databases they can access.  Records take one of these forms:
#
# local         DATABASE  USER  METHOD  [OPTIONS]
# host          DATABASE  USER  ADDRESS  METHOD  [OPTIONS]
# hostssl       DATABASE  USER  ADDRESS  METHOD  [OPTIONS]
# hostnossl     DATABASE  USER  ADDRESS  METHOD  [OPTIONS]
# hostgssenc    DATABASE  USER  ADDRESS  METHOD  [OPTIONS]
# hostnogssenc  DATABASE  USER  ADDRESS  METHOD  [OPTIONS]
#
# (The uppercase items must be replaced by actual values.)
#
# The first field is the connection type: "local" is a Unix-domain
# socket, "host" is either a plain or SSL-encrypted TCP/IP socket,
# "hostssl" is an SSL-encrypted TCP/IP socket, and "hostnossl" is a
# non-SSL TCP/IP socket.  Similarly, "hostgssenc" uses a
# GSSAPI-encrypted TCP/IP socket, while "hostnogssenc" uses a
# non-GSSAPI socket.
#
# DATABASE can be "all", "sameuser", "samerole", "replication", a
# database name, or a comma-separated list thereof. The "all"
# keyword does not match "replication". Access to replication
# must be enabled in a separate record (see example below).
#
# USER can be "all", a user name, a group name prefixed with "+", or a
# comma-separated list thereof.  In both the DATABASE and USER fields
# you can also write a file name prefixed with "@" to include names
# from a separate file.
#
# ADDRESS specifies the set of hosts the record matches.  It can be a
# host name, or it is made up of an IP address and a CIDR mask that is
# an integer (between 0 and 32 (IPv4) or 128 (IPv6) inclusive) that
# specifies the number of significant bits in the mask.  A host name
# that starts with a dot (.) matches a suffix of the actual host name.
# Alternatively, you can write an IP address and netmask in separate
# columns to specify the set of hosts.  Instead of a CIDR-address, you
# can write "samehost" to match any of the server's own IP addresses,
# or "samenet" to match any address in any subnet that the server is
# directly connected to.
#
# METHOD can be "trust", "reject", "md5", "password", "scram-sha-256",
# "gss", "sspi", "ident", "peer", "pam", "ldap", "radius" or "cert".
# Note that "password" sends passwords in clear text; "md5" or
# "scram-sha-256" are preferred since they send encrypted passwords.
#
# OPTIONS are a set of options for the authentication in the format
# NAME=VALUE.  The available options depend on the different
# authentication methods -- refer to the "Client Authentication"
# section in the documentation for a list of which options are
# available for which authentication methods.
#
# Database and user names containing spaces, commas, quotes and other
# special characters must be quoted.  Quoting one of the keywords
# "all", "sameuser", "samerole" or "replication" makes the name lose
# its special character, and just match a database or username with
# that name.
#
# This file is read on server startup and when the server receives a
# SIGHUP signal.  If you edit the file on a running system, you have to
# SIGHUP the server for the changes to take effect, run "pg_ctl reload",
# or execute "SELECT pg_reload_conf()".
#
# Put your actual configuration here
# ----------------------------------
#
# If you want to allow non-local connections, you need to add more
# "host" records.  In that case you will also need to make PostgreSQL
# listen on a non-local interface via the listen_addresses
# configuration parameter, or via the -i or -h command line switches.

# TYPE  DATABASE        USER            ADDRESS                 METHOD

# trust local connections
local all  capitala_admin     scram-sha-256
local all  all                peer map=supabase_map
host  all  all  127.0.0.1/32  trust
host  all  all  ::1/128       trust

# IPv4 external connections
host  all  all  10.0.0.0/8  scram-sha-256
host  all  all  172.31.19.62/32  scram-sha-256
host  all  all  51.20.66.16/32  scram-sha-256
host  all  all  0.0.0.0/0     scram-sha-256

# IPv6 external connections
host  all  all  ::0/0     scram-sha-256

'''

